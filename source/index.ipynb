{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "ha"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# This cell and its output are hidden in the final document\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import import_ipynb\n",
    "\n",
    "%pylab inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. raw:: html\n",
    "\n",
    "    <section class=\"first-page\">\n",
    "        <h1>Playing Awale with MCTS</h1>\n",
    "        <h2>Master thesis submitted in partial fulfillment of the requirements\n",
    "        for the degree of Master of Science in Applied Sciences and Engineering:&nbsp;Computer Science\n",
    "        </h2>\n",
    "\n",
    "        2020-2021\n",
    "    </section>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. contents:: Table of Contents\n",
    "   :depth: 3\n",
    "\n",
    ".. sectnum::"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "============\n",
    "Introduction\n",
    "============\n",
    "\n",
    "Awale is a popular board game played mainly in Africa. The board has two rows of six pits, each containing four seeds in the initial state.\n",
    "\n",
    "At each turn, the players move some seeds and can potentially capture some of them, according to deterministic rules. The goal of the game is to capture more seeds than one's opponent.\n",
    "\n",
    ".. _board:\n",
    "\n",
    ".. figure:: /_static/initial.jpg\n",
    "\n",
    "   A typical Awale board in the initial state with both players on their side of the board.\n",
    "   \n",
    "\n",
    ".. todo:: Explain here what i'm going to do in my thesis, why it is interesting and why it is new.\n",
    "\n",
    "In Section 2, we present Awale in detail. We then introduce Game Theory frameworks in Section 3.\n",
    "Section 4 reviews various approaches to solve Awale: retrograde analysis, :math:`\\alpha\\beta`-pruning Minimax, and basic Monte Carlo Tree Search.\n",
    "In Section 5, we describe more advanced versions of MCTS and in particular UCT.\n",
    "Section 6 presents some empirical results (simulations) allowing to compare several MCTS algorithms and Section 7 concludes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=====\n",
    "Awale\n",
    "=====\n",
    "\n",
    "The subject of our study, Awale is an ancient, two player board game originating from Ghana.\n",
    "This game is also sometimes called Awele, Oware, Owari or Ayo in the neighboring countries, languages and cultures :cite:`crane1982`.\n",
    "\n",
    "Originally, the game is played on the ground, by digging two rows of six small pits, each containing\n",
    "stones, seeds or shells. In the present document, we will name them seeds. The game is also often played on a wooden board symbolizing the original dirt pits.\n",
    "The board can be schematized as in :numref:`Figure %s <fig:initial_board>`, every big circle representing a pit and every small disc representing a seed.\n",
    "Numbers at the bottom right of each pit are the counts of seeds in each pit for better readability.\n",
    "Each row of pits is owned by a player that sits in front of it (:numref:`see Figure %s <board>`).\n",
    "For the sake of convenience, the players are named North and South.\n",
    "The 6 pits from the top row belong to North and the 6 from the bottom to South.\n",
    "\n",
    "The players take turns, a player removing all the seeds from a pit and placing them in other pits following the rules. This is called sowing the seeds. This can result in a configuration in which the player is allowed to capture some seeds according to the rules.\n",
    "The goal for each player is to capture more seeds than his opponent.\n",
    "The rules vary slightly across countries and will be detailed in Section (:ref:`sec:rules`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": [
     "ha"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell and its output are hidden in the final document\n",
    "\n",
    "from lib.draw import board_to_svg, pit_numbering\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hc",
     "fig:initial_board"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"535\" height=\"180\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\"/><text x=\"82.0\" y=\"82.0\">4</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\"/><text x=\"170.0\" y=\"82.0\">4</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\"/><text x=\"258.0\" y=\"82.0\">4</text><circle cx=\"312.0\" cy=\"48.0\" r=\"40\"/><text x=\"346.0\" y=\"82.0\">4</text><circle cx=\"400.0\" cy=\"48.0\" r=\"40\"/><text x=\"434.0\" y=\"82.0\">4</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\"/><text x=\"522.0\" y=\"82.0\">4</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\"/><text x=\"82.0\" y=\"170.0\">4</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\"/><text x=\"170.0\" y=\"170.0\">4</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\"/><text x=\"258.0\" y=\"170.0\">4</text><circle cx=\"312.0\" cy=\"136.0\" r=\"40\"/><text x=\"346.0\" y=\"170.0\">4</text><circle cx=\"400.0\" cy=\"136.0\" r=\"40\"/><text x=\"434.0\" y=\"170.0\">4</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\"/><text x=\"522.0\" y=\"170.0\">4</text>\n",
       "      <circle cx=\"57.776392789047875\" cy=\"51.524506211407875\" r=\"4\" class=\"bean\"/><circle cx=\"51.52450621140787\" cy=\"38.223607210952125\" r=\"4\" class=\"bean\"/><circle cx=\"38.223607210952125\" cy=\"44.47549378859213\" r=\"4\" class=\"bean\"/><circle cx=\"44.475493788592125\" cy=\"57.776392789047875\" r=\"4\" class=\"bean\"/><circle cx=\"146.33186414030598\" cy=\"46.88081128210673\" r=\"4\" class=\"bean\"/><circle cx=\"134.88081128210672\" cy=\"37.66813585969403\" r=\"4\" class=\"bean\"/><circle cx=\"125.66813585969403\" cy=\"49.119188717893266\" r=\"4\" class=\"bean\"/><circle cx=\"137.11918871789328\" cy=\"58.33186414030597\" r=\"4\" class=\"bean\"/><circle cx=\"233.96180229575887\" cy=\"50.96015118198604\" r=\"4\" class=\"bean\"/><circle cx=\"226.96015118198605\" cy=\"38.038197704241135\" r=\"4\" class=\"bean\"/><circle cx=\"214.03819770424113\" cy=\"45.03984881801395\" r=\"4\" class=\"bean\"/><circle cx=\"221.03984881801395\" cy=\"57.961802295758865\" r=\"4\" class=\"bean\"/><circle cx=\"319.5100994524531\" cy=\"40.81679693909025\" r=\"4\" class=\"bean\"/><circle cx=\"304.81679693909024\" cy=\"40.48990054754687\" r=\"4\" class=\"bean\"/><circle cx=\"304.4899005475469\" cy=\"55.18320306090974\" r=\"4\" class=\"bean\"/><circle cx=\"319.18320306090976\" cy=\"55.51009945245314\" r=\"4\" class=\"bean\"/><circle cx=\"410.3435662541287\" cy=\"49.005304504341986\" r=\"4\" class=\"bean\"/><circle cx=\"401.005304504342\" cy=\"37.65643374587131\" r=\"4\" class=\"bean\"/><circle cx=\"389.6564337458713\" cy=\"46.99469549565801\" r=\"4\" class=\"bean\"/><circle cx=\"398.994695495658\" cy=\"58.34356625412869\" r=\"4\" class=\"bean\"/><circle cx=\"494.73039450084\" cy=\"40.08155382268322\" r=\"4\" class=\"bean\"/><circle cx=\"480.0815538226832\" cy=\"41.26960549916001\" r=\"4\" class=\"bean\"/><circle cx=\"481.26960549916\" cy=\"55.91844617731678\" r=\"4\" class=\"bean\"/><circle cx=\"495.9184461773168\" cy=\"54.73039450083999\" r=\"4\" class=\"bean\"/><circle cx=\"58.37488565087998\" cy=\"136.60145467922752\" r=\"4\" class=\"bean\"/><circle cx=\"48.601454679227515\" cy=\"125.62511434912003\" r=\"4\" class=\"bean\"/><circle cx=\"37.62511434912002\" cy=\"135.39854532077248\" r=\"4\" class=\"bean\"/><circle cx=\"47.398545320772485\" cy=\"146.37488565087997\" r=\"4\" class=\"bean\"/><circle cx=\"145.48182987485808\" cy=\"131.74618968167962\" r=\"4\" class=\"bean\"/><circle cx=\"131.74618968167965\" cy=\"126.51817012514192\" r=\"4\" class=\"bean\"/><circle cx=\"126.51817012514192\" cy=\"140.25381031832035\" r=\"4\" class=\"bean\"/><circle cx=\"140.25381031832035\" cy=\"145.48182987485808\" r=\"4\" class=\"bean\"/><circle cx=\"234.36094883416834\" cy=\"136.80668411149958\" r=\"4\" class=\"bean\"/><circle cx=\"224.80668411149958\" cy=\"125.63905116583166\" r=\"4\" class=\"bean\"/><circle cx=\"213.63905116583166\" cy=\"135.19331588850042\" r=\"4\" class=\"bean\"/><circle cx=\"223.19331588850042\" cy=\"146.36094883416834\" r=\"4\" class=\"bean\"/><circle cx=\"315.3772325643266\" cy=\"145.82823993431438\" r=\"4\" class=\"bean\"/><circle cx=\"321.82823993431435\" cy=\"132.62276743567338\" r=\"4\" class=\"bean\"/><circle cx=\"308.6227674356734\" cy=\"126.17176006568562\" r=\"4\" class=\"bean\"/><circle cx=\"302.17176006568565\" cy=\"139.37723256432662\" r=\"4\" class=\"bean\"/><circle cx=\"409.2902649594875\" cy=\"131.3426427040092\" r=\"4\" class=\"bean\"/><circle cx=\"395.34264270400917\" cy=\"126.70973504051251\" r=\"4\" class=\"bean\"/><circle cx=\"390.7097350405125\" cy=\"140.6573572959908\" r=\"4\" class=\"bean\"/><circle cx=\"404.65735729599083\" cy=\"145.2902649594875\" r=\"4\" class=\"bean\"/><circle cx=\"495.1804464869795\" cy=\"128.4872649289607\" r=\"4\" class=\"bean\"/><circle cx=\"480.4872649289607\" cy=\"128.8195535130205\" r=\"4\" class=\"bean\"/><circle cx=\"480.8195535130205\" cy=\"143.5127350710393\" r=\"4\" class=\"bean\"/><circle cx=\"495.5127350710393\" cy=\"143.1804464869795\" r=\"4\" class=\"bean\"/>\n",
       "    </svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is hidden in the final document but the output is shown\n",
    "\n",
    "board = np.full((2, 6), 4)\n",
    "SVG(board_to_svg(board, True))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  A schematized view of the initial state of the board."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mancala\n",
    "-------\n",
    "\n",
    "The Mancala games are an ancient family of game that are played on many continents :cite:`deVoogt2008`, Awale being one of them.\n",
    "The word mancala comes from the Arabic word \"نقلة\", transliterated as \"naqala\" and literally meaning \"to move\".\n",
    "\n",
    "Like Awale, Mancala games can consist of rows of pits, some of them having more than two rows (:numref:`see Figure %s <bao>`) and sometimes extra pits with a special role. Mancala games can sometimes be played by more than two players.\n",
    " \n",
    ".. _bao:\n",
    "\n",
    ".. figure:: _static/bao.jpg\n",
    "\n",
    "  A wooden Bao game [#source_bao]_\n",
    "\n",
    "There are too many variants of the Mancala games to list them all here, but a\n",
    "few notable ones are Awale, Wari, Bao, Congkak and Kalah.\n",
    "\n",
    "Mancala games in general, while less known than Chess or Go, are quite popular and\n",
    "are played in tournaments around the world, both in offline and online competitions :cite:`owaresociety,fandom_tournaments`.\n",
    "\n",
    "\n",
    "\n",
    "In particular, Kalah is a commercial, modern variant of Mancala, introduced in the 1950s by William Julius Champion Jr., that is widespread in the United States. :cite:`irving2000solving`. This variant has been studied in Artifical Intelligence as early as 1964 by :cite:`russel1964`.\n",
    "Nowadays, Kalah is often used as an example game in computer-science courses.\n",
    "Other Mancala games have been studied in Computer Science and Artificial Intelligence :cite:`deVoogt2008`. Tournaments opposing computers on both sides have been organized multiple times, notably in the Computer Olympiad organized by the International Computer Games Association :cite:`icga_olympiad`.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _sec:rules:\n",
    "\n",
    "\n",
    "Rules of the game\n",
    "-----------------\n",
    "\n",
    "The basic rules of Awale are the same everywhere but there are some minor differences around the globe and in the literature.\n",
    "The rules presented here and implemented later in this thesis are inspired from :cite:`goot2001` and adapted by us.\n",
    "\n",
    "The goal for each player is to capture more seeds than his opponent. Because the\n",
    "game has 48 seeds, capturing 25 is enough for a player to win and ends the game.\n",
    "\n",
    "Each player plays alternatively, without the right to pass his turn. A\n",
    "player's turn consists in choosing one of his non-empty pits, picking all seeds\n",
    "contained in the pit and sowing them one by one in every consecutive pits on the right\n",
    "(rotating counter-clockwise). The player thus has at most 6 possible moves at\n",
    "each turn (one per non-empty pit owned by him).\n",
    "\n",
    "Usually, the player that starts the game is the oldest player. In this work, South will always play first.\n",
    "\n",
    "In this work, the pits of a player are numbered left to right from his point of view as shown in :numref:`Figure %s <fig:pit_numbering>`, :math:`1` being the leftmost pit of South, until :math:`6` at the far right. The same holds for North: :math:`1'` to :math:`6'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hc",
     "fig:pit_numbering"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"397\" height=\"140\">\n",
       "  <style>\n",
       "    circle {\n",
       "      fill: none;\n",
       "      stroke: #000;\n",
       "      stroke-width: 2;\n",
       "    }\n",
       "    text {\n",
       "      font-size: 1.5em;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "  <circle cx=\"36.0\" cy=\"36.0\" r=\"30\"/><text x=\"30.0\" y=\"42.0\">6'</text><circle cx=\"102.0\" cy=\"36.0\" r=\"30\"/><text x=\"96.0\" y=\"42.0\">5'</text><circle cx=\"168.0\" cy=\"36.0\" r=\"30\"/><text x=\"162.0\" y=\"42.0\">4'</text><circle cx=\"234.0\" cy=\"36.0\" r=\"30\"/><text x=\"228.0\" y=\"42.0\">3'</text><circle cx=\"300.0\" cy=\"36.0\" r=\"30\"/><text x=\"294.0\" y=\"42.0\">2'</text><circle cx=\"366.0\" cy=\"36.0\" r=\"30\"/><text x=\"360.0\" y=\"42.0\">1'</text><circle cx=\"36.0\" cy=\"102.0\" r=\"30\"/><text x=\"30.0\" y=\"108.0\">1</text><circle cx=\"102.0\" cy=\"102.0\" r=\"30\"/><text x=\"96.0\" y=\"108.0\">2</text><circle cx=\"168.0\" cy=\"102.0\" r=\"30\"/><text x=\"162.0\" y=\"108.0\">3</text><circle cx=\"234.0\" cy=\"102.0\" r=\"30\"/><text x=\"228.0\" y=\"108.0\">4</text><circle cx=\"300.0\" cy=\"102.0\" r=\"30\"/><text x=\"294.0\" y=\"108.0\">5</text><circle cx=\"366.0\" cy=\"102.0\" r=\"30\"/><text x=\"360.0\" y=\"108.0\">6</text>\n",
       "  \n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is hidden in the final document but the output is shown\n",
    "\n",
    "pit_numbering"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Pit numbering convention: the pits of a player are numbered left to right from his point of view."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "As an example, in the initial state (:numref:`See Figure %s <fig:initial_board>`), the first player to move is South (on the bottom) and he plays :math:`4` (highlighted in the figure in red), the board will then be in the  state shown in :numref:`Figure %s <fig:first_move>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hc",
     "fig:first_move"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"535\" height=\"180\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\"/><text x=\"82.0\" y=\"82.0\">4</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\"/><text x=\"170.0\" y=\"82.0\">4</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\"/><text x=\"258.0\" y=\"82.0\">4</text><circle cx=\"312.0\" cy=\"48.0\" r=\"40\"/><text x=\"346.0\" y=\"82.0\">4</text><circle cx=\"400.0\" cy=\"48.0\" r=\"40\"/><text x=\"434.0\" y=\"82.0\">5</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\"/><text x=\"522.0\" y=\"82.0\">5</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\"/><text x=\"82.0\" y=\"170.0\">4</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\"/><text x=\"170.0\" y=\"170.0\">4</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\"/><text x=\"258.0\" y=\"170.0\">4</text><circle cx=\"312.0\" cy=\"136.0\" r=\"40\" class=\"highlight\"/><text x=\"346.0\" y=\"170.0\">0</text><circle cx=\"400.0\" cy=\"136.0\" r=\"40\"/><text x=\"434.0\" y=\"170.0\">5</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\"/><text x=\"522.0\" y=\"170.0\">5</text>\n",
       "      <circle cx=\"58.19679791591028\" cy=\"50.00631808596934\" r=\"4\" class=\"bean\"/><circle cx=\"50.00631808596934\" cy=\"37.80320208408972\" r=\"4\" class=\"bean\"/><circle cx=\"37.80320208408972\" cy=\"45.99368191403066\" r=\"4\" class=\"bean\"/><circle cx=\"45.99368191403066\" cy=\"58.19679791591028\" r=\"4\" class=\"bean\"/><circle cx=\"140.16630376660459\" cy=\"38.47939534880392\" r=\"4\" class=\"bean\"/><circle cx=\"126.47939534880392\" cy=\"43.83369623339542\" r=\"4\" class=\"bean\"/><circle cx=\"131.83369623339541\" cy=\"57.52060465119608\" r=\"4\" class=\"bean\"/><circle cx=\"145.5206046511961\" cy=\"52.16630376660458\" r=\"4\" class=\"bean\"/><circle cx=\"234.3570137238723\" cy=\"47.14427415399539\" r=\"4\" class=\"bean\"/><circle cx=\"223.14427415399538\" cy=\"37.64298627612767\" r=\"4\" class=\"bean\"/><circle cx=\"213.6429862761277\" cy=\"48.85572584600461\" r=\"4\" class=\"bean\"/><circle cx=\"224.85572584600462\" cy=\"58.35701372387233\" r=\"4\" class=\"bean\"/><circle cx=\"320.6291675922412\" cy=\"42.208845826174645\" r=\"4\" class=\"bean\"/><circle cx=\"306.20884582617464\" cy=\"39.37083240775884\" r=\"4\" class=\"bean\"/><circle cx=\"303.3708324077588\" cy=\"53.79115417382536\" r=\"4\" class=\"bean\"/><circle cx=\"317.79115417382536\" cy=\"56.62916759224116\" r=\"4\" class=\"bean\"/><circle cx=\"407.8005315333329\" cy=\"57.11875582508267\" r=\"4\" class=\"bean\"/><circle cx=\"411.0829489569068\" cy=\"43.399104172164016\" r=\"4\" class=\"bean\"/><circle cx=\"399.0491076176157\" cy=\"36.03773417461711\" r=\"4\" class=\"bean\"/><circle cx=\"388.32936723113636\" cy=\"45.20780896528805\" r=\"4\" class=\"bean\"/><circle cx=\"393.73804466100825\" cy=\"58.236596862848174\" r=\"4\" class=\"bean\"/><circle cx=\"498.36581751276714\" cy=\"41.954354683575154\" r=\"4\" class=\"bean\"/><circle cx=\"485.45346339863937\" cy=\"36.27331456301779\" r=\"4\" class=\"bean\"/><circle cx=\"476.06033631399634\" cy=\"46.798155140991426\" r=\"4\" class=\"bean\"/><circle cx=\"483.1674186291675\" cy=\"58.98390446491059\" r=\"4\" class=\"bean\"/><circle cx=\"496.95296414542963\" cy=\"55.99027114750505\" r=\"4\" class=\"bean\"/><circle cx=\"50.63801858005013\" cy=\"125.94809182436936\" r=\"4\" class=\"bean\"/><circle cx=\"37.94809182436935\" cy=\"133.36198141994987\" r=\"4\" class=\"bean\"/><circle cx=\"45.36198141994987\" cy=\"146.05190817563064\" r=\"4\" class=\"bean\"/><circle cx=\"58.05190817563065\" cy=\"138.63801858005013\" r=\"4\" class=\"bean\"/><circle cx=\"145.7011488283653\" cy=\"132.27337801623148\" r=\"4\" class=\"bean\"/><circle cx=\"132.2733780162315\" cy=\"126.29885117163471\" r=\"4\" class=\"bean\"/><circle cx=\"126.29885117163471\" cy=\"139.72662198376852\" r=\"4\" class=\"bean\"/><circle cx=\"139.72662198376852\" cy=\"145.7011488283653\" r=\"4\" class=\"bean\"/><circle cx=\"230.18116195653835\" cy=\"144.35423466674496\" r=\"4\" class=\"bean\"/><circle cx=\"232.35423466674496\" cy=\"129.81883804346165\" r=\"4\" class=\"bean\"/><circle cx=\"217.81883804346165\" cy=\"127.64576533325504\" r=\"4\" class=\"bean\"/><circle cx=\"215.64576533325504\" cy=\"142.18116195653835\" r=\"4\" class=\"bean\"/><circle cx=\"406.6165455374505\" cy=\"146.011060141206\" r=\"4\" class=\"bean\"/><circle cx=\"411.5657089974446\" cy=\"132.8008789665864\" r=\"4\" class=\"bean\"/><circle cx=\"400.5314557269607\" cy=\"124.01177432601969\" r=\"4\" class=\"bean\"/><circle cx=\"388.7627487053329\" cy=\"131.78999010208966\" r=\"4\" class=\"bean\"/><circle cx=\"392.5235410328113\" cy=\"145.38629646409825\" r=\"4\" class=\"bean\"/><circle cx=\"492.4390087832571\" cy=\"147.14877576338165\" r=\"4\" class=\"bean\"/><circle cx=\"499.9748449906837\" cy=\"135.22341294815237\" r=\"4\" class=\"bean\"/><circle cx=\"490.9618524309968\" cy=\"124.37126704335343\" r=\"4\" class=\"bean\"/><circle cx=\"477.8556804813338\" cy=\"129.589634838544\" r=\"4\" class=\"bean\"/><circle cx=\"478.7686133137285\" cy=\"143.66690940656855\" r=\"4\" class=\"bean\"/>\n",
       "    </svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is hidden in the final document but the output is shown\n",
    "\n",
    "board = np.array([[4, 4, 4, 4, 5, 5], [4, 4, 4, 0, 5, 5],])\n",
    "SVG(board_to_svg(board, True, highlight=[(1, 3)]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  The board after the first move, where South played pit 4, in red."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When the last sowed seed is placed in a pit owned by the opponent and, after sowing,\n",
    "the pit contains two or three seeds, the content of the pit is captured by\n",
    "the player and removed from the game. If the pit preceding the captured pit also\n",
    "contains two or three seeds, it is also captured. The capture continues until a\n",
    "pit without two or three seeds is encountered. When the capture is ended the\n",
    "next player's turn starts.\n",
    "\n",
    "Otherwise, when the last sowed seed is placed in a pit that, after sowing, contains one seed, more\n",
    "than 3 seeds or in the current player's own pits, the turn of the player is ended without\n",
    "any capture.\n",
    "For example, if South plays :math:`4` in the configuration shown in :numref:`Figure %s <fig:pre_capture>`, he will\n",
    "be able to capture the seeds in pits 2' and 3' (highlighted in red in :numref:`Figure %s <fig:post_capture>`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hc",
     "fig:pre_capture"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"535\" height=\"180\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\"/><text x=\"82.0\" y=\"82.0\">4</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\"/><text x=\"170.0\" y=\"82.0\">6</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\"/><text x=\"258.0\" y=\"82.0\">4</text><circle cx=\"312.0\" cy=\"48.0\" r=\"40\"/><text x=\"346.0\" y=\"82.0\">1</text><circle cx=\"400.0\" cy=\"48.0\" r=\"40\"/><text x=\"434.0\" y=\"82.0\">2</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\"/><text x=\"522.0\" y=\"82.0\">3</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\"/><text x=\"82.0\" y=\"170.0\">3</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\"/><text x=\"170.0\" y=\"170.0\">3</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\"/><text x=\"258.0\" y=\"170.0\">3</text><circle cx=\"312.0\" cy=\"136.0\" r=\"40\" class=\"highlight\"/><text x=\"346.0\" y=\"170.0\">5</text><circle cx=\"400.0\" cy=\"136.0\" r=\"40\"/><text x=\"434.0\" y=\"170.0\">2</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\"/><text x=\"522.0\" y=\"170.0\">2</text>\n",
       "      <circle cx=\"55.20066266717835\" cy=\"55.49336087169862\" r=\"4\" class=\"bean\"/><circle cx=\"55.49336087169863\" cy=\"40.79933733282165\" r=\"4\" class=\"bean\"/><circle cx=\"40.79933733282165\" cy=\"40.50663912830137\" r=\"4\" class=\"bean\"/><circle cx=\"40.50663912830138\" cy=\"55.20066266717836\" r=\"4\" class=\"bean\"/><circle cx=\"143.14275956365765\" cy=\"59.35697960796695\" r=\"4\" class=\"bean\"/><circle cx=\"149.40681263259003\" cy=\"47.492678568731684\" r=\"4\" class=\"bean\"/><circle cx=\"142.26405306893238\" cy=\"36.13569896076474\" r=\"4\" class=\"bean\"/><circle cx=\"128.85724043634235\" cy=\"36.64302039203305\" r=\"4\" class=\"bean\"/><circle cx=\"122.59318736740997\" cy=\"48.50732143126831\" r=\"4\" class=\"bean\"/><circle cx=\"129.73594693106762\" cy=\"59.864301039235265\" r=\"4\" class=\"bean\"/><circle cx=\"233.1232119791061\" cy=\"52.976645776453786\" r=\"4\" class=\"bean\"/><circle cx=\"228.97664577645378\" cy=\"38.87678802089392\" r=\"4\" class=\"bean\"/><circle cx=\"214.8767880208939\" cy=\"43.023354223546214\" r=\"4\" class=\"bean\"/><circle cx=\"219.02335422354622\" cy=\"57.12321197910608\" r=\"4\" class=\"bean\"/><circle cx=\"312.0\" cy=\"48.0\" r=\"4\" class=\"bean\"/><circle cx=\"403.80436380039663\" cy=\"52.63969999830073\" r=\"4\" class=\"bean\"/><circle cx=\"396.19563619960337\" cy=\"43.36030000169927\" r=\"4\" class=\"bean\"/><circle cx=\"493.6312627922533\" cy=\"41.652647846181566\" r=\"4\" class=\"bean\"/><circle cx=\"479.6874003919007\" cy=\"46.296859443431764\" r=\"4\" class=\"bean\"/><circle cx=\"490.681336815846\" cy=\"56.05049271038667\" r=\"4\" class=\"bean\"/><circle cx=\"52.43385454533432\" cy=\"128.76529655958046\" r=\"4\" class=\"bean\"/><circle cx=\"39.51763575908285\" cy=\"135.77752104726514\" r=\"4\" class=\"bean\"/><circle cx=\"52.04850969558283\" cy=\"143.4571823931544\" r=\"4\" class=\"bean\"/><circle cx=\"142.48757159932057\" cy=\"141.46913290601802\" r=\"4\" class=\"bean\"/><circle cx=\"137.49262223362473\" cy=\"127.64703173310893\" r=\"4\" class=\"bean\"/><circle cx=\"128.0198061670547\" cy=\"138.88383536087304\" r=\"4\" class=\"bean\"/><circle cx=\"230.4757477217844\" cy=\"141.48312788869677\" r=\"4\" class=\"bean\"/><circle cx=\"225.51065418291816\" cy=\"127.65027402008712\" r=\"4\" class=\"bean\"/><circle cx=\"216.01359809529748\" cy=\"138.8665980912161\" r=\"4\" class=\"bean\"/><circle cx=\"312.74593474139357\" cy=\"147.97679345073556\" r=\"4\" class=\"bean\"/><circle cx=\"323.62111396742847\" cy=\"138.99160661786254\" r=\"4\" class=\"bean\"/><circle cx=\"318.43630867761334\" cy=\"125.87212112007262\" r=\"4\" class=\"bean\"/><circle cx=\"304.3567435574225\" cy=\"126.74902000040011\" r=\"4\" class=\"bean\"/><circle cx=\"300.83989905614214\" cy=\"140.41045881092916\" r=\"4\" class=\"bean\"/><circle cx=\"404.42849081772613\" cy=\"140.0482674167248\" r=\"4\" class=\"bean\"/><circle cx=\"395.57150918227387\" cy=\"131.9517325832752\" r=\"4\" class=\"bean\"/><circle cx=\"490.29854402239755\" cy=\"141.54226446293396\" r=\"4\" class=\"bean\"/><circle cx=\"485.70145597760245\" cy=\"130.45773553706604\" r=\"4\" class=\"bean\"/>\n",
       "    </svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is hidden in the final document but the output is shown\n",
    "\n",
    "board = np.array([[4, 6, 4, 1, 2, 3], [3, 3, 3, 5, 2, 2],])\n",
    "SVG(board_to_svg(board, True, highlight=[(1, 3)]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  An example of a board configuration where South is to play pit 4, in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": [
     "hc",
     "fig:post_capture"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"535\" height=\"180\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\"/><text x=\"82.0\" y=\"82.0\">4</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\"/><text x=\"170.0\" y=\"82.0\">6</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\"/><text x=\"258.0\" y=\"82.0\">4</text><circle cx=\"312.0\" cy=\"48.0\" r=\"40\" class=\"highlight\"/><text x=\"346.0\" y=\"82.0\">2</text><circle cx=\"400.0\" cy=\"48.0\" r=\"40\" class=\"highlight\"/><text x=\"434.0\" y=\"82.0\">3</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\"/><text x=\"522.0\" y=\"82.0\">4</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\"/><text x=\"82.0\" y=\"170.0\">3</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\"/><text x=\"170.0\" y=\"170.0\">3</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\"/><text x=\"258.0\" y=\"170.0\">3</text><circle cx=\"312.0\" cy=\"136.0\" r=\"40\"/><text x=\"346.0\" y=\"170.0\">0</text><circle cx=\"400.0\" cy=\"136.0\" r=\"40\"/><text x=\"434.0\" y=\"170.0\">3</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\"/><text x=\"522.0\" y=\"170.0\">3</text>\n",
       "      <circle cx=\"57.652076594929724\" cy=\"51.851936838216574\" r=\"4\" class=\"bean\"/><circle cx=\"51.85193683821658\" cy=\"38.34792340507028\" r=\"4\" class=\"bean\"/><circle cx=\"38.34792340507028\" cy=\"44.14806316178342\" r=\"4\" class=\"bean\"/><circle cx=\"44.14806316178342\" cy=\"57.65207659492972\" r=\"4\" class=\"bean\"/><circle cx=\"149.3957281777676\" cy=\"47.25537486789458\" r=\"4\" class=\"bean\"/><circle cx=\"142.05299980818418\" cy=\"36.02664652980952\" r=\"4\" class=\"bean\"/><circle cx=\"128.65727163041657\" cy=\"36.77127166191494\" r=\"4\" class=\"bean\"/><circle cx=\"122.60427182223239\" cy=\"48.74462513210541\" r=\"4\" class=\"bean\"/><circle cx=\"129.94700019181582\" cy=\"59.973353470190474\" r=\"4\" class=\"bean\"/><circle cx=\"143.34272836958343\" cy=\"59.22872833808506\" r=\"4\" class=\"bean\"/><circle cx=\"227.7468500349619\" cy=\"38.30664584287224\" r=\"4\" class=\"bean\"/><circle cx=\"214.30664584287223\" cy=\"44.25314996503809\" r=\"4\" class=\"bean\"/><circle cx=\"220.2531499650381\" cy=\"57.69335415712776\" r=\"4\" class=\"bean\"/><circle cx=\"233.69335415712777\" cy=\"51.74685003496191\" r=\"4\" class=\"bean\"/><circle cx=\"313.20106334233236\" cy=\"53.87855822865653\" r=\"4\" class=\"bean\"/><circle cx=\"310.79893665766764\" cy=\"42.12144177134347\" r=\"4\" class=\"bean\"/><circle cx=\"405.0717405352781\" cy=\"54.802752967940066\" r=\"4\" class=\"bean\"/><circle cx=\"403.35548661826704\" cy=\"40.20636737107588\" r=\"4\" class=\"bean\"/><circle cx=\"391.5727728464549\" cy=\"48.990879660984056\" r=\"4\" class=\"bean\"/><circle cx=\"488.70379475209114\" cy=\"37.631553976273544\" r=\"4\" class=\"bean\"/><circle cx=\"477.63155397627355\" cy=\"47.29620524790884\" r=\"4\" class=\"bean\"/><circle cx=\"487.29620524790886\" cy=\"58.368446023726456\" r=\"4\" class=\"bean\"/><circle cx=\"498.36844602372645\" cy=\"48.70379475209116\" r=\"4\" class=\"bean\"/><circle cx=\"56.14912251807388\" cy=\"138.3646991744028\" r=\"4\" class=\"bean\"/><circle cx=\"45.97332829830397\" cy=\"127.7603032935948\" r=\"4\" class=\"bean\"/><circle cx=\"41.87754918362215\" cy=\"141.8749975320024\" r=\"4\" class=\"bean\"/><circle cx=\"140.98245305684034\" cy=\"142.8684176879673\" r=\"4\" class=\"bean\"/><circle cx=\"139.4569976731619\" cy=\"128.25086023562918\" r=\"4\" class=\"bean\"/><circle cx=\"127.56054926999775\" cy=\"136.88072207640352\" r=\"4\" class=\"bean\"/><circle cx=\"226.6729324021207\" cy=\"127.94671294602674\" r=\"4\" class=\"bean\"/><circle cx=\"215.68918262623046\" cy=\"137.71181616415154\" r=\"4\" class=\"bean\"/><circle cx=\"229.63788497164882\" cy=\"142.34147088982172\" r=\"4\" class=\"bean\"/><circle cx=\"405.0026375533266\" cy=\"142.85373018946953\" r=\"4\" class=\"bean\"/><circle cx=\"403.43418567810164\" cy=\"128.24072369815835\" r=\"4\" class=\"bean\"/><circle cx=\"391.56317676857174\" cy=\"136.90554611237212\" r=\"4\" class=\"bean\"/><circle cx=\"495.764564276412\" cy=\"139.4222129678714\" r=\"4\" class=\"bean\"/><circle cx=\"487.0814412291312\" cy=\"127.5645836033744\" r=\"4\" class=\"bean\"/><circle cx=\"481.15399449445687\" cy=\"141.0132034287542\" r=\"4\" class=\"bean\"/>\n",
       "    </svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is hidden in the final document but the output is shown\n",
    "\n",
    "board = np.array([[4, 6, 4, 2, 3, 4], [3, 3, 3, 0, 3, 3],])\n",
    "SVG(board_to_svg(board, True, highlight=[(0, 3), (0, 4)]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  The resulting board after South played 4 in :numref:`Fig %s <fig:pre_capture>`. Pits 2' and 3' in red will be captured."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If the pit chosen by the player contains more than 12 seeds, the sowing makes\n",
    "more than a full revolution of the board and the starting hole is skipped during the second\n",
    "and subsequent passes.\n",
    "\n",
    "If the current player's opponent has no seed left in his half board, the\n",
    "current player has to play a move that gives him seeds if such a move exists.\n",
    "This rule is called the \"feed your opponent\".\n",
    "In :numref:`Figure %s <fig:feed>`, South has to play pit 5 because playing pit 1 would leave the opponent without any move to play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hc",
     "fig:feed"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"535\" height=\"180\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\"/><text x=\"82.0\" y=\"82.0\">0</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\"/><text x=\"170.0\" y=\"82.0\">0</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\"/><text x=\"258.0\" y=\"82.0\">0</text><circle cx=\"312.0\" cy=\"48.0\" r=\"40\"/><text x=\"346.0\" y=\"82.0\">0</text><circle cx=\"400.0\" cy=\"48.0\" r=\"40\"/><text x=\"434.0\" y=\"82.0\">0</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\"/><text x=\"522.0\" y=\"82.0\">0</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\"/><text x=\"82.0\" y=\"170.0\">2</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\"/><text x=\"170.0\" y=\"170.0\">0</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\"/><text x=\"258.0\" y=\"170.0\">0</text><circle cx=\"312.0\" cy=\"136.0\" r=\"40\"/><text x=\"346.0\" y=\"170.0\">0</text><circle cx=\"400.0\" cy=\"136.0\" r=\"40\" class=\"highlight\"/><text x=\"434.0\" y=\"170.0\">3</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\"/><text x=\"522.0\" y=\"170.0\">0</text>\n",
       "      <circle cx=\"53.228072421467154\" cy=\"133.05597915158629\" r=\"4\" class=\"bean\"/><circle cx=\"42.771927578532846\" cy=\"138.94402084841371\" r=\"4\" class=\"bean\"/><circle cx=\"404.91234343928784\" cy=\"129.08126587196142\" r=\"4\" class=\"bean\"/><circle cx=\"391.5520287634443\" cy=\"135.20515285348222\" r=\"4\" class=\"bean\"/><circle cx=\"403.53562779726786\" cy=\"143.71358127455636\" r=\"4\" class=\"bean\"/>\n",
       "    </svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is hidden in the final document but the output is shown\n",
    "\n",
    "board = np.array([[0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 3, 0],])\n",
    "SVG(board_to_svg(board, True, highlight=[(1, 4)]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  South is forced to play pit 5, in red, because playing pit 1 would leave North without any seed to play."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When a player has captured more than 25 seeds the game ends and he wins. If both\n",
    "players have captured 24 seeds, the game ends by a draw. If the current player's\n",
    "pits are all empty, the game ends and the player with the most captures wins.\n",
    "\n",
    "The last way to stop the game is when a position is encountered twice in the\n",
    "same game (there is a cycle): the game ends and the player with most captures\n",
    "wins."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Implementation of the rules\n",
    "---------------------------\n",
    "\n",
    "You might be reading this document in the form of a web page or a pdf file but its original form is a Jupyter Notebook :cite:`jupyter`. Jupyter Notebooks are documents mixing computer code (in this case Python code), the result of the execution of the code and text. These can be used to document experiments in the same place they are run.\n",
    "\n",
    "Sections containing code are prefixed by :code:`In[]:` and the output of the code is showed immediately under it, prefixed by :code:`Out[]:`. An example is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was executed by Python\n"
     ]
    }
   ],
   "source": [
    "# This is Python code\n",
    "print(\"This was executed by Python\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this subsection, we use the use the power of Jupyter Notebooks to define in multiple steps a Python :code:`Game()` class holding the state of the game. We will then successively inherit from it to add an implementation of the rules and some convenience methods.\n",
    "\n",
    "We set the following encoding conventions:\n",
    " - :code:`0` is South, :code:`1` is North,\n",
    " - player's actions are numbered from :code:`0` to :code:`5`, :code:`0` being the leftmost pit in front of him, :code:`5` being the rightmost.\n",
    "\n",
    "First, we define a dataclass with the minimal attributes needed to store a state of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "ha"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell and its output are hidden in the final document\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "import itertools\n",
    "from typing import List, Dict, Set, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class Game:\n",
    "    # a 2x6 matrix containing the number of seeds in each pits\n",
    "    pits: np.array = field(default_factory=lambda: np.ones(6 * 2, dtype=int) * 4)\n",
    "    # 0 for South and 1 for North\n",
    "    current_player: int = 0\n",
    "    # the number of seeds captured by each player\n",
    "    captures: np.array = field(default_factory=lambda: np.zeros(2, dtype=int))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "We then add some convenience methods that will be useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Game(Game):\n",
    "    ...\n",
    "\n",
    "    @property\n",
    "    def view_from_current_player(self) -> List[int]:\n",
    "        \"\"\"Returns the board as seen by a player\"\"\"\n",
    "        if self.current_player == 0:\n",
    "            return self.pits\n",
    "        else:\n",
    "            return np.roll(self.pits, 6)\n",
    "\n",
    "    @property\n",
    "    def current_player_pits(self) -> List[int]:\n",
    "        \"\"\"Returns a 6-vector containing the pits owned by the current player\"\"\"\n",
    "        if self.current_player == 0:\n",
    "            return self.pits[:6]\n",
    "        else:\n",
    "            return self.pits[6:]\n",
    "\n",
    "    @property\n",
    "    def current_opponent(self) -> int:\n",
    "        return (self.current_player + 1) % 2\n",
    "\n",
    "    @property\n",
    "    def adverse_pits_idx(self) -> List[int]:\n",
    "        \"\"\"Returns the indices in the `self.pits` array owned by the opposing player\"\"\"\n",
    "        if self.current_player == 1:\n",
    "            return list(range(6))\n",
    "        else:\n",
    "            return list(range(6, 6 * 2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Now that the base is set, we start implementing the rules,\n",
    "some of them being deliberately excluded from this implementation:\n",
    "\n",
    "-  Loops in the game state are not checked (this considerably speeds up the computations and we did not encounter a loop in our preliminary work);\n",
    "-  The \"feed your opponent\" rule is removed; This makes the\n",
    "   rules simpler and we expect it does not tremendously change the complexity of the game.\n",
    "\n",
    ".. todo We did later encounter loops after running way more simulations. But this only happened yet using basic algorithms (greedy vs greedy for example). For now, we simulate 500 turns, if we hit this threshold, we declare a tie. This should be detailed in the experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Game(Game):\n",
    "    ...\n",
    "\n",
    "    @property\n",
    "    def legal_actions(self) -> List[int]:\n",
    "        \"\"\"Returns a list of indices for each legal action for the current player\"\"\"\n",
    "        our_pits = self.current_player_pits\n",
    "        # Return every pit of the player that contains some seeds\n",
    "        return [x for x in range(6) if our_pits[x] != 0]\n",
    "\n",
    "    @property\n",
    "    def game_finished(self) -> bool:\n",
    "        # Does the current player has an available move ?\n",
    "        no_moves_left = np.sum(self.current_player_pits) == 0\n",
    "\n",
    "        # Has one player captured more than half the total seeds ?\n",
    "        HALF_SEEDS = 24  # (there are 2*6*4=48 seeds in total)\n",
    "        enough_captures = self.captures[0] > HALF_SEEDS or self.captures[1] > HALF_SEEDS\n",
    "\n",
    "        # Is it a draw ? Does both player have 24 seeds ?\n",
    "        draw = self.captures[0] == HALF_SEEDS and self.captures[1] == HALF_SEEDS\n",
    "\n",
    "        # If one of the above three are True, the game is finished\n",
    "        return no_moves_left or enough_captures or draw\n",
    "\n",
    "    @property\n",
    "    def winner(self) -> Optional[int]:\n",
    "        \"\"\"Returns the winner of the game or None if the game is not finished or in a draw\"\"\"\n",
    "        if not self.game_finished:\n",
    "            return None\n",
    "        # The game is finished but both player have the same number of seeds: it's a draw\n",
    "        elif self.captures[0] == self.captures[1]:\n",
    "            return None\n",
    "        # Else, there is a winner: the player with the most seeds\n",
    "        else:\n",
    "            return 0 if self.captures[0] > self.captures[1] else 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "We can now define the :code:`Game.step(i)` method that is called for every step of the game.\n",
    "It takes a single parameter, :code:`i`, and plays the i-th pit in the current sate.\n",
    "This method returns the new state, the number of seeds captured and a boolean informing whether the game is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Game(Game):\n",
    "    ...\n",
    "\n",
    "    def step(self, action: int) -> Tuple[Game, int, bool]:\n",
    "        \"\"\"Plays the action given as parameter and returns:\n",
    "            - a the new state as a new Game object,\n",
    "            - the number of captured stones in the transition\n",
    "            - a bool indicating if the new state is the end of the game\n",
    "        \"\"\"\n",
    "        assert 0 <= action < 6, \"Illegal action\"\n",
    "\n",
    "        # Translate the action index to a pit index\n",
    "        target_pit = action if self.current_player == 0 else action - 6\n",
    "\n",
    "        seeds = self.pits[target_pit]\n",
    "        assert seeds != 0, \"Illegal action: pit % is empty\" % target_pit\n",
    "\n",
    "        # Copy the attributes of `Game` so that the original\n",
    "        # stays immutable\n",
    "        pits = np.copy(self.pits)\n",
    "        captures = np.copy(self.captures)\n",
    "\n",
    "        # Empty the pit targeted by the player\n",
    "        pits[target_pit] = 0\n",
    "\n",
    "        # Fill the next pits while there are still seeds\n",
    "        pit_to_sow = target_pit\n",
    "        while seeds > 0:\n",
    "            pit_to_sow = (pit_to_sow + 1) % (6 * 2)\n",
    "            # Do not fill the target pit ever\n",
    "            if pit_to_sow != target_pit:\n",
    "                pits[pit_to_sow] += 1\n",
    "                seeds -= 1\n",
    "\n",
    "        # Count the captures of the play\n",
    "        round_captures = 0\n",
    "\n",
    "        # If the last seed was in a adverse pit we can try to collect seeds\n",
    "        if pit_to_sow in self.adverse_pits_idx:\n",
    "            # If the pit contains 2 or 3 seeds, we capture them\n",
    "            while pits[pit_to_sow] in (2, 3):\n",
    "                captures[self.current_player] += pits[pit_to_sow]\n",
    "                round_captures += pits[pit_to_sow]\n",
    "                pits[pit_to_sow] = 0\n",
    "\n",
    "                # Select backwards the next pit to check\n",
    "                pit_to_sow = (pit_to_sow - 1) % 12\n",
    "\n",
    "        # Change the current player\n",
    "        current_player = (self.current_player + 1) % 2\n",
    "\n",
    "        # Create the new `Game` instance\n",
    "        new_game = type(self)(pits, current_player, captures)\n",
    "\n",
    "        return new_game, round_captures, new_game.game_finished"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "As the game rules are now implemented, we can add some methods to display the current state of the board to the user, either in textual mode or as an SVG file that can be displayed inline in this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(Game):\n",
    "    ...\n",
    "\n",
    "    def show_state(self):\n",
    "        \"\"\"Print a textual representation of the game to the standard output\"\"\"\n",
    "        if self.game_finished:\n",
    "            print(\"Game finished\")\n",
    "        print(\n",
    "            \"Current player: {} - Score: {}/{}\\n{}\".format(\n",
    "                self.current_player,\n",
    "                self.captures[self.current_player],\n",
    "                self.captures[(self.current_player + 1) % 2],\n",
    "                \"-\" * 6 * 3,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        pits = []\n",
    "        for seeds in self.view_from_current_player:\n",
    "            pits.append(\"{:3}\".format(seeds))\n",
    "\n",
    "        print(\"\".join(reversed(pits[6:])))\n",
    "        print(\"\".join(pits[:6]))\n",
    "\n",
    "    def _repr_svg_(self):\n",
    "        \"\"\"Return a SVG file representing the current state to be displayed in a notebook\"\"\"\n",
    "        board = np.array([list(reversed(self.pits[6:])), self.pits[:6]])\n",
    "        return board_to_svg(board, True) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To show a minimal example of the implementation, we can now play a move and have its results displayed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "\n",
       "    <svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"535\" height=\"180\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\" /><text x=\"82.0\" y=\"82.0\" >4</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\" /><text x=\"170.0\" y=\"82.0\" >4</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\" /><text x=\"258.0\" y=\"82.0\" >4</text><circle cx=\"312.0\" cy=\"48.0\" r=\"40\" /><text x=\"346.0\" y=\"82.0\" >5</text><circle cx=\"400.0\" cy=\"48.0\" r=\"40\" /><text x=\"434.0\" y=\"82.0\" >5</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\" /><text x=\"522.0\" y=\"82.0\" >5</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\" /><text x=\"82.0\" y=\"170.0\" >4</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\" /><text x=\"170.0\" y=\"170.0\" >4</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\" /><text x=\"258.0\" y=\"170.0\" >4</text><circle cx=\"312.0\" cy=\"136.0\" r=\"40\" /><text x=\"346.0\" y=\"170.0\" >4</text><circle cx=\"400.0\" cy=\"136.0\" r=\"40\" /><text x=\"434.0\" y=\"170.0\" >0</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\" /><text x=\"522.0\" y=\"170.0\" >5</text>\n",
       "      <circle cx=\"53.04026716281911\" cy=\"57.088218028161926\" r=\"4\" class=\"bean\"/><circle cx=\"57.088218028161926\" cy=\"42.959732837180894\" r=\"4\" class=\"bean\"/><circle cx=\"42.959732837180894\" cy=\"38.911781971838074\" r=\"4\" class=\"bean\"/><circle cx=\"38.911781971838074\" cy=\"53.040267162819106\" r=\"4\" class=\"bean\"/><circle cx=\"144.82329329078402\" cy=\"42.50914437407013\" r=\"4\" class=\"bean\"/><circle cx=\"130.50914437407013\" cy=\"39.17670670921598\" r=\"4\" class=\"bean\"/><circle cx=\"127.17670670921598\" cy=\"53.49085562592987\" r=\"4\" class=\"bean\"/><circle cx=\"141.49085562592987\" cy=\"56.82329329078402\" r=\"4\" class=\"bean\"/><circle cx=\"232.1816496160764\" cy=\"54.40785530109387\" r=\"4\" class=\"bean\"/><circle cx=\"230.40785530109386\" cy=\"39.818350383923594\" r=\"4\" class=\"bean\"/><circle cx=\"215.8183503839236\" cy=\"41.59214469890613\" r=\"4\" class=\"bean\"/><circle cx=\"217.59214469890614\" cy=\"56.181649616076406\" r=\"4\" class=\"bean\"/><circle cx=\"313.86564476226886\" cy=\"36.14591337887989\" r=\"4\" class=\"bean\"/><circle cx=\"301.3026096112642\" cy=\"42.56255217303346\" r=\"4\" class=\"bean\"/><circle cx=\"303.52300438656596\" cy=\"56.49355905200053\" r=\"4\" class=\"bean\"/><circle cx=\"317.4583189771498\" cy=\"58.686756006557204\" r=\"4\" class=\"bean\"/><circle cx=\"323.8504222627512\" cy=\"46.11121938952893\" r=\"4\" class=\"bean\"/><circle cx=\"411.395808884639\" cy=\"51.75972603586798\" r=\"4\" class=\"bean\"/><circle cx=\"407.09721055589927\" cy=\"38.32376094108706\" r=\"4\" class=\"bean\"/><circle cx=\"392.9905084642213\" cy=\"38.26002934245453\" r=\"4\" class=\"bean\"/><circle cx=\"388.57068543113485\" cy=\"51.65660614312318\" r=\"4\" class=\"bean\"/><circle cx=\"399.94578666410564\" cy=\"59.999877537467256\" r=\"4\" class=\"bean\"/><circle cx=\"499.97125737033366\" cy=\"47.16994158444599\" r=\"4\" class=\"bean\"/><circle cx=\"490.9098895064512\" cy=\"36.358155512967656\" r=\"4\" class=\"bean\"/><circle cx=\"477.82715324815985\" cy=\"41.63500283082744\" r=\"4\" class=\"bean\"/><circle cx=\"478.80294543856763\" cy=\"55.70805989818683\" r=\"4\" class=\"bean\"/><circle cx=\"492.48875443648774\" cy=\"59.12884017357208\" r=\"4\" class=\"bean\"/><circle cx=\"56.45517424060568\" cy=\"129.95764710059083\" r=\"4\" class=\"bean\"/><circle cx=\"41.95764710059085\" cy=\"127.54482575939433\" r=\"4\" class=\"bean\"/><circle cx=\"39.54482575939432\" cy=\"142.04235289940917\" r=\"4\" class=\"bean\"/><circle cx=\"54.04235289940915\" cy=\"144.4551742406057\" r=\"4\" class=\"bean\"/><circle cx=\"139.96611348553515\" cy=\"145.6057245338317\" r=\"4\" class=\"bean\"/><circle cx=\"145.6057245338317\" cy=\"132.03388651446485\" r=\"4\" class=\"bean\"/><circle cx=\"132.03388651446485\" cy=\"126.3942754661683\" r=\"4\" class=\"bean\"/><circle cx=\"126.3942754661683\" cy=\"139.96611348553515\" r=\"4\" class=\"bean\"/><circle cx=\"234.13812102038685\" cy=\"133.71559588163777\" r=\"4\" class=\"bean\"/><circle cx=\"221.71559588163777\" cy=\"125.86187897961315\" r=\"4\" class=\"bean\"/><circle cx=\"213.86187897961315\" cy=\"138.28440411836223\" r=\"4\" class=\"bean\"/><circle cx=\"226.2844041183622\" cy=\"146.13812102038685\" r=\"4\" class=\"bean\"/><circle cx=\"320.8589079531736\" cy=\"130.56679193503535\" r=\"4\" class=\"bean\"/><circle cx=\"306.5667919350353\" cy=\"127.14109204682636\" r=\"4\" class=\"bean\"/><circle cx=\"303.1410920468264\" cy=\"141.43320806496465\" r=\"4\" class=\"bean\"/><circle cx=\"317.4332080649647\" cy=\"144.85890795317363\" r=\"4\" class=\"bean\"/><circle cx=\"496.1175292597307\" cy=\"127.16225601652687\" r=\"4\" class=\"bean\"/><circle cx=\"482.10326048876226\" cy=\"125.54875781848838\" r=\"4\" class=\"bean\"/><circle cx=\"476.2380852995199\" cy=\"138.37852109064235\" r=\"4\" class=\"bean\"/><circle cx=\"486.627476453564\" cy=\"147.92124905848706\" r=\"4\" class=\"bean\"/><circle cx=\"498.9136484984231\" cy=\"140.98921601585533\" r=\"4\" class=\"bean\"/>\n",
       "    </svg>\n",
       "    "
      ],
      "text/plain": [
       "Game(pits=array([4, 4, 4, 4, 0, 5, 5, 5, 5, 4, 4, 4]), current_player=1, captures=array([0, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Game()  # Create a new game\n",
    "g, captures, done = g.step(4)  # play the 5th pit (our implementation starts at 0)\n",
    "g  # Display the resulting board inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=====================\n",
    "Awale and Game Theory\n",
    "====================="
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The notation and most conventions used in this section are taken from :cite:`MaschlerSolanZamir2013`.\n",
    "\n",
    "Basic game theoretic concepts\n",
    "----------------------------\n",
    "\n",
    "The two main representations of games are the strategic form and the extensive form. Since the extensive-form representation is particularly  convenient for describing algorithms playing Awale, we  only present the extensive form. We also restrict this section to zero-sum  two-players finite games.\n",
    "A  *zero-sum two-players finite game in extensive form*  is an ordered vector\n",
    "\n",
    ".. math::\n",
    "  \\Gamma = (N, V, E, x^{0}, (V_{i})_{i \\in N}, O, u),\n",
    "\n",
    "where:\n",
    "\n",
    " * :math:`N= \\{0,1\\}` is the  set of  players,\n",
    " * :math:`x^{0}` is the initial state of the game,\n",
    " * :math:`(V , E, x_{0})` is a  finite tree with root :math:`x^{0}` called the game tree,\n",
    " * :math:`(V_{0}, V_{1})` is a partition of the set of nodes that are not leaves,\n",
    " * :math:`O \\subseteq \\mathbb{R}` is the set of possible game outcomes,\n",
    " * :math:`u` is a function associating every leaf of the tree with a game outcome in the set :math:`O`.\n",
    "\n",
    "An outcome is a description of what happens when the game terminates. For zero-sum games, it is a real number corresponding to the gain of player 0 or, equivalently, the loss of player 1.\n",
    "\n",
    "The set :math:`V_{i}` contains all nodes at which player :math:`i` is to play. In *sequential games*, players take turns.  This implies that a node at depth :math:`i` belongs to :math:`V_{0}` iff :math:`i` is even.\n",
    "\n",
    ".. proof:application::\n",
    "\n",
    "  Awale is a sequential zero-sum game where the  players 0 and 1 are respectively called South and North and :math:`O=\\{+1,-1,0\\}`, respectively  meaning South wins, North wins or draw. Each node represents a state of the game and belongs either to :math:`V_{0}` or :math:`V_{1}`. In the first case, South is to play whereas, in the second one, North is to play. Each node has between 0 and 6 children corresponding to the possible states resulting from the move of the player \"owning\" that node.\n",
    "\n",
    "  For instance, the root :math:`x^{0}` of the game tree (the initial state) belongs to :math:`V_{0}`, meaning South is to play in the initial state (see :numref:`Figure %s <fig:initial_board>`).  The root :math:`x^{0}` has six children corresponding to the six possible states resulting from  South's move. Each of these children belongs to :math:`V_{1}`, meaning North is to play in these six states. Each of these six states at depth 1  in turn has six children corresponding to the six possible states resulting from North's move. We thus have 36 states at depth 2 and they all belong to :math:`V_{0}`, and so on.\n",
    "\n",
    "A *perfect information* game is such that that every player who is to take an action knows the current state of the game, meaning that he knows all the actions in the game that led to the current point in the play. This is not the case if, for instance, the players have cards and hide them as in poker.\n",
    "\n",
    ".. proof:application::\n",
    "\n",
    "  It is easy to see that Awale is a perfect information game.\n",
    "\n",
    "\n",
    "Let us define a mapping :math:`A` associating to each node `x` of a game tree the set :math:`A(x)` of its children.  A *strategy* for player :math:`i` is a function :math:`s_{i}` mapping each node :math:`x \\in V_{i}` to an element in :math:`A(x)`. In other words, a strategy for player :math:`i` tells us what player :math:`i` is going to play at each node of the tree where he is to play. The set of all possible strategies for player :math:`i` is denoted by :math:`S_{i}`.\n",
    "A *strategy vector* is a pair of strategies :math:`s = (s_{0}, s_{1} )`, one for each player. Notice that a strategy vector completely specifies a path in the game tree down to a leaf. A strategy vector :math:`s` therefore identifies a single outcome and :math:`u(s)` can be used to denote that outcome.\n",
    "\n",
    ".. proof:application::\n",
    "\n",
    "  In the case of Awale, for any :math:`x`, :math:`A(x)` contains at most six nodes.\n",
    "\n",
    "When the only outcomes of a two-player game are \"player 0 wins\", \"player 1 wins\" and \"draw\", \n",
    "it is convenient to code these outcomes by :math:`+1, -1` and :math:`0` respectively, as we did higher for Awale.\n",
    "A *winning strategy for player 0*  is then defined as a strategy :math:`(s_{0},s_{1})`\n",
    "such that :math:`u(s_{0},s_{1}) = 1`  for all :math:`s_{1} \\in S_{1}`. A strategy :math:`s_{0}` of\n",
    "player 0 is called a strategy guaranteeing at least a draw if\n",
    ":math:`u(s_{0}, s_{1}) \\in \\{0, 1\\}`, for all :math:`s_{1} \\in S_{1}`.\n",
    "Similar definitions hold  for player 1.\n",
    "We can now state an important result due to the founder of game theory.\n",
    "\n",
    ".. _theo:vonNeumann:\n",
    "\n",
    ".. proof:theorem:: :cite:`vonNeumann1928`\n",
    "\n",
    "   In every two-player extensive form game with perfect information in which the set of outcomes is  :math:`\\{-1, 0, +1\\}`, one and only one of the following three alternatives holds:\n",
    "\n",
    "   1. Player 0 has a winning strategy.\n",
    "   2. Player 1 has a winning strategy.\n",
    "   3. Each of the two players has a strategy guaranteeing at least a draw.\n",
    "\n",
    ".. proof:application::\n",
    "\n",
    "  This theorem obviously applies to Awale but the game tree of Awale is so large that it is very difficult which of the three statements is correct. This question has been solved only in 2003 (see Section XXXX Analyse retrograde).\n",
    "\n",
    "If player 0 chooses strategy :math:`s_{0}`, he gets :math:`u(s_{0},s_{1})`, depending on the strategy :math:`s_{1}` chosen by player 1. In the worst case, player 0 gets :math:`\\min_{s_{1} \\in S_{1}} u(s_{0},s_{1})`. If player 0 wants to play safe, he better chooses a strategy maximizing :math:`\\min_{s_{1} \\in S_{1}} u(s_{0},s_{1})`.\n",
    "Hence the *security level  of a game for player 0* is defined by\n",
    "\n",
    ".. math::\n",
    "\n",
    "  \\underline{v} = \\max_{s_{0} \\in S_{0}} \\min_{s_{1} \\in S_{1}} u(s_{0},s_{1}).\n",
    "\n",
    "It is also called the *maximin value* of the game.\n",
    "This is the payoff player 0 can  guarantee for himself, whatever the other player does.\n",
    "A strategy :math:`s^{*}_{0} \\in S_{0}` is a *maximin strategy*  if :math:`u(s^{*}_{0},s_{1}) \\geq\n",
    "\\underline{v}_{0}` for all :math:`s_{1} \\in S_{1}`. A maximin strategy needs not be unique.\n",
    "\n",
    "We can also define the *minimax value* of a game as\n",
    "\n",
    ".. math::\n",
    "  \\overline{v} = \\min_{s_{1} \\in S_{1}} \\max_{s_{0} \\in S_{0}} u(s_{0},s_{1}).\n",
    "\n",
    "Player 1 can guarantee that he will pay no more than :math:`\\overline{v}`.  A strategy of Player 1 that guarantees :math:`\\overline{v}` is called a minimax strategy. The maximin strategy of player 0 and the minimax strategy of player 1 are called *optimal strategies*.\n",
    "Since we consider zero-sum games, a payment made by player 1 is a gain for player 0 and player 0 is guaranteed to receive no more than :math:`\\overline{v}` (if player 1 plays his minimax strategy). Hence, if  players 0 and 1 respectively play their maximin and minimax strategies, the gain of player 0 is at least :math:`\\underline{v}` and at most :math:`\\overline{v}`. It follows that :math:`\\underline{v} \\leq \\overline{v}`.\n",
    "\n",
    "If :math:`\\underline{v} = \\overline{v}`, then we say *the game has a value* and :math:`\\underline{v}=\\overline{v}` is called the *value of the game*,  simply denoted by :math:`v`. The value of the game represents the gain of player 0 (or the loss of player 1). Any of the  maximin and minimax strategies of players 0 and 1 respectively are then called *optimal strategies*.\n",
    "Calculating the value of a game (when it exists), is called *solving the game*. it can be done by computing the maximin value or the minimax value (because they are equal).\n",
    "\n",
    "Consider  a finite two-players zero-sum game with perfect information with :math:`O=\\{-1, 0, +1\\}`  and let us apply :numref:`theo:vonNeumann`.  There are three cases.\n",
    "\n",
    " 1. If player 0 has a winning strategy, then :math:`\\underline{v}=1` and by the zero-sum property, :math:`\\underline{v}=1`. Whence the game has a value and it is 1.\n",
    " 2. If player 1 has a winning strategy, then :math:`\\underline{v}=-1` and by the zero-sum property, :math:`\\underline{v}=-1`. Whence the game has a value and it is -1.\n",
    " 3. If each of the two players has a strategy guaranteeing at least a draw, then each of them  plays such a strategy and the outcome of the game is a draw. So, :math:`\\underline{v}=0` and  :math:`\\underline{v}=0`. Whence anew the game has a value and it is 0.\n",
    "\n",
    "We have just proved the following:\n",
    "\n",
    ".. _theo:value:\n",
    "\n",
    ".. proof:theorem::\n",
    "\n",
    "  Every finite two-player zero-sum extensive-form game with perfect information and with :math:`O=\\{-1, 0, +1\\}` has a value.\n",
    "\n",
    "This is a special case of Theorem 4.43 in :cite:`MaschlerSolanZamir2013`.\n",
    "\n",
    ".. proof:application::\n",
    "\n",
    "  Awale has a value :math:`v` and it belongs to :math:`\\{-1, 0, +1\\}`. It is therefore possible  to solve Awale (see Section 4.3 XXXXX, passage \\`a propos de Romein 2003).\n",
    "  When both players play their optimal strategy, South wins :math:`v` and North pays :math:`v`. If a player has a winning strategy, then it is also an optimal strategy. Any maximin strategy is an optimal policy.\n",
    "\n",
    "Let us consider a game :math:`\\Gamma` with game tree :math:`(V,E,x^{0})`.\n",
    "Given a node :math:`x \\in V`, we may consider the subtree with root :math:`x`, which is  obtained by removing all nodes of :math:`V` that are not descendants of :math:`x`. The partition :math:`(V_{0},V_{1})` of the original game :math:`\\Gamma` naturally defines a partition of the nodes of the subtree. Similarly, the function :math:`u` of the original game naturally associates every leaf of the subtree to a game outcome. Therefore,\n",
    "the subtree of the game tree, which we will denote by :math:`\\Gamma(x)`, corresponds to a game that is called the subgame beginning at :math:`x`.\n",
    "\n",
    ".. proof:application::\n",
    "\n",
    "  Every subgame of Awale is a finite two-player zero-sum extensive-form game with perfect information and we can therefore appeal to Theorem :numref:`theo:value`. So, for every node :math:`x \\in V`, the subgame :math:`\\Gamma(x)` has a value, which is equal to the maximin value and the minimax value. It is also called the value of node :math:`x`, denoted :math:`v(x)`. It represents the gain of player 0 if, starting from node :math:`x`, both players play their optimal strategy, i.e.\\  maximin for player 0 and minimax for player 1.\n",
    "\n",
    "  Example. Suppose North has two seeds in pit  6' while South has one seed in pit 2 and one in 4 (see :numref:`Figure %s <fig:game>`).\n",
    "  Suppose also both South and North have  captured 22 seeds. Suppose finally  South is to play. If South plays 2, then North plays 6' and has no more seeds in his half board. The game ends with a draw because no player has captured more seeds than the other. If, on the contrary, South plays 4, then North plays 6', captures two seeds in pit 2 and has no more seeds in his half board.  The game ends with a win for North because he has captured more seeds than South. This subgame tree is represented in :numref:`Figure %s <fig:tree>`. The optimal strategy for South is obviously to play 2 whereas the optimal strategy for North is the only available strategy, that is playing 6'. If both players apply their optimal strategy, the outcome is a draw and the value of the game is 0.\n",
    "\n",
    "    \n",
    ".. _fig:game:\n",
    "    \n",
    ".. figure:: game.pdf\n",
    "\n",
    "  An nearly final position of Awale\n",
    "\n",
    "    \n",
    ".. _fig:tree:\n",
    "    \n",
    ".. figure:: tree.pdf\n",
    "\n",
    "  The subgame tree corresponding to the position depicted in :numref:`Figure %s <fig:game>`.\n",
    "\n",
    "\n",
    "\n",
    "The minimax tree of a game with game tree :math:`(V,E,x^{0})` is the 4-tuple :math:`(V,E,x^{0},m)` where :math:`m:V\\to \\mathbb{R}` associates to each node its minimax value.\n",
    "\n",
    ".. proof:application::\n",
    "\n",
    "  By Theorem :numref:`theo:value`, the minimax value of an Awale subgame is equal to the value of the subgame. The minimax tree can thus be used to find the optimal strategies.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Implementation of the tree representation\n",
    "-----------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "We now implement this tree representation in Python by inheriting from :code:`Game()` class previously defined so that a state can hold references to its parent and children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Optional, List\n",
    "from weakref import ref, ReferenceType\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TreeGame(Game):\n",
    "    # Hold an optional reference to the parent state\n",
    "    parent: Optional[ReferenceType[Game]] = None\n",
    "    # Hold a list of 6 optional references to the children\n",
    "    children: List[Optional[Game]] = field(default_factory=lambda: [None] * 6)\n",
    "    depth: int = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Next, we overload the ``Game.step(i)`` method so that we do not compute twice state if it was already in the tree. If a new node was generated, we keep a reference to the parent when we create a new child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeGame(TreeGame):\n",
    "    ...\n",
    "\n",
    "    def step(self, action):\n",
    "        # If we already did compute the children node, just return it\n",
    "        if self.children[action] is not None:\n",
    "            new_game = self.children[action]\n",
    "            captures = (\n",
    "                new_game.captures[self.current_player]\n",
    "                - self.captures[self.current_player]\n",
    "            )\n",
    "            return new_game, captures, new_game.game_finished\n",
    "        # If not, call the original `step()` method and keep references in both directions\n",
    "        else:\n",
    "            new_game, captures, finished = super().step(action)\n",
    "            new_game.parent = ref(self)\n",
    "            new_game.depth = self.depth + 1\n",
    "            self.children[action] = new_game\n",
    "            return new_game, captures, finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class TreeGame(TreeGame):\n",
    "    ...\n",
    "\n",
    "    @property\n",
    "    def successors(self):\n",
    "        children = [x for x in self.children if x is not None]\n",
    "        successors = children + list(itertools.chain(*[x.successors for x in children]))\n",
    "        return successors\n",
    "\n",
    "    @property\n",
    "    def unvisited_actions(self):\n",
    "        return [i for i, x in enumerate(self.children) if x is None]\n",
    "\n",
    "    @property\n",
    "    def legal_unvisited_actions(self):\n",
    "        return list(set(self.unvisited_actions).intersection(set(self.legal_actions)))\n",
    "\n",
    "    @property\n",
    "    def expanded_children(self):\n",
    "        return [x for x in self.children if x is not None]\n",
    "\n",
    "    @property\n",
    "    def is_fully_expanded(self):\n",
    "        legal_actions = set(self.legal_actions)\n",
    "        unvisited_actions = set(self.unvisited_actions)\n",
    "        return len(legal_actions.intersection(unvisited_actions)) == 0\n",
    "\n",
    "    @property\n",
    "    def is_leaf_game(self):\n",
    "        return self.children == [None] * 6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "================================================\n",
    "Artificial Intelligence approaches to play Awale\n",
    "================================================\n",
    "\n",
    "Many algorithms have been proposed and studied to play sequential perfect information games.\n",
    "We start by describing simple algorithms to be used as a baseline (random and greedy). Then follow with algorithms computing the exact minimax tree, either starting from the root (:math:`\\alpha\\beta` pruning Minimax) or the leaves (retrograde analysis). As those are often impractical for big game trees, we present their depth-limited variants (depth-limited minimax and end-game databases). We then explore approaches that overcome the limitation of the previous algorithms by iteratively estimating the value of promising sub-trees of the game such as Monte Carlo tree search (MCTS) and the most recent approach from Deepmind: Alpha Zero :cite:`AlphaZero`.\n",
    "\n",
    "We will quickly present and implement the above-mentioned and then focus on MCTS and its variants as they are computationally feasible and do not require expert knowledge about the given game to make reasonable decisions."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Before presenting those, we describe a :code:`Player` class that every implementation will then reuse and implement two basic agents to be used as a baseline in our comparisons.\n",
    "The :code:`Player` class keeps track of the game state internally.\n",
    "At each turn of the game, the :code:`Player` is called with the method :code:`play()` to inform it of the action played by their opponent\n",
    "(and thus update their internal state) and then chooses an action with :code:`get_action()`,\n",
    "updates once more their internal state and then outputs their action for the opposing :code:`Player` to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def play(self, their_action):\n",
    "        # If we are the first player, there is no previous action\n",
    "        if their_action != -1:\n",
    "            # Play the opponent's move\n",
    "            self.root, _, _ = self.root.step(their_action)\n",
    "        else:\n",
    "            assert self.player_id == 0, \"Only the first player can have their_action=-1\"\n",
    "        \n",
    "        action = self.get_action()\n",
    "        self.root, _, _ = self.root.step(action)\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Naive agents\n",
    "------------\n",
    "\n",
    "In addition to the above-listed algorithms, we also implement two most basic agents: a random and a greedy player.\n",
    "While not having any interest per se due to their simplicity and low strength, these will serve us later as a baseline to compare their strength to some more advanced algorithms.\n",
    "\n",
    "The first agent is the most simple we can think of and does not use any intelligence at all: it lists all the legal actions it can play and chooses one uniformly at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer(Player):\n",
    "    def __init__(self, player_id):\n",
    "        self.root = Game()\n",
    "        self.player_id = player_id\n",
    "    \n",
    "    def get_action(self):\n",
    "        return random.choice(self.root.legal_actions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The second is :math:`\\varepsilon`-Greedy: an agent that tries to maximize an immediate reward at each turn: the number of seeds captured during that turn.\n",
    "The :math:`\\varepsilon \\in [0, 1]` parameter introduces randomness: at each turn, the agent draws a number :math:`e` in the uniform distribution :math:`\\mathcal{U}(0, 1)`, if :math:`e > \\varepsilon`, the agent chooses an action uniformly at random, else it maximizes the immediate reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyPlayer(Player):\n",
    "    def __init__(self, player_id, eps=0):\n",
    "        self.root = Game()\n",
    "        self.player_id = player_id\n",
    "        self.eps = eps\n",
    "    \n",
    "    def get_action(self):\n",
    "        # Choose a move\n",
    "        children = []\n",
    "        \n",
    "        for legal_action in self.root.legal_actions:\n",
    "            new_state, captures, finished = self.root.step(legal_action)\n",
    "            if new_state.winner is None:\n",
    "                win = 0\n",
    "            elif new_state.winner == self.player_id:\n",
    "                win = 1\n",
    "            else:\n",
    "                win = -1\n",
    "            children.append((legal_action, captures, win))\n",
    "        \n",
    "        # order wins first, then by captures, then random\n",
    "        sorted_children = sorted(children, key=lambda c: (-c[2], -c[1], random.random()))\n",
    "        if random.random() < self.eps:\n",
    "            action = random.choice(self.root.legal_actions)\n",
    "        else:\n",
    "            action = sorted_children[0][0]\n",
    "            \n",
    "        return action"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Depth-limited Minimax\n",
    "---------------------\n",
    "\n",
    "The minimax algorithm performs a complete depth-first search used to compute the minimax tree.\n",
    "It is a recursive algorithm that computes the value of a node based on the value of its children. In the case of a terminal node, the value is trivial to compute and depends solely on the winner. Otherwise, for \"inner\" (non-terminal) nodes, the value is computed as the max (resp. min) of the value of the children if the node is at an even (resp. odd) depth.\n",
    "\n",
    "In Awale and other complex games, as shown before, generating the whole tree is computationally very hard and not practical. :cite:`Shannon1988` proposed an adaptation of the minimax where instead of generating the whole tree, it is generated up to depth :math:`d`. Nodes at depth :math:`d` are then considered as leaves and their value are estimated using an heuristic instead of being computed by recursively computing the values of their children. \n",
    "\n",
    "The heuristic used should estimate the value of the node only by inspecting the state of the game and can be of varying complexity. A simple approach as taken here is to count the difference of the number of seeds each player has captured. Because heuristics are most often crafted by hand using human knowledge of the game, exploring more complex ones is beyond the scope of this work.\n",
    "\n",
    "The complexity of the depth-limited minimax algorithm is :math:`O(b^d)` (TODO ref) where :math:`b` is the average branching factor. A well known optimization of this algorithm called alpha-beta pruning minimax (TODO source) (:math:`\\alpha\\beta` minimax) returns the same result and has an average performance of :math:`O(\\sqrt{b^d})`. \n",
    "The algorithm keeps track of two values, :math:`\\alpha` and :math:`\\beta`, which hold the minimum score that the maximizing player is assured of and the maximum score that the minimizing player is assured of.\n",
    "Initially, :math:`\\alpha = -\\infty` and :math:`\\beta = +\\infty`: both players begin with their worst possible score.\n",
    "If the maximum score that the minimizing player is assured of becomes less than the minimum score that the maximizing player is assured of (so :math:`\\beta < \\alpha`), the maximizing player does not need to consider further children of this node (it prunes the node) as they are certain that the minimizing player would never play this move.\n",
    "This pruning of entire sub-trees is where the complexity gain arises from. \n",
    "As :math:`\\alpha\\beta` minimax has no disadvantage over minimax and has a lower computational complexity, this is the one we implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaBetaMinimaxPlayer(Player):\n",
    "    def __init__(self, player_id, cutoff_depth):\n",
    "        self.root = Game()\n",
    "        self.player_id = player_id\n",
    "        self.cutoff_depth = cutoff_depth\n",
    "    \n",
    "    def get_action(self):\n",
    "        actions = self.root.legal_actions\n",
    "        values = []\n",
    "        for action in actions:\n",
    "            child, _, _ = self.root.step(action)\n",
    "            value = self.minimax(child, self.cutoff_depth, float(\"-inf\"), float(\"+inf\"), False)\n",
    "            values.append(value)\n",
    "        best_action, best_value = max_rand(list(zip(actions, values)), key=lambda x: x[1])\n",
    "        \n",
    "        return best_action\n",
    "        \n",
    "        \n",
    "    def minimax(self, node, depth, alpha, beta, is_maximizing):\n",
    "        if depth == 0 or node.game_finished:\n",
    "            return self.evaluate(node)\n",
    "        \n",
    "        if is_maximizing:\n",
    "            value = float(\"-inf\")\n",
    "            for action in node.legal_actions:\n",
    "                child, _, _ = node.step(action)\n",
    "                value = max(value, self.minimax(child, depth - 1, alpha, beta, False))\n",
    "                alpha = max(alpha, value)\n",
    "                if alpha >= beta:\n",
    "                    break\n",
    "            return value\n",
    "        else:\n",
    "            value = float(\"+inf\")\n",
    "            for action in node.legal_actions:\n",
    "                child, _, _ = node.step(action)\n",
    "                value = min(value, self.minimax(child, depth - 1, alpha, beta, True))\n",
    "                beta = min(beta, value)\n",
    "                if alpha >= beta:\n",
    "                    break\n",
    "            return value\n",
    "        \n",
    "    def evaluate(self, node):\n",
    "        return node.captures[self.player_id] - node.captures[1 - self.player_id]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Retrograde analysis\n",
    "-------------------\n",
    "\n",
    "Board games can mostly be divided into two separate categories. The first category consist\n",
    "of games where the number of pieces on the board increases over time, because players add pieces on the board during their turn. The state space increases over time: these are called divergent games.\n",
    "Examples of these games are Tick Tack Toe, Connect Four and Go.\n",
    "The second category consists of games where the number of pieces on the board decreases over time because players may capture pieces over time. Those are called convergent games.\n",
    "Games that belong to this category are Chess, Checkers, Backgammon and Awale :cite:`vandenherik2002`.\n",
    "\n",
    "For both divergent and convergent games, search algorithms can compute the game value for positions near\n",
    "the end of a game. However, for divergent games the number of endgame\n",
    "positions is so big that enumerating them all is computationally impossible (except for trivial\n",
    "games like Tic-Tac-Toe). However, for convergent games, the number of positions\n",
    "near the end of the game is small. Usually small enough to traverse them all, and collect\n",
    "their game values in a database, a so called endgame database.\n",
    "\n",
    "Retrograde Analysis computes endgame databases by going backward from values of final\n",
    "positions towards the initial position :cite:`goot2001`.\n",
    "First, Retrograde Analysis identifies all final positions in which the game value is known.\n",
    "By making reverse moves from these final positions the game value of some non-final positions can be deduced. And by making reverse moves from these newly computed non-final positions, the game value of other non-final positions can be deduced. This can continue either by running of available memory or by having enumerated all the legal positions in the game.\n",
    "\n",
    "Ströhlein is the first researcher who came up with the idea to create endgame databases and applied his idea to chess :cite:`endgame1970`.\n",
    "The first endgame database for Awale has been created by :cite:`allis1995` and was followed by many others, while the quest was ended by :cite:`romein2003solving` publishing a database for all legal positions.\n",
    "\n",
    "The above-mentioned results for Kalah and Awale both use an almost brute-force\n",
    "method to solve the game and use a database of all possible states. The database\n",
    "used by :cite:`romein2003solving` has 204 billion entries and weighs 178GiB.\n",
    "Such a huge database is of course not practical and we thus think there is still room for\n",
    "improvement if we can create an agent with a policy that does not need a\n",
    "exhaustive database, even if the agent is not capable of a perfect play.\n",
    "\n",
    "\n",
    "Monte Carlo Tree Search\n",
    "-----------------------\n",
    "\n",
    "Monte Carlo Tree Search (MCTS) has been introduced by :cite:`coulom2006mcts` as a formalization of Monte Carlo methods applied to tree search that were previously explored by others, among which :cite:`Bouzy2004montecarlo`. Since then, MCTS has been a major advancement and topic of interest in the field of AI research, particularly for games and planning problems.\n",
    "\n",
    "\n",
    "--cc-- The focus of MCTS is on the analysis of the most promising moves, expanding the search tree based on random sampling of the game space. The application of Monte Carlo tree search in games is based on many playouts, also called roll-outs. In each playout, the game is played out to the very end by selecting moves at random. The final game result of each playout is then used to weight the nodes in the game tree so that better nodes are more likely to be chosen in future playouts.\n",
    "\n",
    "--cc-- The most basic way to use playouts is to apply the same number of playouts after each legal move of the current player, then choose the move which led to the most victories.[10] The efficiency of this method—called Pure Monte Carlo Game Search—often increases with time as more playouts are assigned to the moves that have frequently resulted in the current player's victory according to previous playouts. Each round of Monte Carlo tree search consists of four steps:[35]\n",
    "\n",
    "\n",
    "--cc-- A tree is built in an incremental and asymmetric manner.\n",
    "For each iteration of the algorithm, a tree policy is used to find the most urgent node of the current tree.\n",
    "The tree policy attempts to balance considerations of exploration (look in areas that have not been well sampled yet) and exploitation (look in areas which appear to be promising).\n",
    "\n",
    "--cc-- A simulation is then run from the selected node and the search tree updated according to the result.\n",
    "This involves the addition of a child node corresponding to the action taken from the selected node, and an update of the statistics of its ancestors.\n",
    "Moves are made during this simulation according to some default policy, which in the simplest case is to make uniform random moves.\n",
    "\n",
    "TODO The MCTS algorithm constructs an estimation of the game tree by sampling. \n",
    "\n",
    "A great benefit of MCTS is that unlike depth-limited minimax, MCTS is aheuristic: there is no need to estimate the values of non-terminal nodes with an domain specific heuristic. This in turn, greatly reduces (or even removes) the need to acquire and incorporate domain knowledge. This explains our interest on the subject and the title of this work.\n",
    "\n",
    "\n",
    "\n",
    "Algorithm\n",
    "~~~~~~~~~\n",
    "\n",
    ".. figure:: _static/mcts-algorithm.svg\n",
    "\n",
    "   The 4 steps of MCTS :cite:`chaslot2008monte`\n",
    "\n",
    "The estimation of the true game tree is constructed with the following algorithm: The estimation starts with a single node, the current state of the game. Then these four steps are repeated until the budget (usually a time or memory constraint) is exhausted. \n",
    "\n",
    "* Selection: first, a node from the estimated tree is selected by starting at the root node and repeatedly\n",
    "  choosing (using a tree policy, defined later) a child until a leaf :math:`L` is reached.\n",
    "* Expansion: then, if :math:`L` is not a terminal node, create a child :math:`C` by playing a move at random.\n",
    "* Simulation: run a playout from :math:`C` until a terminal node :math:`T` is\n",
    "  reached (play a full game)\n",
    "* Back-propagation: update the counters described below of each ancestor\n",
    "  of :math:`T`.\n",
    "\n",
    "\n",
    "Each node :math:`x` holds 3 counters : :math:`N_x` (the number of simulation that went through :math:`x`),:math:`W^S_x` and :math:`W^N_x` (the number of simulations going through :math:`x` and leading to a win respectively for South and North). From these counters, a probability of North winning can be estimated by :math:`\\frac{W^N_x}{N_x}` if both players play randomly from :math:`x`. TODO: \n",
    "\n",
    "TODO This sampling can be ran as many times as allowed (most of the\n",
    "time, the agent is time constrained). One can also stop the sampling earlier if\n",
    "\n",
    "TODO each time refining the probability of\n",
    "winning when choosing a child of the root node. When we are done sampling, the\n",
    "agent chooses the child with the highest probability of winning and plays the\n",
    "corresponding action in the game.\n",
    "\n",
    "TODO the total number of times a node has been played during a\n",
    "sampling iteration (:math:`N_x`)\n",
    "\n",
    "TODO Every game are played at full random so the estimated value of a node (wins - losses / total_games) will converge to the mean of the value of all possible children games. A lot of early implementations of MCTS were trying to be clever by pruning some branches or choose more often promising moves. We intentionally choose at full random so we can compare it later to UCT that chooses in a formalized way with no domain knowledge and is proven to converge to minimax.\n",
    "\n",
    "We can show that this simple MCTS method is better than a random agent.\n",
    "\n",
    "We can show that estimated value :math:`\\hat{v_x}: (W^S_x- W^N_x)/N_x` of node :math:`x` when :math:`N_x` is big converges to a weighted average of the true value of the leaves of the subtree where :math:`x` is the root.\n",
    "For every leaf :math:`l`, :math:`\\hat{v_l} = v_l` if :math:`N_l > 0`. For every other node, :math:`\\lim_{N_{X} \\to\\infty} \\hat{v_x} = \\sum_{x' \\in A(x)} \\hat{v_{x'}} / |A(x)|`. Donc pour un noeud qui n'a que des feuilles, sa valeur estimée est la moyenne des vraies valeurs des feuilles. Pour un autre noeud, sa valeur estimée sera la moyenne pondérée (en fct de la topologie du ss arbre) des v des feuilles du ss arbre \n",
    "\n",
    "SI tu pars de x0 et que tu joues un coup de MCTS en manximisant l'espérence de gain sous l'hypothèse que les coups suivants sont joués au hasard. Tu es meilleur que le harad car il fait soit pire, soit aussi bien.\n",
    "C'est vrai pour tout jeu. Et comme chaque sous jeu est un jeu, c'est vrai à chaque itération.\n",
    "\n",
    "Des gens ont aessayé de biaiser en diminuant l'importance des choxi que tu ne prendras jamais. \n",
    "\n",
    "Kocis a réussi à suffisament biaiser pour ne plus jamais prendre les choix sub-optimaux et du coup ça converge vers le minimax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Implementation\n",
    "~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First, we subclass :code:`TreeGame` so in addition to holding the game state, each node also hold three counters needed for MCTS and its variants: the amount of simulations this node was used into and the amount of those simulations that resulted in a win for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TreeStatsGame(TreeGame):\n",
    "    wins: np.array = field(default_factory=lambda: np.zeros(2, dtype=int))\n",
    "    n_playouts: int = 0\n",
    "\n",
    "    def update_stats(self, winner):\n",
    "        if winner in [0, 1]:\n",
    "            self.wins[winner] += 1\n",
    "        self.n_playouts += 1\n",
    "        if self.parent and self.parent():\n",
    "            self.parent().update_stats(winner)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The MCTS first chooses a node to expand with the `tree_policy()` when the node is found, it is expanded with the `default_policy()`. When reaching a terminal node, the counters are updated. This is repeated `BUDGET` times and then the final action is chosen as the action that has the highest mean of game values (game value is 1 for wins, 0 for draws, -1 for losses).\n",
    "\n",
    "Both policies in this implementation are random walks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSPlayer(Player):\n",
    "    def __init__(self, player_id, budget: timedelta):\n",
    "        self.root = TreeStatsGame()\n",
    "        self.player_id = player_id\n",
    "        self.budget = budget\n",
    "\n",
    "    def tree_policy(self, node):\n",
    "        while not node.is_leaf_game:\n",
    "            if node.is_fully_expanded:\n",
    "                node = random.choice(node.expanded_children)\n",
    "            else:\n",
    "                action = random.choice(node.legal_unvisited_actions)\n",
    "                node, _, _ = node.step(action)\n",
    "        return node\n",
    "    \n",
    "    def explore_tree(self):\n",
    "        # Choose a starting node\n",
    "        node = self.tree_policy(self.root)\n",
    "\n",
    "        # Run a simulation on that node\n",
    "        finished = node.game_finished\n",
    "        while not finished:\n",
    "            action = self.default_policy(node)\n",
    "            node, _, finished = node.step(action)\n",
    "\n",
    "        # Backtrack stats\n",
    "        node.update_stats(node.winner)\n",
    "    \n",
    "    def default_policy(self, node):\n",
    "        # Random walk\n",
    "        return random.choice(node.legal_actions)\n",
    "    \n",
    "    def action_score(self, x):\n",
    "        node = self.root.children[x]\n",
    "        if node is None:\n",
    "            return float(\"-inf\")\n",
    "\n",
    "        return (node.wins[self.player_id] - node.wins[1 - self.player_id]) / node.n_playouts\n",
    "    \n",
    "    def final_selection(self):\n",
    "        return max(self.root.legal_actions, key=self.action_score)\n",
    "        \n",
    "    \n",
    "    def get_action(self):\n",
    "        start = datetime.now()\n",
    "        end = start + self.budget\n",
    "        while datetime.now() < end:\n",
    "            self.explore_tree()\n",
    "        \n",
    "        return self.final_selection()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "================================\n",
    "Monte Carlo tree search variants\n",
    "================================\n",
    "\n",
    "The basic version of MCTS presented above has proven to be effective in a variety of problems. Variants and enhancements to MCTS have been studied extensively and were shown to bring substantial benefits :cite:`browne2012survey`. In this section, we present a few of them and apply them to Awale.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Upper Confidence Bounds for Trees\n",
    "---------------------------------\n",
    "\n",
    "Because basic MCTS samples uniformly the game tree, it spends compute time estimating the value of uninteresting nodes that will never be played in a real game. A more efficient method would instead explore more often the interesting parts of the tree: an asymmetric method.\n",
    ":cite:`kocsis2006bandit` defined Upper Confidence Bounds for Trees (UCT), a method combining during the selection process vanilla MCTS and Upper Confidence Bounds (UCB) used in the multi-armed bandit problem.\n",
    "\n",
    "Basic MCTS, during the tree policy, chooses a child at random even if the children is likely of having a poor mean value. UCT instead treats the choice of child as a multi-armed bandit problem: picking a child for which we have an estimation of the true value to make a simulation is analogous to picking a slot machine for which we have an estimation of the true reward probability. \n",
    "\n",
    "TODO When a node has not been visited much, the ratio of wins to visits is an estimation of the mean value of the children. But after a time, UCT prioritizes more the good moves so the value drifts and converges to the game theoretic value (:cite:`kocsis2006bandit`). This means that the bandit is non stationary but this is ok as it does not drift too much.\n",
    "\n",
    "\n",
    "UCT adapts UCB to a game tree and gives us the following formula for the upper confidence bound:\n",
    "\n",
    ".. math::\n",
    "\n",
    "    \\frac{W_1}{N} + c \\times \\sqrt{\\frac{ln N'}{N}},\n",
    "\n",
    "where :math:`N'` is the number of times the\n",
    "parent node has been visited and :math:`c` is a parameter that can be tuned to balance exploitation of known wins and exploration of\n",
    "less visited nodes.\n",
    "\n",
    "The tree policy from MCTS is then replaced by a policy always choosing the node with the highest upper confidence bound, resolving ties by a coin toss.\n",
    ":code:`UCTPlayer` thus reuses the MCTS agent but subclasses the :code:`tree_policy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import max_rand\n",
    "\n",
    "class UCTPlayer(MCTSPlayer):\n",
    "    def __init__(self, player_id, budget: Union[int, timedelta], c: float):\n",
    "        super().__init__(player_id, budget)\n",
    "        self.c = c\n",
    "        \n",
    "    def node_score(self, node):\n",
    "        draws = node.n_playouts - node.wins.sum()\n",
    "        w = node.wins[node.current_opponent] + 0.5 * draws\n",
    "        exporation = w / (node.n_playouts + 1)\n",
    "        exploitation = math.sqrt(math.log(node.parent().n_playouts) / (node.n_playouts + 1))\n",
    "        return exporation + self.c * exploitation\n",
    "\n",
    "    def tree_policy(self, node):\n",
    "        while not node.is_leaf_game:\n",
    "            if node.is_fully_expanded:\n",
    "                node = max_rand(node.expanded_children, key=self.node_score)\n",
    "            else:\n",
    "                action = random.choice(node.legal_unvisited_actions)\n",
    "                node, _, _ = node.step(action)\n",
    "        return node"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Informed UCT\n",
    "------------\n",
    "\n",
    ":code:`GreedyUCTPlayer` subclasses :code:`UCTPlayer` and changes the :code:`default_policy` to weigh more the actions that will give more immediate rewards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyUCTPlayer(UCTPlayer):    \n",
    "    def default_policy(self, node):\n",
    "        # Greedy walk\n",
    "        assert len(node.legal_actions) != 0\n",
    "        captures = [node.step(action)[1] + 1 for action in node.legal_actions]\n",
    "        return random.choices(node.legal_actions, weights=captures)[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "All moves as first\n",
    "------------------\n",
    "\n",
    "\"All Moves As First\" (AMAF) and its successor \"Rapid Action Value Estimation\" (RAVE) are enhancements that have often been proved very successful when applying MCTS to the game of Go :cite:`gelly20111rave`.\n",
    "The basic idea is to update statistics for all actions selected during a simulation as if they were the first action applied. This method is particularly well suited for incremental games such as Go, where the value of a move is often dependent on the state of the board in its close proximity and unaffected by moves played elsewhere on the board. \n",
    "Due to the popularity of AMAF, these methods are mentioned here for completeness but will not be pursued further due to the lack of applicability to Awale where the value of moves are dependent on the whole board and on the advancement of the game."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Alpha Zero\n",
    "----------\n",
    "\n",
    "To replace the random play in the simulation step, :cite:`AlphaGo,AlphaGoZero,AlphaZero` proposes\n",
    "to use a neural network to estimate the value of a\n",
    "game state without having to play it. This can greatly enhance the performance\n",
    "of the algorithm because much less playouts are required."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "======\n",
    "Method\n",
    "======\n",
    "\n",
    "This section describes the statistical framework used to compare two agents and the method used to compare and rank multiple agents. Next, we detail the experimental setup in which the games between agents are played as well as the method used to run the experiments in a massively parallel setup to be able to record enough game to have statistically strong results."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comparing algorithms\n",
    "--------------------\n",
    "\n",
    "\n",
    "How to compare A and B\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Because the outcome of a match between two agents is not deterministic, we can not rely on a single match to ascertain than the winner of a match is better than the looser. So the first step is to define a statistical method to compare two arbitrarily chosen agents: A and B.\n",
    "\n",
    "The probability that A wins is denoted by :math:`p_A`, the probability that B wins is :math:`p_B` and the probability of a draw is :math:`p_d`. All are unknown. Because every game outcome is either A wins, B wins or a draw, :math:`p_A + p_B + p_d = 1`.\n",
    "Our null hypothesis (:math:`H_0`) is that both agents are equally strong (:math:`p_A=p_B`) and the alternative hypothesis is that they are of different strength (:math:`p_A \\neq p_B`).\n",
    "\n",
    "We define :math:`\\pi_A` as :math:`p_A + \\frac{1}{2}\\ p_d` and :math:`\\pi_B` as :math:`p_B + \\frac{1}{2}\\ p_d` and put forward another hypothesis :math:`H'_0: \\pi_A = 0.5`. We then prove with the following that :math:`H_0` and :math:`H'_0` are equivalent. Let us start from :math:`H'_0`:\n",
    "\n",
    ".. figure:: _static/proof-h0.svg\n",
    "  \n",
    "which is our initial hypothesis :math:`H_0`.\n",
    "\n",
    "To compare agents A and B, we run :math:`N` matches and A wins :math:`n_A` times, B :math:`n_B` and there are :math:`n_d` draws.\n",
    "\n",
    "Using the SciPy function :code:`scipy.stats.binom_test`, we then compute the p-value.\n",
    "If it is lower than :math:`5\\%`, we traditionally reject the null hypothesis.\n",
    "This guarantees that, conditional on :math:`H_0` being true, the probability of making an incorrect decision is :math:`5\\%`.\n",
    "But if :math:`H_1` is true, the probability of an incorrect decision is not necessarily :math:`5\\%`: it depends on the number :math:`N` of matches and on the true value of :math:`\\pi_A`.\n",
    "To ensure that the probability of an incorrect decision, conditional on :math:`H_1`, be acceptable, we resort to the concept of statistical power.\n",
    "\n",
    "Suppose the true probability :math:`\\pi_A` is :math:`0.75`. This is very far from the null hypothesis. In that case, we want the probability of choosing :math:`H_1` (not making an incorrect decision) to be high (for instance :math:`95\\%`). This probability is the power and can be computed by means of the R function :code:`powerBinom` implemented in the R package :code:`exactci`. The output of this function is the number :math:`N` of matches needed to achieve the desired power and it is 49. As we always play a even number of matches between two agents (A vs. B and B vs. A), we decide that we need :math:`N=50` matches.\n",
    "\n",
    "Now that we know the number of matches we need to play to be able to ascertain that :math:`H_1` is probable enough, we still need to know how big :math:`n_A` (or :math:`n_B`) needs to win so we may declare :math:`H_1` true. This can be done with the :code:`scipy.stats.binom_test` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "ha"
    ]
   },
   "outputs": [],
   "source": [
    "# This is R code\n",
    "#powerBinom(power = 0.95, p0 = 0.5, p1 = 0.75, sig.level = 0.05, alternative = \"two.sided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If nₐ is at least 32 we can reject H₀' with a p-value of 0.0325\n"
     ]
    }
   ],
   "source": [
    "for value in range(50):\n",
    "    pvalue = scipy.stats.binom_test(value, 50, p=0.5, alternative=\"greater\")\n",
    "    if pvalue < 0.05:\n",
    "        print(\"If nₐ is at least\", value, \"we can reject H₀' with a p-value of\", round(pvalue, 4))\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "With this method, we can then define a strength relation \"is stronger than\", noted :math:`\\succ` over the set of agents where :math:`A \\succ B` if when playing 50 matches between A and B, :math:`n_A + \\frac{1}{2}\\ n_d \\geq 32`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Transitivity of the strength relation\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "We have a method to determine if an agent is stronger than another but we don't have a way to order all our agents regarding to their strength. It could be tempting to use a sorting algorithm to order the agents using the :math:`\\succ` relation but for this to be correct, the relation has to be transitive.\n",
    "\n",
    "In the following mind experiment, we prove that the relation of strength between two agents is not transitive and thus a total order between all possible agents does not exist.\n",
    "\n",
    "Let us define a theoretical algorithm A: if the algorithm plays South, its first move, :math:`s_0(x^0)`, is played uniformly at random. For the subsequent moves as well as all the moves if the algroithm plays North, the moves depend on :math:`s_0(x^0)` in the following manner:\n",
    " * if :math:`s_0(x^0) \\in {1, 2}` play the optimal strategy (noted :math:`+` in the following table)\n",
    " * if :math:`s_0(x^0) \\in {3, 4}` play the worst strategy (noted :math:`-`)\n",
    " * if :math:`s_0(x^0) \\in {5, 6}` play uniformly at random (noted :math:`r`).\n",
    " \n",
    "In a similar fashion, we define the theoretical algorithms B and C with a permutation of the strategies as shown in the table below.\n",
    "\n",
    ".. table:: Moves of the theoretical algorithms A, B and C depending on the first move of the game.\n",
    "\n",
    "  +------------------+-----------+-----------+-----------+\n",
    "  | :math:`s_0(x^0)` | A         | B         | C         |\n",
    "  +------------------+-----------+-----------+-----------+\n",
    "  | 1, 2             | :math:`+` | :math:`r` | :math:`-` |\n",
    "  +------------------+-----------+-----------+-----------+\n",
    "  | 3, 4             | :math:`r` | :math:`-` | :math:`+` |\n",
    "  +------------------+-----------+-----------+-----------+\n",
    "  | 5, 6             | :math:`-` | :math:`+` | :math:`r` |\n",
    "  +------------------+-----------+-----------+-----------+\n",
    "\n",
    "\n",
    "When playing matches between any two of these agents, :math:`s_0(x^0)` will be uniformly distributed between the 6 possible moves. \n",
    "If A and B play a match and :math:`s_0(x^0)` is\n",
    " - 1 or 2 : A plays :math:`+`, B plays :math:`r`. Thus A wins,\n",
    " - 3 or 4: A either wins the game is a draw,\n",
    " - 5 or 6: B wins.\n",
    "\n",
    "A thus wins more than :math:`\\frac{1}{3}` of the matches (up to :math:`\\frac{2}{3}`) whereas B wins exactly :math:`\\frac{1}{3}` of the matches.\n",
    "A wins more matches than B so we can say :math:`A \\succ B`. The same reasoning with B vs. C and C vs. A yields :math:`B \\succ C` and :math:`C \\succ A`. Thus the relation between these 3 theoretical algorithms is not transitive.\n",
    "\n",
    "How to compare more than two agents\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "As described above, transitivity can not be proved in all cases so we can not use a sorting algorithm to order our agents. We thus have to resort to a full tournament where the relation :math:`\\succ` is evaluated between every pair of agent. \n",
    "\n",
    "We have 6 algorithms, each with some continuous or discrete parameters. Even if we restrict every parameter to a small finite set of values (let's say 100), we would still have 600 agents to compare. This would in turn make a tournament of size :math:`600^2` where each evaluation of the relation requires 50 matches. This method would thus require :math:`600^2 * 50 = 18\\,000\\,000` matches. Playing such a big number of matches is hardly feasible so we will resort to a more frugal approach.\n",
    "\n",
    "The approach that we take is to first select, for each algorithm, the parameters that result in the best agent (a champion). This will in turn reduce the number of agents playing in the tournament to 6 and the number of matches to play to :math:`6^2 * 50 = 180`, a much more reasonable number. While this approach reduces drastically the amount of computations needed, it might not be perfect.\n",
    "We have no guarantee that the champion within a family (all agents derived from a single algorithm) is also the best family member against agents from other families. This is a known limitation and verifying this assumption is outside of the scope of this work.  \n",
    "\n",
    "\n",
    "Champion selection\n",
    "~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Let  :math:`A_x` be an algorithm :math:`A` with a continuous parameter :math:`x \\in X` and :math:`f_n(A_{x}, A_{y})`, the number of wins of :math:`A_{x}` against :math:`A_{y}` after :math:`n` matches.\n",
    "We make the assumption that with :math:`n` big enough, :math:`f_n(A_{x}, A_{y})` is smooth for all :math:`x,y \\in X` due to the fact that both agents :math:`A_{x}` and :math:`A_{y}` share the same algorithm. This smoothness property will be empirically confirmed later (see :ref:`sec:eps-tuning` and :ref:`sec:uct-tuning`).\n",
    "\n",
    "\n",
    "So, for :math:`x_1` close to :math:`x_1` and :math:`y_1` close to :math:`y_2`, the value of :math:`f_n(A_{x_1}, A_{y_1})` gives us an indication about the value of :math:`f_n(A_{x_2}, A_{y_2})`.\n",
    "This assumption and the fact that we evaluate :math:`f_n` over a dense sample of the parameter space allows us to compare agents from a single family by playing much less matches than the 50 matches derived from our statistical power analysis.\n",
    "\n",
    "\n",
    "During the champion selection, contrary to the full tournament, we also assume that the strength relation :math:`\\succ` over agents of a family a weaker property than transitivity: :math:`\\forall y \\in X, \\exists x \\neq y, y \\in X` such that :math:`f_{n \\to \\infty}(A_{x}, A_{y}) / n > f_{n \\to \\infty}(A_{y}, A_{x}) / n`: there exists an agent that wins more than half the time against every other agent of its family."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tournament solution\n",
    "~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    ".. todo::\n",
    "  We will use the framework of tournament solutions :cite:`laslier` to analyze the results and eventually find a total order or an overall best agent. This will be done once we have our final results."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Experimental setup\n",
    "------------------\n",
    "\n",
    "A match between two agents is played with the following code, where the variables :code:`player` and :code:`opponent` contain an instance of an agent (a class derived from :code:`Player`).\n",
    "Because most games finish in less than 200 moves, we limit games to 500 moves to avoid playing infinite games. A game that goes over the threshold of 500 moves is considered a draw, regardless of the score of both players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "ha"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell and its output are hidden in the final document\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "player = RandomPlayer(0)\n",
    "opponent = RandomPlayer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game()\n",
    "opponent_action = -1\n",
    "depth = 0\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "while not game.game_finished and depth < 500:\n",
    "    player_action = player.play(opponent_action)\n",
    "    game, captures, finished = game.step(player_action)\n",
    "\n",
    "    player, opponent = opponent, player\n",
    "    opponent_action = player_action\n",
    "    depth += 1\n",
    "\n",
    "duration = round(time.perf_counter() - start, 4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Relevant data from the match can then be recorded in a dictionary like below where:\n",
    " * :code:`duration` is the total duration of the game in seconds,\n",
    " * :code:`depth` is the number of moves played by both agents,\n",
    " * :code:`score` is a tuple of score of South followed by the score of North,\n",
    " * :code:`winner` is :code:`0` if South won, :code:`1` if North won and :code:`None` is the game was a draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration': 0.0099, 'depth': 81, 'score': [25, 10], 'winner': 0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"duration\": duration,\n",
    "    \"depth\": depth,\n",
    "    \"score\": game.captures.tolist(),\n",
    "    \"winner\": game.winner,\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Because the number of matches we expect to play is quite high and a match between two agents might take a few minutes of CPU time, we have to be able to play a big number of run matches in parallel.\n",
    "\n",
    "We used the infrastructure of Amazon Web Services (AWS) to be able to access hundreds of CPU cores at the same time and used AWS Batch to schedule the jobs across the different machines.\n",
    "\n",
    "To this effect, we placed the code to run a match in a standalone Python script that accepts parameters to give to the agents via environment variables and packaged it in a Docker container. When the match is finished, the dictionary showed above is then outputted to the standard output.\n",
    "\n",
    "This Docker container is then used as a template to launch AWS Batch tasks in parallel, their standard output being sent to AWS Cloudwatch to be analyzed later.\n",
    "Each match was in a separate AWS Batch task was allowed 1 vCPU with 500MB of RAM. Those tasks were running on C5 compute optimized EC2 instances [#aws_c5]_. \n",
    "\n",
    "AWS Batch tasks can be launched with the :code:`submit_match()` function, using itself the :code:`submit_aws_job()` utility function defined in Annex XXX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import submit_aws_job\n",
    "\n",
    "def submit_match(a, b, pool, side, timeout=600):\n",
    "    return submit_aws_job(\n",
    "        jobDefinition='run-match',\n",
    "        jobName=pool,\n",
    "        jobQueue='match-queue',\n",
    "        containerOverrides={\n",
    "            'command': [\"python\", \"simulate.py\"],\n",
    "            'environment': [\n",
    "                {'name': 'PLAYER_A', 'value': a % 0},\n",
    "                {'name': 'PLAYER_B', 'value': b % 1},\n",
    "                {'name': 'POOL','value': pool},\n",
    "                {'name': 'SIDE', 'value': str(side)},\n",
    "            ]\n",
    "        },\n",
    "        timeout={'attemptDurationSeconds': timeout},\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Because we can not be sure an agent has the same strength if it is allowed to be the first player as if it is the second to play, each time we play a match between two agents (A and B), we play the match A vs. B and B vs. A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumbit_symmetric_match(a, b, pool, timeout=600):\n",
    "    submit_match(a, b, pool, side=0, timeout=timeout)\n",
    "    submit_match(b, a, pool, side=1, timeout=timeout)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Results of the jobs submitted to AWS Batch can then be found in AWS CloudWatch. They are downloaded with a script available in the Annex XXX and then stored in :code:`source/data/*.jsonl`. These results are then processed and normalized and made available in Pandas DataFrame :cite:`pandas` importable with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "hr"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from lib.results import results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "===========\n",
    "Experiments\n",
    "===========\n",
    "\n",
    "We run our experiments, analyze their results and present a ranking between the different agents.\n",
    "\n",
    "Champion selection\n",
    "------------------\n",
    "\n",
    ".. _sec:eps-tuning:\n",
    "\n",
    ":math:`\\varepsilon`-Greedy\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "The first agent we have to tune is :math:`\\varepsilon`-Greedy and it has one parameter :math:`\\varepsilon` that can vary in the interval :math:`[0, 1]`. As running a match between two :math:`\\varepsilon`-Greedy agents takes less than 100ms, playing thousands of matches is computationally feasible.\n",
    "\n",
    "We thus pick evenly spaced values of :math:`\\varepsilon` in the interval :math:`[0, 1]` and play 50 matches for each pair of values of :math:`\\varepsilon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = np.linspace(0, 1, 21)\n",
    "\n",
    "for i in range(25):\n",
    "    for eps1 in search_space:\n",
    "        for eps2 in search_space:\n",
    "            player = f\"GreedyPlayer(%s, {eps1})\"\n",
    "            opponent = f\"GreedyPlayer(%s, {eps2})\"\n",
    "            sumbit_symmetric_match(player, opponent, \"local-eps-matrix\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The results of these matches is shown in :numref:`Figure %s <fig:eps-matrix>` below in which we can see despite the noise that a higher value of :math:`\\varepsilon` (meaning the agent chooses most often the greedy approach) is stronger than a lower value. Due to the noise in the data despite the high number of games played it is hard to know for sure if :math:`\\varepsilon = 1` is the optimum or if it is a bit lower. We will keep a value of :math:`\\varepsilon = 0.95` for the rest of this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "fig:eps-matrix",
     "hc"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-fe125af09f93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfolded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fold' is not defined"
     ]
    }
   ],
   "source": [
    "eps = results[results.pool == 'local-eps-matrix'].copy()\n",
    "\n",
    "eps['player_eps'] = eps.player_eval.apply(lambda x: x.args[1])\n",
    "eps['opponent_eps'] = eps.opponent_eval.apply(lambda x: x.args[1])\n",
    "\n",
    "grouped = eps.groupby(['player_eps', 'opponent_eps']).winner.agg(['mean', 'count'])\n",
    "\n",
    "im = grouped.drop('count', axis=1).unstack()\n",
    "folded = fold(im.values)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "ax1 = plt.gca()\n",
    "ax1.set_title(\"Win ratios of greedy agents for multiple values of $\\epsilon$\")\n",
    "ax1.tick_params(axis='both', direction='out')\n",
    "\n",
    "ax1.set_xticks(range(len(im.columns)))\n",
    "ax1.set_xticklabels([round(x[1], 2) for x in im.columns])\n",
    "ax1.set_yticks(range(len(im.index)))\n",
    "ax1.set_yticklabels([round(x, 2) for x in im.index])\n",
    "\n",
    "ax1.set_xlabel(\"$\\epsilon$ of the column player\")\n",
    "ax1.set_ylabel(\"$\\epsilon$ of the row player\")\n",
    "\n",
    "img = ax1.imshow(folded , origin='lower')\n",
    "\n",
    "cbar = fig.colorbar(img)\n",
    "cbar.set_label('Ratio of win of the row player', rotation=270)\n",
    "cbar.ax.get_yaxis().labelpad = 15"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Heatmap of the win ratio of the row player against the column player."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _sec:mcts-tuning:\n",
    "\n",
    "MCTS\n",
    "~~~~\n",
    "\n",
    "The MCTS agent has a parameter :math:`t` that states how much time the agent may spend on simulation during its turn.\n",
    "As :cite:`kocsis2006bandit` have shown that given enough time MCTS (TODO UTC converges, not MCTS) converges to the minimax tree and thus is optimal, we know that the higher is :math:`t`, the better the agent will be. However, since we are constrained by the capacity of our computation resources, we have to choose a reasonable value of :math:`t`.\n",
    "\n",
    "Given our objective of producing an agent capable of playing against a human, choosing a value of :math:`t` higher than 1 minute is unrealistic as the human will not want to wait more than that at each turn of the game. While 1 minute is an upper bound, having a much smaller waiting time at each turn would be valuable. We think that  :math:`t = 5s` is a reasonable value.\n",
    "\n",
    "As stated earlier, we know that the strength of the agent is an increasing function of :math:`t`. However, we don't know the shape of this function. We compare the strength of MCTS(:math:`t=5`) against a range of values of :math:`t' \\in \\{0.5, 1, 1.5, 2, 3, 5, 7, 10, 15, 20, 30, 40\\}` by playing 10 matches for each value of :math:`t'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [0.5, 1, 1.5, 2, 3, 5, 7, 10, 15, 20, 30, 40]\n",
    "\n",
    "for i in range(5):\n",
    "    for time in search_space:\n",
    "            player = \"MCTSPlayer(%s, td(seconds=5))\"\n",
    "            opponent = f\"MCTSPlayer(%s, td(seconds={time}))\"\n",
    "\n",
    "            sumbit_symmetric_match(player, opponent, \"mcts-5s-time-compare\", timeout=60*100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "While the results shown in in :numref:`Figure %s <fig:mcts-time_5s>` are also noisy, we indeed see that the strength of MCTS increases with :math:`t` but the slope of the curve is not very important after :math:`t=5s` so we decide that :math:`t=5s` is a good compromise between strength and waiting time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hc",
     "fig:mcts-time_5s"
    ]
   },
   "outputs": [],
   "source": [
    "mcts = results[results.pool == 'mcts_5s_time_compare_longer'].copy()\n",
    "mcts['time'] = mcts.opponent_eval.map(lambda x: x.args[1].total_seconds())\n",
    "grouped = mcts.groupby('time').winner.agg(['mean'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(\n",
    "    grouped.index,\n",
    "    grouped['mean'],\n",
    "    label='win ratio',\n",
    "    s=100\n",
    ")\n",
    "\n",
    "plt.vlines(5, 0, 1.2, linestyles='dashed', label=\"5s\", color=\"grey\")\n",
    "plt.hlines(0.5, grouped.index.min() , grouped.index.max(), linestyles='dotted', label=\"0.5 win ratio\", color=\"grey\")\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.title(\"Win ratios of different time values against 5s\");\n",
    "plt.xlabel(\"Opponent's time limit\")\n",
    "plt.ylabel(\"Opponent's win ratio\");"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Strength of MCTS related to the allowed simulation time budget"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _sec:uct-tuning:\n",
    "\n",
    "UCT\n",
    "~~~\n",
    "\n",
    "The UCT agent has 2 variables that we can tune, :math:`t` as in MCTS and :math:`c` the balance between exploration and exploitation. We will fix :math:`t=5s` so that we can fairly compare MCTS and UTC later.\n",
    "\n",
    ":cite:`kocsis2006bandit` has shown that :math:`c=\\frac{\\sqrt{2}}{2}` is a good starting value. We thus play matches of UCT(:math:`c=\\frac{\\sqrt{2}}{2}`) against a range of 11 values equally spaced between 0.2 and 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = np.linspace(0, 2, 11) + 0.2\n",
    "\n",
    "for i in range(25):\n",
    "    for c in search_space:\n",
    "            player = \"UCTPlayer(%s, td(seconds=5), c=math.sqrt(2)/2)\"\n",
    "            opponent = f\"UCTPlayer(%s, td(seconds=5), c={c:.2f})\"\n",
    "\n",
    "            sumbit_symmetric_match(player, opponent, \"uct-tuning-c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ha"
    ]
   },
   "outputs": [],
   "source": [
    "from lib.utils import fold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What we see in :numref:`Figure %s <utc-tuning-c>` is a bell curve with some noise and a plateau around :math:`c = \\sqrt(2) / 2`. The noise is louder on the right than on on the left of its maximum. An explanation for this could be that on the left, as :math:`c` is lower, there is not much exploration so the algorithm is more deterministic while it's the opposite on the right and each simulation could be either really good or really bad depending on luck.\n",
    "\n",
    "As the maximum of the bell curve is around :math:`c = \\sqrt(2) / 2` it seems to confirm that it is the optimum value for UCT.\n",
    "\n",
    ".. _utc-tuning-c:\n",
    "\n",
    ".. figure:: notebooks/uct-value.png\n",
    "\n",
    "  Strength of UCT(:math:`c=\\frac{\\sqrt{2}}{2}`) against other values of :math:`c`. TODO: regenerate figure in svg"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Under the assumption that the curve is smooth, we know that :math:`c = \\sqrt(2) / 2` is will win against any value of :math:`c \\in [0.2, 2.2]`. While this result might be convenient, we don't know if the relation of one agent winning against another is transitive, so while :math:`c = \\sqrt(2) / 2` beats every value, we might have another value of :math:`c = \\sqrt(2) / 2` that beats every :math:`c \\neq \\sqrt(2) / 2` by a bigger margin. To have a better intuition it is the case or not, we can also run the same experiment as above but with :math:`c = 1.5` to see if we were not lucky by using :math:`c = \\sqrt(2) / 2` the first time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = np.linspace(0, 2, 11) + 0.2\n",
    "\n",
    "for i in range(25):\n",
    "    for c in search_space:\n",
    "            player = \"UCTPlayer(%s, td(seconds=5), c=1.5)\"\n",
    "            opponent = f\"UCTPlayer(%s, td(seconds=5), c={c:.2f})\"\n",
    "\n",
    "            sumbit_symmetric_match(player, opponent, \"uct-tuning-c-15\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "While the curve in :numref:`Figure %s <fig:uct-tuning-c-15>` is not as smooth as in the first experiment, the result of the matches against :math:`c = 1.5` seem to show the same curve with a maximum at :math:`c = \\sqrt(2) / 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hc",
     "fig:uct-tuning-c-15"
    ]
   },
   "outputs": [],
   "source": [
    "uct = results[results.pool == 'uct-1_5-vs-range'].copy()\n",
    "uct['c'] = uct.opponent_eval.map(lambda x: x.kwargs['c'])\n",
    "grouped = uct.groupby('c').winner.agg(['mean', 'count'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(\n",
    "    grouped.index,\n",
    "    grouped['mean'],\n",
    "    #c=grouped['count'],\n",
    "    label='win ratio',\n",
    "    s=100\n",
    ")\n",
    "\n",
    "plt.vlines(1.5, 0, 1, linestyles='dashed', label=\"$1.5$\", color=\"grey\")\n",
    "plt.hlines(0.5, grouped.index.min() , grouped.index.max(), linestyles='dotted', label=\"0.5 win ratio\", color=\"grey\")\n",
    "plt.legend()\n",
    "#cb = plt.colorbar()\n",
    "#cb.set_label('# of matches', rotation=270)\n",
    "#cb.ax.set_yticklabels([int(i) for i in cb.get_ticks()])\n",
    "#cb.ax.get_yaxis().labelpad = 15\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.title(\"Win ratios of different $c$ values against $c = 1.5$\");\n",
    "plt.xlabel(\"Opponent's value of $c$\")\n",
    "plt.ylabel(\"Opponent's win ratio\");"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Strength of UCT(:math:`c=1.5`) against other values of :math:`c`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tournament results\n",
    "------------------\n",
    "\n",
    "We select the best agent for every algorithm and make each of them play 50 match against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [\n",
    "    \"RandomPlayer(%i)\",\n",
    "    \"GreedyPlayer(%i, 0.95)\",\n",
    "    \"MCTSPlayer(%i, td(seconds=5))\",\n",
    "    \"UCTPlayer(%i, td(seconds=5), c=math.sqrt(2)/2)\",\n",
    "    \"GreedyUCTPlayer(%i, td(seconds=5), c=math.sqrt(2)/2)\",\n",
    "]\n",
    "\n",
    "for i in range(25):\n",
    "    for a in algos:\n",
    "        for b in algos:\n",
    "            sumbit_symmetric_match(a, b, \"tournament\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The results, displayed in a matrix in :numref:`Figure %s <fig:matrix>`, show that UCT and GreedyUCT beat every other agent. There is no clear winner between those 2 champions though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "fig:matrix",
     "hc"
    ]
   },
   "outputs": [],
   "source": [
    "tournament = results[results.pool == 'tournament-1'].copy()\n",
    "\n",
    "tournament['player_algo'] = tournament.player.str.split(\"(\").map(lambda x: x[0])\n",
    "tournament['opponent_algo'] = tournament.opponent.str.split(\"(\").map(lambda x: x[0])\n",
    "\n",
    "grouped = tournament.groupby(['player_algo', 'opponent_algo']).head(25).groupby(['player_algo', 'opponent_algo']).winner.agg(['mean', 'count'])\n",
    "\n",
    "im = grouped.drop('count', axis=1).unstack()\n",
    "folded = fold(im.values)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "ax1 = plt.gca()\n",
    "ax1.set_title(\"Win ratios of each algorithm in the tournament\")\n",
    "ax1.tick_params(axis='both', direction='out')\n",
    "ax1.set_xticks(range(len(im.columns)))\n",
    "ax1.set_xticklabels([x[1] for x in im.columns])\n",
    "ax1.set_yticks(range(len(im.index)))\n",
    "ax1.set_yticklabels(im.index)\n",
    "\n",
    "\n",
    "\n",
    "img = ax1.imshow(folded , origin='lower');\n",
    "\n",
    "cbar = fig.colorbar(img)\n",
    "cbar.set_label('Win ratio of the column player', rotation=270)\n",
    "cbar.ax.get_yaxis().labelpad = 15"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Matrix representation of the valued tournament between every algorithm\n",
    "  \n",
    ".. todo:: We still have to transform the values tournament in a binary one and then analyze it with the framework of tournament solutions."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "==========\n",
    "Conclusion\n",
    "=========="
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "========\n",
    "Appendix\n",
    "========\n",
    "\n",
    "Bibliography\n",
    "------------\n",
    "\n",
    ".. bibliography:: refs.bib\n",
    "   :style: custom"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Footnotes\n",
    "---------\n",
    "\n",
    ".. [#source_bao] Picture by Yintan under Creative Commons SA license https://commons.wikimedia.org/wiki/File:Bao_europe.jpg\n",
    " \n",
    " .. [#aws_c5] C5 instances contain a 2nd generation Intel Xeon Scalable Processor (Cascade Lake) with a sustained all core Turbo frequency of 3.6GHz.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Appendix\n",
    "--------\n",
    "\n",
    ":doc:`removed`"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
