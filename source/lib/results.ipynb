{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Download data from AWS\n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hr"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikita/Code/Thesis/ve/lib/python3.9/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "from datetime import timedelta as td\n",
    "\n",
    "session = boto3.client('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "ha"
    ]
   },
   "outputs": [],
   "source": [
    "# __file__ does not exist while executing a notebok from jupyter but does exist when importing it\n",
    "# this ensures __file__ always exists\n",
    "__file__ = globals().get('__file__', os.path.join(os.path.abspath(\"./results.ipynb\"), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_results():\n",
    "    start = int(datetime(2021, 5, 1).timestamp())\n",
    "    results = []\n",
    "\n",
    "    while True:\n",
    "        print('Querying')\n",
    "\n",
    "        # Query for the first time beginning in 1970\n",
    "        query = session.start_query(\n",
    "            logGroupName='/aws/batch/job',\n",
    "            startTime=start,\n",
    "            endTime=int(time.time()),\n",
    "            queryString=\"\"\"\n",
    "                fields @message, @timestamp\n",
    "                | filter success == 1\n",
    "                | sort @timestamp asc\n",
    "                | limit 10000\n",
    "            \"\"\",\n",
    "            limit=10000\n",
    "        )\n",
    "\n",
    "        # Loop untill the query response is ready\n",
    "        query_result = {'status': 'Scheduled'}\n",
    "        while query_result['status'] in ('Scheduled', 'Running'):\n",
    "            query_result = session.get_query_results(queryId=query['queryId'])\n",
    "            time.sleep(1)\n",
    "\n",
    "        tmp = query_result\n",
    "\n",
    "        # If we reached the end, we don't have any more data, we break\n",
    "        if len(query_result['results']) == 0:\n",
    "            break\n",
    "\n",
    "        # If we did not reach the end, we get the timestamp of the last line and use this\n",
    "        # as a starting point for the next iteration\n",
    "        assert query_result['results'][-1][1]['field'] == \"@timestamp\"\n",
    "        start = int(datetime.strptime(query_result['results'][-1][1]['value'], \"%Y-%m-%d %H:%M:%S.%f\").replace(tzinfo=timezone.utc).timestamp()) + 1\n",
    "\n",
    "        # Process the data a little bit and push it to results\n",
    "        data = [\n",
    "            json.loads(row[0]['value'])\n",
    "            for row in query_result['results']\n",
    "        ]\n",
    "        results += data\n",
    "\n",
    "    print(f\"Done, with {len(results)} results\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DIR = os.path.dirname(os.path.dirname(__file__))\n",
    "\n",
    "\n",
    "DATA_DIR = os.path.join(SOURCE_DIR, \"data/\")\n",
    "CLOUDWATCH_DATA_PATH = os.path.join(DATA_DIR, \"cloudwtach-results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(results):\n",
    "    with open(CLOUDWATCH_DATA_PATH, \"w\") as fd:\n",
    "        for row in results:\n",
    "            json.dump(row, fd)\n",
    "            fd.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying\n",
      "Querying\n",
      "Done, with 2987 results\n"
     ]
    }
   ],
   "source": [
    "write_results(download_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def read_results():\n",
    "    with open(CLOUDWATCH_DATA_PATH) as fd:\n",
    "        cloudwatch = [json.loads(l) for l in fd]\n",
    "\n",
    "        local = []\n",
    "\n",
    "        for path in glob.glob(os.path.join(DATA_DIR, \"local-results\", \"*.jsonl\")):\n",
    "            with open(path) as fd:\n",
    "                data = [json.loads(l) for l in fd if l.startswith(\"{\")]\n",
    "            local += data\n",
    "\n",
    "    raw_results = cloudwatch + local\n",
    "\n",
    "    for row in raw_results:\n",
    "        if row['winner'] is None:\n",
    "            row['winner'] = 0.5\n",
    "\n",
    "    df = pd.DataFrame(raw_results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locals():\n",
    "    class Player:\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            self.args = args\n",
    "            self.kwargs = kwargs\n",
    "\n",
    "    class GreedyPlayer(Player):\n",
    "        pass\n",
    "\n",
    "    class MCTSPlayer(Player):\n",
    "        pass\n",
    "\n",
    "    class UCTPlayer(Player):\n",
    "        pass\n",
    "\n",
    "\n",
    "    class GreedyUCTPlayer(Player):\n",
    "        pass\n",
    "\n",
    "\n",
    "    class RandomPlayer(Player):\n",
    "        pass\n",
    "    return locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_locals = get_locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(df):\n",
    "    \n",
    "\n",
    "    # Fix bad data\n",
    "    df['version'] = df.version.fillna(1).astype(int)\n",
    "    df['side'] = df['side'].fillna(-1).astype(int)\n",
    "\n",
    "    # Only keep usable data\n",
    "    df = df[df.version >= 2]\n",
    "\n",
    "    is_normalized = df['side'] == 0\n",
    "\n",
    "    to_normalise = df[~is_normalized].copy()\n",
    "\n",
    "    # Swap columns\n",
    "    opponents = to_normalise['opponent'].copy()\n",
    "    players = to_normalise['player'].copy()\n",
    "\n",
    "    to_normalise['player'] = opponents\n",
    "    to_normalise['opponent'] = players\n",
    "\n",
    "    # Swap winner\n",
    "    to_normalise['winner'] = 1 - to_normalise['winner']\n",
    "\n",
    "    # Swap individual scores\n",
    "    to_normalise['score'] = to_normalise['score'].map(lambda x: list(reversed(x)))\n",
    "\n",
    "    # Concatenate the 2 sides\n",
    "    normalised = pd.concat([\n",
    "        df[is_normalized].copy(),\n",
    "        to_normalise.copy()\n",
    "    ]).copy()\n",
    "\n",
    "\n",
    "    # Evaluate both players\n",
    "    normalised['player_eval'] = normalised['player'].map(lambda x: eval(x, globals(), player_locals))\n",
    "    normalised['opponent_eval'] = normalised['opponent'].map(lambda x: eval(x, globals(), player_locals))\n",
    "    \n",
    "    return normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results = read_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = process_results(raw_results)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
