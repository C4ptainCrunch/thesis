{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mancala\n",
    "\n",
    "Mancala is a ancient family of games played played on many continents ([source, page 2623](https://doi.org/10.1007/978-94-007-3934-5_9947-1)). The word *mancala* comes from the Arabic word *نقل* transliterated *naqala* meaning literally \"to move\".\n",
    "\n",
    "Mancala games usualy consists of two row of pits each containing a proportionaite amount of seeds, stones or shells.\n",
    "Usualy, these games are played by two opponents who play sequentialy.\n",
    "\n",
    "The goal for each opponent is to capture as many seeds as possible before the other.\n",
    "\n",
    "-- Insert figure here\n",
    "\n",
    "We will focus on Awalé (also called Oware or Owari), originating from Ghana and Kalah, a modern version invented by William Julius Champion Jr. circa 1940.\n",
    "\n",
    "There are too many other existing variations to list them all here, but a few notable ones are Wari, Bao and Congkak.\n",
    "\n",
    "\n",
    "## Perfect information\n",
    "\n",
    "Mancala games are : \n",
    " * sequential : the oppenents play one after the other,\n",
    " * hold no secret information : each playser has the same information about the game as the other\n",
    " * do not rely on randomness : the state of the game depends only on the actions taken sequentialy by each player and an action has a determinitc result.\n",
    "\n",
    "This type of game is called a sequential perfect information game. ([6.1 page 89](http://ebour.com.ar/pdfs/A%20Course%20in%20Game%20Theory.pdf)).\n",
    "\n",
    "-- Insert something about finite state machines ?\n",
    "\n",
    "Other games in this category are for example Chess, Go, Checkers or even Tic-tac-toe and Connect Four.\n",
    "\n",
    "This type of game is a particularly intersting field to study in computer science and artifical intelligence as they are easy to simulate.\n",
    "\n",
    "While it might be tempting to enumerate every possible play of those games by starting a game and recusively try each legal action untill the end of the play, most of the time, this is not a feasible approch for most games due to the size of the state space.\n",
    "\n",
    "For example, [Romein et al.](https://www.cs.vu.nl/pub/bal/awari.ps) claims that Awalé has 889,063,398,406 legal positions and the number of $\\approx 2.08 * 10^170$ legal postions in Go has only [recently been determined](http://tromp.github.io/go/legal.html).\n",
    "\n",
    "[Kalah is solved](http://kalaha.krus.dk/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oware\n",
    "\n",
    "The b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awalé\n",
    "Also known as awari and owari\n",
    "\n",
    "## Solved\n",
    "\n",
    "It might be solved by [Solving awari with parallel retrograde analysis](http://ieeexplore.ieee.org/abstract/document/1236468/)\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recordclass import recordclass\n",
    "\n",
    "GAME_NODE_FIELDS = ['n_pits', 'seeds_per_pit', 'pits', 'current_player', 'captures', 'parent', 'children', 'wins', 'n_playouts']\n",
    "        \n",
    "class Game(recordclass('GameNode', GAME_NODE_FIELDS)):\n",
    "    @classmethod\n",
    "    def start_game(klass, n_pits=6, seeds_per_pit=4):\n",
    "        return klass(\n",
    "            n_pits,\n",
    "            seeds_per_pit,\n",
    "            pits=np.ones((n_pits * 2), dtype=int) * seeds_per_pit,\n",
    "            current_player=0,\n",
    "            captures=np.zeros((2,), dtype=int),\n",
    "            parent=None,\n",
    "            children=[None] * n_pits,\n",
    "            wins=0,\n",
    "            n_playouts=0\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def view_from_current_player(self):\n",
    "        shift = 0 if self.current_player == 0 else self.n_pits\n",
    "        return np.roll(self.pits, shift)\n",
    "\n",
    "    @property\n",
    "    def legal_actions(self):\n",
    "        # todo : add the Let the opponent play rule\n",
    "        player_view = self.view_from_current_player\n",
    "        return [x for x in range(self.n_pits) if player_view[x] != 0]\n",
    "    \n",
    "    @property\n",
    "    def successors(self):\n",
    "        children = [x for x in self.children if x is not None]\n",
    "        successors = children + list(itertools.chain(*[x.successors for x in children]))\n",
    "        return successors\n",
    "\n",
    "    def step(self, action):\n",
    "        assert 0 <= action < self.n_pits\n",
    "        \n",
    "        if self.children[action] is not None:\n",
    "            new_game = self.children[action]\n",
    "            captures = self.captures[self.current_player] - new_game.captures[self.current_player]\n",
    "            return new_game, captures, new_game.game_finished\n",
    "        \n",
    "        target_pit = action if self.current_player == 0 else action - self.n_pits\n",
    "        \n",
    "        seeds = self.pits[target_pit]\n",
    "        assert seeds != 0\n",
    "        \n",
    "        # copy attributes\n",
    "        pits = np.copy(self.pits)\n",
    "        captures = np.copy(self.captures)\n",
    "        \n",
    "        # empty the target pit\n",
    "        pits[target_pit] = 0\n",
    "        \n",
    "        # fill the next pits\n",
    "        pit_to_sow = target_pit\n",
    "        while seeds > 0:\n",
    "            pit_to_sow = (pit_to_sow + 1) % (self.n_pits * 2)\n",
    "            if pit_to_sow != target_pit: # do not fill the target pit ever\n",
    "                pits[pit_to_sow] += 1\n",
    "                seeds -= 1\n",
    "        \n",
    "        # capture\n",
    "        # count the captures of the play\n",
    "        round_captures = 0\n",
    "        if pit_to_sow in self.adverse_pits_idx:\n",
    "            # if the last seed was in a adverse pit\n",
    "            # we can try to collect seeds\n",
    "            while pits[pit_to_sow] in (2, 3):\n",
    "                # if the pit contains 2 or 3 seeds, we capture them\n",
    "                captures[self.current_player] += pits[pit_to_sow]\n",
    "                round_captures += pits[pit_to_sow]\n",
    "                pits[pit_to_sow] = 0\n",
    "                \n",
    "                # go backwards\n",
    "                pit_to_sow = (pit_to_sow - 1) % (self.n_pits * 2)\n",
    "        \n",
    "        # change player\n",
    "        current_player = (self.current_player + 1) % 2\n",
    "        \n",
    "        new_game = type(self)(\n",
    "            self.n_pits,\n",
    "            self.seeds_per_pit,\n",
    "            pits,\n",
    "            current_player,\n",
    "            captures,\n",
    "            self,\n",
    "            [None] * self.n_pits,\n",
    "            0,\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        self.children[action] = new_game\n",
    "        return new_game, round_captures, new_game.game_finished\n",
    "    \n",
    "    @property\n",
    "    def adverse_pits_idx(self):\n",
    "        if self.current_player == 1:\n",
    "            return list(range(self.n_pits))\n",
    "        else:\n",
    "            return list(range(self.n_pits, self.n_pits * 2))\n",
    "    \n",
    "    @property\n",
    "    def is_state_loop(self):\n",
    "        ancestor = self.parent\n",
    "        while ancestor is not None:\n",
    "            if np.all(ancestor.pits == self.pits):\n",
    "                return True\n",
    "            ancestor = ancestor.parent\n",
    "        return False\n",
    "    \n",
    "    @property\n",
    "    def game_finished(self):\n",
    "        no_moves_left = np.all(self.view_from_current_player[:self.n_pits] == np.zeros((self.n_pits,)))\n",
    "        enough_captures = np.any(self.captures > (self.n_pits * self.seeds_per_pit) / 2)\n",
    "        draw = np.all(self.captures == (self.n_pits * self.seeds_per_pit) / 2)\n",
    "        loop = self.is_state_loop\n",
    "        return no_moves_left or enough_captures or draw or loop\n",
    "    \n",
    "    def show_state(self):\n",
    "        if self.game_finished:\n",
    "            print(\"Game finished\")\n",
    "        print(\"Current player: {} - Score: {}/{}\\n{}\".format(\n",
    "            self.current_player,\n",
    "            self.captures[self.current_player],\n",
    "            self.captures[(self.current_player + 1) % 2],\n",
    "            \"-\" * self.n_pits * 3\n",
    "        ))\n",
    "        \n",
    "        pits = []\n",
    "        for seeds in self.view_from_current_player:\n",
    "            pits.append(\"{:3}\".format(seeds))\n",
    "        \n",
    "        print(\"\".join(reversed(pits[self.n_pits:])))\n",
    "        print(\"\".join(pits[:self.n_pits]))\n",
    "    \n",
    "    def update_stats(self, win):\n",
    "        self.wins += int(win)\n",
    "        self.n_playouts += 1\n",
    "        if self.parent:\n",
    "            self.parent.update_stats(win)\n",
    "    \n",
    "    @property\n",
    "    def winner(self):\n",
    "        if not self.game_finished:\n",
    "            return None\n",
    "        return np.argmax(self.captures)\n",
    "    \n",
    "    @property\n",
    "    def unvisited_actions(self):\n",
    "        return [i for i, x in enumerate(self.children) if x is None]\n",
    "\n",
    "    @property\n",
    "    def legal_unvisited_actions(self):\n",
    "        return list(set(self.unvisited_actions).intersection(set(self.legal_actions)))\n",
    "    \n",
    "    @property\n",
    "    def expanded_children(self):\n",
    "        return [x for x in self.children if x is not None]\n",
    "    \n",
    "    @property\n",
    "    def is_fully_expanded(self):\n",
    "        legal_actions = set(self.legal_actions)\n",
    "        unvisited_actions = set(self.unvisited_actions)\n",
    "        return len(legal_actions.intersection(unvisited_actions)) == 0\n",
    "    \n",
    "    @property\n",
    "    def is_leaf_game(self):\n",
    "        return self.children == [None] * self.n_pits\n",
    "    \n",
    "    @property\n",
    "    def depth(self):\n",
    "        if self.parent is None:\n",
    "            return 0\n",
    "        return 1 + self.parent.depth\n",
    "    \n",
    "    def to_dot(self, is_root=True):\n",
    "        output = \"%s -> %s;\\n\" % (id(self.parent), id(self)) if self.parent else \"\\n\"\n",
    "        output += '%s [label=\"%s/%s\"]' % (id(self), self.wins, self.n_playouts)\n",
    "        \n",
    "        for child in self.children:\n",
    "            if child is not None:\n",
    "                output += child.to_dot(False) + \"\\n\"\n",
    "        \n",
    "        if is_root:\n",
    "            return \"\"\"\n",
    "            digraph BST {\n",
    "                node [fontname=\"Arial\"];\n",
    "                %s\n",
    "            }\n",
    "            \"\"\" % output\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"<Game {wins}/{n_playouts} player:{player} captures:{captures[0]}/{captures[1]}>\".format(\n",
    "            wins=self.wins,\n",
    "            n_playouts=self.n_playouts,\n",
    "            player=self.current_player,\n",
    "            captures=self.captures\n",
    "        )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Game.start_game(1, 2)\n",
    "\n",
    "g, _, _ = g.step(0)\n",
    "g, captues, done = g.step(0)\n",
    "assert done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_tree_policy(root):\n",
    "    nodes = [root] + root.successors\n",
    "    unexpanded_nodes = [n for n in nodes if not n.is_fully_expanded]\n",
    "    return random.choice(unexpanded_nodes)\n",
    "\n",
    "def random_default_policy(node):\n",
    "    if node.is_fully_expanded:\n",
    "        return random.choice(node.legal_actions)\n",
    "    return random.choice(node.legal_unvisited_actions)\n",
    "\n",
    "def mcts(budget, tree_policy, default_policy):\n",
    "    # Create a tree\n",
    "    root = Game.start_game()\n",
    "\n",
    "    for _ in range(budget):\n",
    "        # Choose a starting node\n",
    "        node = tree_policy(root)\n",
    "        \n",
    "        # Run a simulation on that node\n",
    "        finished = node.game_finished\n",
    "        while not finished:\n",
    "            node, _, finished = node.step(default_policy(node))\n",
    "        \n",
    "        # Backtrack stats\n",
    "        win = (node.winner == 0)\n",
    "        node.update_stats(win)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS + UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_rand(iterable, key=lambda x: x):\n",
    "    maximum_value = max(key(x) for x in iterable)\n",
    "    keep = [x for x in iterable if key(x) == maximum_value]\n",
    "    return random.choice(keep)\n",
    "\n",
    "def UCT_best_child(node):\n",
    "    def score(node):\n",
    "        assert node is not None\n",
    "        c = 1 / math.sqrt(2)\n",
    "        exporation = node.wins / node.n_playouts\n",
    "        exploitation = math.sqrt(math.log(node.parent.n_playouts) / node.n_playouts)\n",
    "        return exporation + c * exploitation\n",
    "    \n",
    "    return max_rand(node.expanded_children, key=score)\n",
    "\n",
    "def UCT_tree_policy(root):\n",
    "    node = root\n",
    "    while not node.is_leaf_game:\n",
    "        if node.is_fully_expanded:\n",
    "            node = UCT_best_child(node)\n",
    "        else:\n",
    "            action = random.choice(node.legal_unvisited_actions)\n",
    "            node, _, _ = node.step(action)\n",
    "    return node\n",
    "\n",
    "def UCT_default_policy(node):\n",
    "    return random.choice(node.legal_unvisited_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcts_player(player_id, budget, tree_policy, default_policy):\n",
    "    root = Game.start_game()\n",
    "    \n",
    "    if player_id == 1:\n",
    "        opponent_action = yield\n",
    "        print(\"Player\", player_id, \"got action\")\n",
    "        root, _, _ = root.step(opponent_action)\n",
    "    \n",
    "    while not root.game_finished:\n",
    "        # Expand the tree\n",
    "        for _ in range(budget):\n",
    "            # Choose a starting node\n",
    "            node = tree_policy(root)\n",
    "\n",
    "            # Run a simulation on that node\n",
    "            finished = node.game_finished\n",
    "            while not finished:\n",
    "                node, _, finished = node.step(default_policy(node))\n",
    "\n",
    "            # Backtrack stats\n",
    "            win = (node.winner == 0)\n",
    "            node.update_stats(win)\n",
    "        \n",
    "        # Chose an action\n",
    "        action = max(root.legal_actions, key=lambda x: -1 if root.children[x] is None else root.children[x].wins)\n",
    "        \n",
    "        # Update the root\n",
    "        root, _, _ = root.step(action)\n",
    "        \n",
    "        # Send the action\n",
    "        opponent_action = yield action\n",
    "        \n",
    "        # Recv the opponent's action and update the root again\n",
    "        #opponent_action = yield\n",
    "        root, _, _ = root.step(opponent_action)\n",
    "\n",
    "def random_player(player_id):\n",
    "    root = Game.start_game()\n",
    "    \n",
    "    if player_id == 1:\n",
    "        opponent_action = yield\n",
    "        print(player_id, \"Player\", 0, opponent_action)\n",
    "        root, _, _ = root.step(opponent_action)\n",
    "    \n",
    "    while not root.game_finished:\n",
    "        action = random.choice(root.legal_actions)\n",
    "        print(player_id, \"Player\", player_id, action)\n",
    "        root, _, _ = root.step(action)\n",
    "        \n",
    "        yield action\n",
    "        opponent_action = yield action\n",
    "        print(player_id, \"Player\", (player_id + 1) % 2, opponent_action)\n",
    "        root, _, _ = root.step(opponent_action)\n",
    "\n",
    "def greedy_player(player_id, eps=0):\n",
    "    root = Game.start_game()\n",
    "    \n",
    "    if player_id == 1:\n",
    "        opponent_action = yield\n",
    "        root, _, _ = root.step(opponent_action)\n",
    "    \n",
    "    while not root.game_finished:\n",
    "        children = []\n",
    "        \n",
    "        for legal_action in root.legal_actions:\n",
    "            new_state, captures, finished = root.step(legal_action)\n",
    "            if new_state.winner is None:\n",
    "                win = None\n",
    "            elif new_state.winner == player_id:\n",
    "                win = 1\n",
    "            else:\n",
    "                win = -1\n",
    "            children.append((legal_action, captures, win))\n",
    "        \n",
    "        # order wins first, then by captures, then random\n",
    "        sorted_children = sorted(results, key=lambda a_c_w: (-a_c_w[2], -a_c_w[1], random.rand()))\n",
    "        if random.rand() < eps:\n",
    "            action = random.choice(root.legal_actions)\n",
    "        else:\n",
    "            action = sorted_children[0][0]\n",
    "        root, _, _ = root.step(action)\n",
    "        \n",
    "        yield action\n",
    "        opponent_action = yield\n",
    "        root, _, _ = root.step(opponent_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Player 0 3\n",
      "M Player 0 3\n",
      "1 Player 0 3\n",
      "1 Player 1 0\n",
      "M Player 1 0\n",
      "M Player 0 3\n",
      "M Player 1 0\n",
      "0 Player 1 0\n",
      "0 Player 0 5\n",
      "M Player 0 5\n",
      "1 Player 0 5\n",
      "1 Player 1 2\n",
      "M Player 1 2\n",
      "M Player 0 5\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-245-34477862cd1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mplayer_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopponent_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"M\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Player\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f96b847458dd>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_pit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mseeds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# copy attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BUDGET = 100\n",
    "\n",
    "game = Game.start_game()\n",
    "#player = mcts_player(0, BUDGET, random_tree_policy, random_default_policy)\n",
    "#opponent = mcts_player(1, BUDGET, UCT_tree_policy, UCT_default_policy)\n",
    "player = random_player(0)\n",
    "opponent = random_player(1)\n",
    "\n",
    "\n",
    "next(opponent) # bootstrap the opponent\n",
    "\n",
    "player_action = next(player)\n",
    "print(\"M\", \"Player\", 0, player_action)\n",
    "game, captures, finished = game.step(action)\n",
    "\n",
    "while True:\n",
    "    opponent_action = opponent.send(player_action)\n",
    "    print(\"M\", \"Player\", 1, opponent_action)\n",
    "    game, captures, finished = game.step(opponent_action)\n",
    "    \n",
    "    player_action = player.send(opponent_action)\n",
    "    print(\"M\", \"Player\", 0, player_action)\n",
    "    game, captures, finished = game.step(player_action)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crasH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-217-9a69434da46d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrasH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'crasH' is not defined"
     ]
    }
   ],
   "source": [
    "crasH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "BUDGET = 100\n",
    "root = mcts(BUDGET, random_tree_policy, random_default_policy)\n",
    "root2 = mcts(BUDGET, UCT_tree_policy, UCT_default_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dot\", 'w') as fd:\n",
    "    fd.write(root.to_dot())\n",
    "\n",
    "with open(\"dot2\", 'w') as fd:\n",
    "    fd.write(root2.to_dot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(root, max([x.depth for x in root.successors]))\n",
    "leaf_depths = [x.depth for x in root.successors if x.is_leaf_game]\n",
    "print(max(leaf_depths) - min(leaf_depths))\n",
    "print(np.var(leaf_depths))\n",
    "plt.hist([6 - len(x.legal_unvisited_actions) for x in root.successors], bins=range(6));\n",
    "plt.show()\n",
    "plt.hist([x.depth for x in root.successors if x.is_leaf_game]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(root2, max([x.depth for x in root2.successors]))\n",
    "leaf_depths = [x.depth for x in root2.successors if x.is_leaf_game]\n",
    "print(max(leaf_depths) - min(leaf_depths))\n",
    "print(np.var(leaf_depths))\n",
    "plt.hist([6 - len(x.legal_unvisited_actions) for x in root2.successors], bins=range(6));\n",
    "plt.show()\n",
    "plt.hist([x.depth for x in root2.successors if x.is_leaf_game]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep mind\n",
    "\n",
    " * Alpha Go [Mastering the game of Go with deep neural networks and tree search](https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf)\n",
    " * Alpha Go Zero [Mastering the game of Go without human knowledge](https://www.nature.com/articles/nature24270.epdf?author_access_token=VJXbVjaSHxFoctQQ4p2k4tRgN0jAjWel9jnR3ZoTv0PVW4gB86EEpGqTRDtpIz-2rmo8-KG06gqVobU5NSCFeHILHcVFUeMsbvwS-lxjqQGg98faovwjxeTUgZAUMnRQ)\n",
    " * Alpha Zero [Mastering Chess and Shogi by Self-Play with a\n",
    "General Reinforcement Learning Algorithm](https://arxiv.org/pdf/1712.01815.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pits = 6\n",
    "seeds_per_pit = 4\n",
    "\n",
    "dropout = 0.3\n",
    "lr = 0.001\n",
    "conv_size = 3\n",
    "\n",
    "inputlen = n_pits * 2\n",
    "padd_len = conv_size - 1\n",
    "num_classes = n_pits * seeds_per_pit * 2\n",
    "\n",
    "Left_pad = Lambda(lambda x: x[:, -padd_len:])\n",
    "\n",
    "def _conv_pad(x):\n",
    "    return Concatenate(axis=1)([\n",
    "        Left_pad(x),\n",
    "        x\n",
    "    ])\n",
    "Conv_pad = Lambda(_conv_pad)\n",
    "\n",
    "board = Input(shape=(inputlen,))\n",
    "board_reshaped = Reshape((inputlen, 1))(board)\n",
    "\n",
    "conv1 = Activation('relu')(BatchNormalization(axis=2)(Conv1D(20, conv_size, padding='valid')(Conv_pad(board_reshaped))))\n",
    "conv2 = Activation('relu')(BatchNormalization(axis=2)(Conv1D(20, conv_size, padding='valid')(Conv_pad(conv1))))\n",
    "conv3 = Activation('relu')(BatchNormalization(axis=2)(Conv1D(20, conv_size, padding='valid')(Conv_pad(conv2))))\n",
    "\n",
    "flat = Flatten()(conv3)       \n",
    "\n",
    "fc1 = Dropout(dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(256)(flat))))\n",
    "fc2 = Dropout(dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(128)(fc1))))\n",
    "\n",
    "policy = Dense(n_pits, activation='softmax', name='policy')(fc2)\n",
    "value = Dense(1, activation='tanh', name='value')(fc2)\n",
    "\n",
    "model = Model(inputs=board, outputs=[policy, value])\n",
    "model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=Adam(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_44 (InputLayer)           (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_38 (Reshape)            (None, 12, 1)        0           input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              multiple             0           reshape_38[0][0]                 \n",
      "                                                                 activation_160[0][0]             \n",
      "                                                                 activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_103 (Conv1D)             (None, 12, 20)       80          lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 12, 20)       80          conv1d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 12, 20)       0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_104 (Conv1D)             (None, 12, 20)       1220        lambda_25[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 12, 20)       80          conv1d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 12, 20)       0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_105 (Conv1D)             (None, 12, 20)       1220        lambda_25[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 12, 20)       80          conv1d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 12, 20)       0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 240)          0           activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 256)          61696       flatten_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 256)          1024        dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 256)          0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 256)          0           activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 128)          32896       dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 128)          512         dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 128)          0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 128)          0           activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "policy (Dense)                  (None, 6)            774         dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "value (Dense)                   (None, 1)            129         dropout_58[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 99,791\n",
      "Trainable params: 98,903\n",
      "Non-trainable params: 888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
