{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _alpha:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing AlphaZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from rules.ipynb\n",
      "Current player: 0 - Score: 0/0\n",
      "------------------\n",
      "  5  5  6  0  5  5\n",
      "  5  5  4  4  4  0\n",
      "importing Jupyter notebook from players.ipynb\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import import_ipynb\n",
    "from rules import Game\n",
    "from players import RandomPlayer, GreedyPlayer, MCTSPlayer, UCTPlayer, HumanPlayer, Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 12, 1)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               multiple             0           reshape_2[0][0]                  \n",
      "                                                                 activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 12, 20)       80          lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12, 20)       80          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 20)       0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 12, 20)       1220        lambda_4[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 12, 20)       80          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 12, 20)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 12, 20)       1220        lambda_4[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 12, 20)       80          conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 12, 20)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 240)          0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          61696       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 256)          0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "policy (Dense)                  (None, 6)            774         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "value (Dense)                   (None, 1)            129         dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 99,791\n",
      "Trainable params: 98,903\n",
      "Non-trainable params: 888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_pits = 6\n",
    "seeds_per_pit = 4\n",
    "\n",
    "def cnn():\n",
    "    dropout = 0.3\n",
    "    lr = 0.001\n",
    "    conv_size = 3\n",
    "\n",
    "    inputlen = n_pits * 2\n",
    "    padd_len = conv_size - 1\n",
    "    num_classes = n_pits * seeds_per_pit * 2\n",
    "\n",
    "    Left_pad = Lambda(lambda x: x[:, -padd_len:])\n",
    "\n",
    "    def _conv_pad(x):\n",
    "        return Concatenate(axis=1)([\n",
    "            Left_pad(x),\n",
    "            x\n",
    "        ])\n",
    "    Conv_pad = Lambda(_conv_pad)\n",
    "\n",
    "    board = Input(shape=(inputlen,))\n",
    "    board_reshaped = Reshape((inputlen, 1))(board)\n",
    "\n",
    "    conv1 = Activation('relu')(BatchNormalization(axis=2)(Conv1D(20, conv_size, padding='valid')(Conv_pad(board_reshaped))))\n",
    "    conv2 = Activation('relu')(BatchNormalization(axis=2)(Conv1D(20, conv_size, padding='valid')(Conv_pad(conv1))))\n",
    "    conv3 = Activation('relu')(BatchNormalization(axis=2)(Conv1D(20, conv_size, padding='valid')(Conv_pad(conv2))))\n",
    "\n",
    "    flat = Flatten()(conv3)       \n",
    "\n",
    "    fc1 = Dropout(dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(256)(flat))))\n",
    "    fc2 = Dropout(dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(128)(fc1))))\n",
    "\n",
    "    policy = Dense(n_pits, activation='softmax', name='policy')(fc2)\n",
    "    value = Dense(1, activation='tanh', name='value')(fc2)\n",
    "\n",
    "    model = Model(inputs=board, outputs=[policy, value])\n",
    "    model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=Adam(lr))\n",
    "    \n",
    "    return model\n",
    "\n",
    "cnn().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense-0 (Dense)                 (None, 48)           624         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 48)           0           dense-0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense-1 (Dense)                 (None, 48)           2352        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 48)           0           dense-1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense-2 (Dense)                 (None, 48)           2352        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 48)           0           dense-2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense-3 (Dense)                 (None, 48)           2352        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 48)           0           dense-3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense-4 (Dense)                 (None, 48)           2352        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 48)           0           dense-4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "policy-dense (Dense)            (None, 128)          6272        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "value-dense (Dense)             (None, 128)          6272        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 128)          0           policy-dense[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 128)          0           value-dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "policy (Dense)                  (None, 6)            774         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "value (Dense)                   (None, 1)            129         dropout_16[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 23,479\n",
      "Trainable params: 23,479\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def bnn(n_pits=6, seeds_per_pit=4, depth=5, width=48, dropout=0.3, lr=0.001, top_dense=128):\n",
    "    inputlen = n_pits * 2\n",
    "    \n",
    "    board = Input(shape=(inputlen,))\n",
    "    \n",
    "    dense = board\n",
    "    for i in range(depth):\n",
    "        dense = Dropout(dropout)(Dense(width, activation='relu', name=\"dense-%s\" % i)(dense))\n",
    "\n",
    "    policy_dense = Dropout(dropout)(Dense(top_dense, activation='relu', name=\"policy-dense\")(dense))\n",
    "    policy = Dense(n_pits, activation='softmax', name='policy')(policy_dense)\n",
    "    \n",
    "    value_dense = Dropout(dropout)(Dense(top_dense, activation='relu', name=\"value-dense\")(dense))\n",
    "    value = Dense(1, activation='tanh', name='value')(value_dense)\n",
    "\n",
    "    model = Model(inputs=board, outputs=[policy, value])\n",
    "    model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=Adam(lr))\n",
    "    \n",
    "    return model\n",
    "\n",
    "bnn().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bnn()\n",
    "root = game = Game.start_game()\n",
    "\n",
    "finished = False\n",
    "while not finished:\n",
    "    view = game.view_from_current_player\n",
    "    view = np.reshape(view, (1,) + view.shape)\n",
    "    \n",
    "    policy, _ = model.predict_on_batch(view)\n",
    "    action = np.argmax(policy[0])\n",
    "    if action not in game.legal_actions:\n",
    "        action = random.choice(game.legal_actions)\n",
    "        \n",
    "    game, _, finished = game.step(action)\n",
    "game.update_stats(game.winner)\n",
    "game\n",
    "#model.train_on_batch(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.show_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaPlayer(Player):\n",
    "    def __init__(self, player_id, budget, model, mode=\"competitive\"):\n",
    "        self.root = Game.start_game()\n",
    "        self.initialize_node(self.root)\n",
    "\n",
    "        self.player_id = player_id\n",
    "        self.budget = budget\n",
    "        self.model = model\n",
    "        \n",
    "        assert mode in (\"competitive\", \"exploratory\")\n",
    "        self.mode = mode\n",
    "    \n",
    "    def evaluate_node(self, node):\n",
    "        view = game.view_from_current_player\n",
    "        view = np.reshape(view, (1,) + view.shape)\n",
    "        policy, value = model.predict_on_batch(view)\n",
    "        return policy, value\n",
    "    \n",
    "    def initialize_node(self, node):\n",
    "        _, value = self.evaluate_node(node)\n",
    "        \n",
    "        node.W = 0\n",
    "        node.Q = 0\n",
    "        node.P = value # ? FIXME\n",
    "        \n",
    "    def get_action(self):\n",
    "        for _ in range(self.budget):\n",
    "            self.simulate()\n",
    "        \n",
    "        if self.mode == \"competitive\":\n",
    "            return self.get_competitive_action()\n",
    "        if self.mode == \"exploratory\":\n",
    "            return self.get_exploratory_action()\n",
    "    \n",
    "    def simulate(self):\n",
    "        node = self.root\n",
    "        finished = node.game_finished\n",
    "        while not finished:\n",
    "            # Evaluate each non evaluated child\n",
    "            for action in node.legal_unvisited_actions:\n",
    "                new_node, _, _ = node.step(action)\n",
    "                self.initialize_node(new_node)\n",
    "            \n",
    "            # Choose the best child with a combinaison of Q (reward from last plays) and U (a priori value)\n",
    "            # upper confidence bound Q(s, a)+U(s, a)\n",
    "            # where  U(s, a)‚àùP(s, a)/(1+N(s, a)) \n",
    "            action = 1\n",
    "            node, _, finished = node.step(action)\n",
    "            self.initialize_node(node)\n",
    "            \n",
    "\n",
    "        # Backtrack stats\n",
    "        node.update_stats(node.winner)\n",
    "        \n",
    "\n",
    "    def get_competitive_action(self):\n",
    "        return max_rand(self.children, key=lambda x: 0 if x is None else x.n_playouts)\n",
    "    \n",
    "    def get_exploratory_action(self):\n",
    "        temperature = 1 if self.root.depth < 10 else 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
