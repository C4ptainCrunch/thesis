
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

<title>Playing Awale with MCTS</title>

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "displayMath": [["$$", "$$"], ["\\[", "\\]"]], "processEscapes": true, "processEnvironments": true}})</script>

    <script id="pseudocode-script" src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
    
    <script src="_static/jquery.js"></script>
    <script src="_static/proof.js"></script>

    <script type="module" src="_static/js/custom.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
  <div data-controller="notebook-toggle" data-notebook-toggle-show-value="true">
    
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section class="first-page">
    <h1>Playing Awale with MCTS</h1>
    <h2>Master thesis submitted in partial fulfillment of the requirements
    for the degree of Master of Science in Applied Sciences and Engineering:&nbsp;Computer Science
    </h2>

    2020-2021

    <p>
        Nikita Marchant<br>
        Promotor: Prof. Bernard Manderick
    </p>
</section><div id="abstract">
<h1>Abstract</h1><p>Awale is a popular board game played since centuries in Africa and more recently around the world. It has simple rules but a gameplay interesting enough to be played in competitions. We introduce Game Theory frameworks such as perfect information zero-sum games, extensive form representations and minimax trees. We then review various artificial intelligence approaches to play Awale and board games in general: Retrograde Analysis, <span class="math notranslate nohighlight">\(\alpha\beta\)</span>-Pruning Minimax and Monte Carlo Tree Search (MCTS); we look into variants of MCTS such as Upper Confidence for Trees (UCT) and heavy playouts. We then describe a statistical framework to compare different algorithms, show that the strength relation between them is not necessarily transitive and set the rules for a tournament between selected agents. Finally, we run experiments to tune the performances of the selected agents and play a full tournament between them. We show that UCT and heavy playouts yield the best results.</p>
</div><div class="contents topic" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#introduction" id="id75">Introduction</a></p></li>
<li><p><a class="reference internal" href="#awale" id="id76">Awale</a></p>
<ul>
<li><p><a class="reference internal" href="#mancala" id="id77">Mancala</a></p></li>
<li><p><a class="reference internal" href="#rules-of-the-game" id="id78">Rules of the game</a></p></li>
<li><p><a class="reference internal" href="#implementation-of-the-rules" id="id79">Implementation of the rules</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#awale-and-game-theory" id="id80">Awale and Game Theory</a></p>
<ul>
<li><p><a class="reference internal" href="#basic-game-theoretic-concepts" id="id81">Basic game theoretic concepts</a></p></li>
<li><p><a class="reference internal" href="#implementation-of-the-tree-representation" id="id82">Implementation of the tree representation</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#artificial-intelligence-approaches-to-play-awale" id="id83">Artificial Intelligence approaches to play Awale</a></p>
<ul>
<li><p><a class="reference internal" href="#naive-agents" id="id84">Naive agents</a></p></li>
<li><p><a class="reference internal" href="#depth-limited-minimax" id="id85">Depth-limited Minimax</a></p></li>
<li><p><a class="reference internal" href="#retrograde-analysis" id="id86">Retrograde analysis</a></p></li>
<li><p><a class="reference internal" href="#monte-carlo-tree-search" id="id87">Monte Carlo Tree Search</a></p>
<ul>
<li><p><a class="reference internal" href="#algorithm" id="id88">Algorithm</a></p></li>
<li><p><a class="reference internal" href="#strength" id="id89">Strength</a></p></li>
<li><p><a class="reference internal" href="#implementation" id="id90">Implementation</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#monte-carlo-tree-search-variants" id="id91">Monte Carlo tree search variants</a></p>
<ul>
<li><p><a class="reference internal" href="#upper-confidence-bounds-for-trees" id="id92">Upper Confidence Bounds for Trees</a></p></li>
<li><p><a class="reference internal" href="#heavy-playouts" id="id93">Heavy playouts</a></p></li>
<li><p><a class="reference internal" href="#other-approaches-and-related-work" id="id94">Other approaches and related work</a></p>
<ul>
<li><p><a class="reference internal" href="#all-moves-as-first" id="id95">All moves as first</a></p></li>
<li><p><a class="reference internal" href="#alpha-zero" id="id96">Alpha Zero</a></p></li>
<li><p><a class="reference internal" href="#related-work" id="id97">Related work</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#method" id="id98">Method</a></p>
<ul>
<li><p><a class="reference internal" href="#comparing-algorithms" id="id99">Comparing algorithms</a></p>
<ul>
<li><p><a class="reference internal" href="#how-to-compare-a-and-b" id="id100">How to compare A and B</a></p></li>
<li><p><a class="reference internal" href="#transitivity-of-the-strength-relation" id="id101">Transitivity of the strength relation</a></p></li>
<li><p><a class="reference internal" href="#how-to-compare-more-than-two-agents" id="id102">How to compare more than two agents</a></p></li>
<li><p><a class="reference internal" href="#champion-selection" id="id103">Champion selection</a></p></li>
<li><p><a class="reference internal" href="#tournament-solution" id="id104">Tournament solution</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#experimental-setup" id="id105">Experimental setup</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#experiments" id="id106">Experiments</a></p>
<ul>
<li><p><a class="reference internal" href="#id45" id="id107">Champion selection</a></p>
<ul>
<li><p><a class="reference internal" href="#varepsilon-greedy" id="id108"><span class="math notranslate nohighlight">\(\varepsilon\)</span>-Greedy</a></p></li>
<li><p><a class="reference internal" href="#mcts" id="id109">MCTS</a></p></li>
<li><p><a class="reference internal" href="#uct" id="id110">UCT</a></p></li>
<li><p><a class="reference internal" href="#id47" id="id111">Heavy playouts</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#tournament-results" id="id112">Tournament results</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#conclusion" id="id113">Conclusion</a></p></li>
</ul>
</div>
<section id="introduction">
<span id="sec-intro"></span><h1><a class="toc-backref" href="#id75"><span class="section-number">1. </span>Introduction</a><a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>Awale is a popular board game played mainly in Africa. The board has two rows of six pits, each containing four seeds in the initial state.</p>
<p>At each turn, the players move some seeds and can potentially capture some of them, according to deterministic rules. The goal of the game is to capture more seeds than one’s opponent.</p>
<figure class="align-default" id="id52">
<span id="board"></span><img alt="_images/initial.jpg" src="_images/initial.jpg" />
<figcaption>
<p><span class="caption-number">Figure 1 </span><span class="caption-text">A typical Awale board in the initial state with both players on their side of the board.</span><a class="headerlink" href="#id52" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>This work explores different machine learning approaches to board games. In particular, we focus on MCTS, its evolution and variants as they proved to be good at beating humans in many games while not requiring domain-specific knowledge beyond the understanding of the rules.
We apply those techniques to Awale because the game is not as often studied as Go or Chess, while being complex enough to be interesting. It is challenging enough to be played in real-life championships but still simple enough that a single computer still has a chance to at least beat a moderate level human player.</p>
<p>In <a class="reference internal" href="#sec-awale"><span class="std std-numref">Section 2</span></a>, we present Awale in detail. We then introduce Game Theory frameworks in <a class="reference internal" href="#sec-game-theory"><span class="std std-numref">Section 3</span></a>.
<a class="reference internal" href="#sec-ai-awale"><span class="std std-numref">Section 4</span></a> reviews various approaches to solving Awale: retrograde analysis, <span class="math notranslate nohighlight">\(\alpha\beta\)</span>-pruning Minimax, and basic Monte Carlo Tree Search.
In <a class="reference internal" href="#sec-variants"><span class="std std-numref">Section 5</span></a>, we describe more advanced versions of MCTS and in particular UCT.
<a class="reference internal" href="#sec-method"><span class="std std-numref">Section 6</span></a> presents the method used in <a class="reference internal" href="#sec-experiments"><span class="std std-numref">Section 7</span></a> where we show some empirical results (simulations) allowing us to compare several algorithms and <a class="reference internal" href="#sec-conclusion"><span class="std std-numref">Section 8</span></a> concludes.</p>
<p>This document, its source, the code used to run the experiments and their results are available to download under an open-source license in a Git repository <a class="reference external" href="https://github.com/C4ptainCrunch/thesis">hosted on GitHub</a>. This document is also available in its original form as a web page on <a class="reference external" href="https://awale.ml">https://awale.ml</a>.</p>
</section>
<section id="awale">
<span id="sec-awale"></span><h1><a class="toc-backref" href="#id76"><span class="section-number">2. </span>Awale</a><a class="headerlink" href="#awale" title="Permalink to this headline">¶</a></h1>
<p>The subject of our study, Awale is an ancient, two player board game originating from Ghana.
This game is also sometimes called Awele, Oware, Owari or Ayo in the neighbouring countries, languages and cultures <a class="bibtex reference internal" href="#crane1982" id="id1">[Crane, 1982]</a>.</p>
<p>Originally, the game is played on the ground, by digging two rows of six small <em>pits</em>, each containing
stones, seeds or shells. In the present document, we name them <em>seeds</em>. The game is also often played on a wooden board symbolizing the original dirt pits.
The board can be schematized as in <a class="reference internal" href="#fig-initial-board"><span class="std std-numref">Figure 2</span></a>, every big circle representing a pit and every small disc representing a seed.
Numbers at the bottom right of each pit are the counts of seeds in each pit for better readability.
Each row of pits is owned by a player that sits in front of it (see <a class="reference internal" href="#board"><span class="std std-numref">Figure 1</span></a>).
For the sake of convenience, the players are named <em>North</em> and <em>South</em>.
The 6 pits from the top row belong to North and the 6 from the bottom to South.</p>
<p>The players take turns, a player removing all the seeds from a pit and placing them in other pits following the rules. This is called sowing the seeds. This can result in a configuration in which the player is allowed to capture some seeds according to the rules.
The goal for each player is to capture more seeds than his opponent.
The rules vary slightly across countries and are detailed in <a class="reference internal" href="#sec-rules"><span class="std std-numref">Section 2.2</span></a>.</p>
<figure class="align-default" id="id53">
<span id="fig-initial-board"></span><img alt="_images/index_8_0.svg" src="_images/index_8_0.svg" /><figcaption>
<p><span class="caption-number">Figure 2 </span><span class="caption-text">A schematized view of the initial state of the board.</span><a class="headerlink" href="#id53" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<section id="mancala">
<span id="sec-mancala"></span><h2><a class="toc-backref" href="#id77"><span class="section-number">2.1. </span>Mancala</a><a class="headerlink" href="#mancala" title="Permalink to this headline">¶</a></h2>
<p>The Mancala games are an ancient family of games that are played on many continents <a class="bibtex reference internal" href="#devoogt2008" id="id2">[Voogt, 2014]</a>, Awale being one of them.
The word mancala comes from the Arabic word ‘نقلة’, transliterated as ‘naqala’ and literally meaning ‘to move’.</p>
<p>Like Awale, Mancala games can consist of rows of pits, some of them having more than two rows (see <a class="reference internal" href="#bao"><span class="std std-numref">Figure 3</span></a>) and sometimes extra pits with a special role. Mancala games can sometimes be played by more than two players.</p>
<figure class="align-default" id="id54">
<span id="bao"></span><img alt="_images/bao.jpg" src="_images/bao.jpg" />
<figcaption>
<p><span class="caption-number">Figure 3 </span><span class="caption-text">A wooden Bao game <a class="footnote-reference brackets" href="#source-bao" id="id3">1</a></span><a class="headerlink" href="#id54" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>There are too many variants of the Mancala games to list them all here, but a
few notable ones are Awale, Wari, Bao, Congkak and Kalah.</p>
<p>Mancala games in general, while less known than Chess or Go, are quite popular and
are played in tournaments around the world, both in offline and online competitions <a class="bibtex reference internal" href="#owaresociety" id="id4">[Society, 2020]</a><a class="bibtex reference internal" href="#fandom-tournaments" id="id5">[World, 2020]</a>.</p>
<p>In particular, Kalah is a commercial, modern variant of Mancala, introduced in the 1950s by William Julius Champion Jr., that is widespread in the United States. <a class="bibtex reference internal" href="#irving2000solving" id="id6">[Irving, 2000]</a>. This variant has been studied in Artificial Intelligence as early as 1964 by <a class="bibtex reference internal" href="#russel1964" id="id7">[Russel, 1964]</a>.
Nowadays, Kalah is often used as an example game in computer science courses.
Other Mancala games have been studied in Computer Science and Artificial Intelligence <a class="bibtex reference internal" href="#devoogt2008" id="id8">[Voogt, 2014]</a>. Tournaments opposing computers on both sides have been organized multiple times, notably in the Computer Olympiad organized by the International Computer Games Association <a class="bibtex reference internal" href="#icga-olympiad" id="id9">[Olympiad, 2000]</a>.</p>
</section>
<section id="rules-of-the-game">
<span id="sec-rules"></span><h2><a class="toc-backref" href="#id78"><span class="section-number">2.2. </span>Rules of the game</a><a class="headerlink" href="#rules-of-the-game" title="Permalink to this headline">¶</a></h2>
<p>The basic rules of Awale are the same everywhere but there are some minor differences around the globe and in the literature.
The rules presented here and implemented later in this work are inspired by <a class="bibtex reference internal" href="#goot2001" id="id10">[Goot, 2000]</a> and adapted by us.</p>
<p>The goal for each player is to capture more seeds than his opponent. Because the
game has 48 seeds, capturing 25 is enough for a player to win and ends the game.</p>
<p>Each player plays alternatively, without the right to pass their turn. A
player’s turn consists of choosing one of his non-empty pits, picking all seeds
contained in the pit and sowing them one by one in every consecutive pit on the right
(rotating counter-clockwise). The player thus has at most 6 possible moves at
each turn (one per non-empty pit owned by him).</p>
<p>Usually, the player that starts the game is the oldest player. In this work, South always plays first.</p>
<p>In this work, the pits of a player are numbered left to right from his point of view as shown in <a class="reference internal" href="#fig-pit-numbering"><span class="std std-numref">Figure 4</span></a>, <span class="math notranslate nohighlight">\(1\)</span> being the leftmost pit of South, until <span class="math notranslate nohighlight">\(6\)</span> at the far right. The same holds for North: <span class="math notranslate nohighlight">\(1'\)</span> to <span class="math notranslate nohighlight">\(6'\)</span>.</p>
<figure class="align-default" id="id55">
<span id="fig-pit-numbering"></span><img alt="_images/index_12_0.svg" src="_images/index_12_0.svg" /><figcaption>
<p><span class="caption-number">Figure 4 </span><span class="caption-text">Pit numbering convention: the pits of a player are numbered left to right from his point of view.</span><a class="headerlink" href="#id55" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>As an example, in the initial state (<a class="reference internal" href="#fig-initial-board"><span class="std std-numref">Figure 2</span></a>), the first player to move is South (on the bottom) and they play <span class="math notranslate nohighlight">\(4\)</span> (highlighted in the figure in red), the board is in the state shown in <a class="reference internal" href="#fig-first-move"><span class="std std-numref">Figure 5</span></a>.</p>
<figure class="align-default" id="id56">
<span id="fig-first-move"></span><img alt="_images/index_15_0.svg" src="_images/index_15_0.svg" /><figcaption>
<p><span class="caption-number">Figure 5 </span><span class="caption-text">The board after the first move, where South played pit 4, in red.</span><a class="headerlink" href="#id56" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>When the last sowed seed is placed in a pit owned by the opponent and, after sowing,
the pit contains two or three seeds, the content of the pit is captured by
the player and removed from the game. If the pit preceding the captured pit also
contains two or three seeds, it is also captured. The capture continues until a
pit without two or three seeds is encountered. When the capture is ended the
next player’s turn starts.</p>
<p>Otherwise, when the last sowed seed is placed in a pit that, after sowing, contains one seed, more
than 3 seeds or in the current player’s own pits, the turn of the player is ended without
any capture.
For example, if South plays <span class="math notranslate nohighlight">\(4\)</span> in the configuration shown in <a class="reference internal" href="#fig-pre-capture"><span class="std std-numref">Figure 6</span></a>, they are able to capture the seeds in pits <span class="math notranslate nohighlight">\(2'\)</span> and <span class="math notranslate nohighlight">\(3'\)</span> (highlighted in red in <a class="reference internal" href="#fig-post-capture"><span class="std std-numref">Figure 7</span></a>).</p>
<figure class="align-default" id="id57">
<span id="fig-pre-capture"></span><img alt="_images/index_18_0.svg" src="_images/index_18_0.svg" /><figcaption>
<p><span class="caption-number">Figure 6 </span><span class="caption-text">An example of a board configuration where South is to play pit 4, in red.</span><a class="headerlink" href="#id57" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id58">
<span id="fig-post-capture"></span><img alt="_images/index_20_0.svg" src="_images/index_20_0.svg" /><figcaption>
<p><span class="caption-number">Figure 7 </span><span class="caption-text">The resulting board after South played 4 in <a class="reference internal" href="#fig-pre-capture"><span class="std std-numref">Figure 6</span></a>. Pits 2’ and 3’ in red will be captured.</span><a class="headerlink" href="#id58" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>If the pit chosen by the player contains more than 12 seeds, the sowing makes
more than a full revolution of the board and the starting hole is skipped during the second
and subsequent passes.</p>
<p>If the current player’s opponent has no seed left in their side of board, the
current player has to play a move that gives them seeds if such a move exists.
This rule is called the ‘feed your opponent’.
In <a class="reference internal" href="#fig-feed"><span class="std std-numref">Figure 8</span></a>, South has to play pit 5 because playing pit 1 would leave the opponent without any move to play.</p>
<figure class="align-default" id="id59">
<span id="fig-feed"></span><img alt="_images/index_23_0.svg" src="_images/index_23_0.svg" /><figcaption>
<p><span class="caption-number">Figure 8 </span><span class="caption-text">South is forced to play pit 5, in red, because playing pit 1 would leave North without any seed to play.</span><a class="headerlink" href="#id59" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>When a player has captured more than 25 seeds the game ends and they win. If both
players have captured 24 seeds, the game ends by a draw. If the current player’s
pits are all empty, the game ends and the player with the most captures wins.</p>
<p>The last way to end the game is when a position is encountered twice in the
same game (there is a cycle): the game ends and the player with most captures
wins.</p>
</section>
<section id="implementation-of-the-rules">
<span id="sec-implem"></span><h2><a class="toc-backref" href="#id79"><span class="section-number">2.3. </span>Implementation of the rules</a><a class="headerlink" href="#implementation-of-the-rules" title="Permalink to this headline">¶</a></h2>
<p>You might be reading this document in the form of a web page or a pdf file but its source is a Jupyter Notebook <a class="bibtex reference internal" href="#jupyter" id="id11">[Kluyver, 2016]</a>. Jupyter Notebooks are documents mixing computer code (in this case Python code), the result of the execution of the code and text. These can be used to document experiments in the same place they are run.</p>
 <div class="no-print">
   <p>
     Most of this document can be read both with and without looking at the Python code as the implementation is available in Python as well as in pseudocode. If you are not fluent in Python or do not want to be distracted by the details of the implementation, you can choose to hide some of the notebooks cells (those that are also available as pseudocode) with the following toggle.
   </p>
   <label class="switcher">
     <div class="switch">
       <input type="checkbox" checked data-action="input->notebook-toggle#toggle">
       <span class="slider"></span>
     </div>
     Show notebook code and execution results
   </label>
</div><div class="no-web">
    Most of this document can be read both with and without looking at the Python code as the implementation is available in Python as well as in pseudocode. If you are not fluent in Python or do not want to be distracted by the details of the implementation, you can view this document in a web page on <a href="https://awale.ml" class="reference external">https://awale.ml</a> and choose to hide some of the notebooks cells (those that are also available as pseudocode) with the a toggle.
</div><p>However, even when activating this toggle, some sections of Python code will still be shown as the sections containing them would have little meaning without them.
Sections containing code are prefixed by <code class="code docutils literal notranslate"><span class="pre">[In]:</span></code> and the output of the code is shown immediately under it, prefixed by <code class="code docutils literal notranslate"><span class="pre">[Out]:</span></code>. An example is shown below.</p>
<blockquote>
<div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This is Python code</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;This was executed by Python&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This was executed by Python
</pre></div>
</div>
<p>In this subsection, we use Jupyter Notebooks cells to define in multiple steps a Python class holding the state of the game. We then successively inherit from it to add an implementation of the rules and some convenience methods. You can skip this and go to <a class="reference internal" href="#sec-game-theory"><span class="std std-numref">Section 3</span></a> if you do not care about the implementation.</p>
<dl class="simple">
<dt>We set the following encoding conventions in our Python implementation:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(0\)</span> is South, <span class="math notranslate nohighlight">\(1\)</span> is North,</p></li>
<li><p>player’s actions are numbered from <span class="math notranslate nohighlight">\(0\)</span> being the leftmost pit in front of him to <span class="math notranslate nohighlight">\(5\)</span> being the rightmost.</p></li>
</ul>
</dd>
</dl>
<p>First, we define a dataclass with the minimal attributes needed to store a state of the game.</p>
<blockquote>
<div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Game</span><span class="p">:</span>
    <span class="c1"># a 2x6 matrix containing the number of seeds in each pits</span>
    <span class="n">pits</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
    <span class="c1"># 0 for South and 1 for North</span>
    <span class="n">current_player</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># the number of seeds captured by each player</span>
    <span class="n">captures</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">))</span>
</pre></div>
</div>
</div></blockquote>
<p>We then add some utility methods that will be useful later.</p>
<blockquote>
<div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Game</span><span class="p">(</span><span class="n">Game</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">view_from_current_player</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns the board as seen by a player&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_player</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pits</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pits</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">current_player_pits</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns a 6-vector containing the pits owned by the current player&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_player</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pits</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pits</span><span class="p">[</span><span class="mi">6</span><span class="p">:]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">current_opponent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_player</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">adverse_pits_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns the indices in the `self.pits` array owned by the opposing player&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_player</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div></blockquote>
<p>After defining a class holding the state of the game, we implement the rules,
some of them being deliberately excluded from this implementation:</p>
<ul class="simple">
<li><p>loops in the game state are not checked (this considerably speeds up the computations and we did not encounter a loop in our preliminary work) <a class="footnote-reference brackets" href="#loop" id="id12">2</a>;</p></li>
<li><p>the ‘feed your opponent’ rule is removed; This makes the
rules simpler and we expect it does not tremendously change the complexity of the game.</p></li>
</ul>
<blockquote>
<div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Game</span><span class="p">(</span><span class="n">Game</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">legal_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns a list of indices for each legal action for the current player&quot;&quot;&quot;</span>
        <span class="n">our_pits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_player_pits</span>
        <span class="c1"># Return every pit of the player that contains some seeds</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span> <span class="k">if</span> <span class="n">our_pits</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">game_finished</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="c1"># Does the current player has an available move ?</span>
        <span class="n">no_moves_left</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_player_pits</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="c1"># Has one player captured more than half the total seeds ?</span>
        <span class="n">HALF_SEEDS</span> <span class="o">=</span> <span class="mi">24</span>  <span class="c1"># (there are 2*6*4=48 seeds in total)</span>
        <span class="n">enough_captures</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">HALF_SEEDS</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">HALF_SEEDS</span>

        <span class="c1"># Is it a draw ? Does both player have 24 seeds ?</span>
        <span class="n">draw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">HALF_SEEDS</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">HALF_SEEDS</span>

        <span class="c1"># If one of the above three are True, the game is finished</span>
        <span class="k">return</span> <span class="n">no_moves_left</span> <span class="ow">or</span> <span class="n">enough_captures</span> <span class="ow">or</span> <span class="n">draw</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">winner</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns the winner of the game or None if the game is not finished or in a draw&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">game_finished</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="c1"># The game is finished but both player have the same number of seeds: it&#39;s a draw</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="c1"># Else, there is a winner: the player with the most seeds</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">else</span> <span class="mi">1</span>
</pre></div>
</div>
</div></blockquote>
<p>We can now define the <code class="code docutils literal notranslate"><span class="pre">Game.step(i)</span></code> method that is called for every step of the game.
It takes a single parameter, <code class="code docutils literal notranslate"><span class="pre">i</span></code>, and plays the i-th pit in the current state.
This method returns the new state, the number of seeds captured and a boolean informing whether the game is finished.</p>
<blockquote>
<div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Game</span><span class="p">(</span><span class="n">Game</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Game</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Plays the action given as parameter and returns:</span>
<span class="sd">            - the new state as a new Game object,</span>
<span class="sd">            - the number of captured stones in the transition</span>
<span class="sd">            - a bool indicating if the new state is the end of the game</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">action</span> <span class="o">&lt;</span> <span class="mi">6</span><span class="p">,</span> <span class="s2">&quot;Illegal action&quot;</span>

        <span class="c1"># Translate the action index to a pit index</span>
        <span class="n">target_pit</span> <span class="o">=</span> <span class="n">action</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_player</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">action</span> <span class="o">-</span> <span class="mi">6</span>

        <span class="n">seeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pits</span><span class="p">[</span><span class="n">target_pit</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">seeds</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Illegal action: pit </span><span class="si">% i</span><span class="s2">s empty&quot;</span> <span class="o">%</span> <span class="n">target_pit</span>

        <span class="c1"># Copy the attributes of `Game` so that the original</span>
        <span class="c1"># stays immutable</span>
        <span class="n">pits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pits</span><span class="p">)</span>
        <span class="n">captures</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">)</span>

        <span class="c1"># Empty the pit targeted by the player</span>
        <span class="n">pits</span><span class="p">[</span><span class="n">target_pit</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Fill the next pits while there are still seeds</span>
        <span class="n">pit_to_sow</span> <span class="o">=</span> <span class="n">target_pit</span>
        <span class="k">while</span> <span class="n">seeds</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pit_to_sow</span> <span class="o">=</span> <span class="p">(</span><span class="n">pit_to_sow</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
            <span class="c1"># Do not fill the target pit ever</span>
            <span class="k">if</span> <span class="n">pit_to_sow</span> <span class="o">!=</span> <span class="n">target_pit</span><span class="p">:</span>
                <span class="n">pits</span><span class="p">[</span><span class="n">pit_to_sow</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">seeds</span> <span class="o">-=</span> <span class="mi">1</span>

        <span class="c1"># Count the captures of the play</span>
        <span class="n">round_captures</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># If the last seed was in a adverse pit we can try to collect seeds</span>
        <span class="k">if</span> <span class="n">pit_to_sow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">adverse_pits_idx</span><span class="p">:</span>
            <span class="c1"># If the pit contains 2 or 3 seeds, we capture them</span>
            <span class="k">while</span> <span class="n">pits</span><span class="p">[</span><span class="n">pit_to_sow</span><span class="p">]</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
                <span class="n">captures</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">current_player</span><span class="p">]</span> <span class="o">+=</span> <span class="n">pits</span><span class="p">[</span><span class="n">pit_to_sow</span><span class="p">]</span>
                <span class="n">round_captures</span> <span class="o">+=</span> <span class="n">pits</span><span class="p">[</span><span class="n">pit_to_sow</span><span class="p">]</span>
                <span class="n">pits</span><span class="p">[</span><span class="n">pit_to_sow</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="c1"># Select backwards the next pit to check</span>
                <span class="n">pit_to_sow</span> <span class="o">=</span> <span class="p">(</span><span class="n">pit_to_sow</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">12</span>

        <span class="c1"># Change the current player</span>
        <span class="n">current_player</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_player</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span>

        <span class="c1"># Create the new `Game` instance</span>
        <span class="n">new_game</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)(</span><span class="n">pits</span><span class="p">,</span> <span class="n">current_player</span><span class="p">,</span> <span class="n">captures</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">new_game</span><span class="p">,</span> <span class="n">round_captures</span><span class="p">,</span> <span class="n">new_game</span><span class="o">.</span><span class="n">game_finished</span>
</pre></div>
</div>
</div></blockquote>
<p>As the game rules are now implemented, we can add some methods to display the current state of the board to the user, either in textual mode or as an SVG file that can be displayed inline in this document.</p>
<blockquote>
<div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Game</span><span class="p">(</span><span class="n">Game</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">show_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Print a textual representation of the game to the standard output&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">game_finished</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Game finished&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Current player: </span><span class="si">{}</span><span class="s2"> - Score: </span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">current_player</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">current_player</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_player</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span><span class="p">],</span>
                <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">pits</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">seeds</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_from_current_player</span><span class="p">:</span>
            <span class="n">pits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:3}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">seeds</span><span class="p">))</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">pits</span><span class="p">[</span><span class="mi">6</span><span class="p">:])))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pits</span><span class="p">[:</span><span class="mi">6</span><span class="p">]))</span>

    <span class="k">def</span> <span class="nf">_repr_svg_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a SVG file representing the current state to be displayed in a notebook&quot;&quot;&quot;</span>
        <span class="n">board</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pits</span><span class="p">[</span><span class="mi">6</span><span class="p">:])),</span> <span class="bp">self</span><span class="o">.</span><span class="n">pits</span><span class="p">[:</span><span class="mi">6</span><span class="p">]])</span>
        <span class="k">return</span> <span class="n">board_to_svg</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>To show a minimal example of the implementation, we can now play a move and have its results displayed here.</p>
<blockquote>
<div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">Game</span><span class="p">()</span>  <span class="c1"># Create a new game</span>
<span class="n">g</span><span class="p">,</span> <span class="n">captures</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>  <span class="c1"># play the 5th pit (our implementation starts at 0)</span>
<span class="n">g</span>  <span class="c1"># Display the resulting board inline</span>
</pre></div>
</div>
</div></blockquote>
<figure class="align-default" id="id60">
<span id="fig-svg"></span><img alt="_images/index_42_0.svg" src="_images/index_42_0.svg" /><figcaption>
<p><span class="caption-number">Figure 9 </span><span class="caption-text">An example of the SVG representation of a game state</span><a class="headerlink" href="#id60" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="awale-and-game-theory">
<span id="sec-game-theory"></span><h1><a class="toc-backref" href="#id80"><span class="section-number">3. </span>Awale and Game Theory</a><a class="headerlink" href="#awale-and-game-theory" title="Permalink to this headline">¶</a></h1>
<p>In this section, we introduce the game-theoretic notions that are needed to understand the algorithms of <a class="reference internal" href="#sec-ai-awale"><span class="std std-numref">Section 4</span></a>. After introducing each notion, we apply it to Awale.
The notation and most conventions used for game-theoretic concepts are taken from <a class="bibtex reference internal" href="#maschlersolanzamir2013" id="id13">[Maschler, 2013]</a>.</p>
<section id="basic-game-theoretic-concepts">
<h2><a class="toc-backref" href="#id81"><span class="section-number">3.1. </span>Basic game theoretic concepts</a><a class="headerlink" href="#basic-game-theoretic-concepts" title="Permalink to this headline">¶</a></h2>
<p>The two main representations of games are the strategic form and the extensive form. Since the extensive-form representation is particularly  convenient for describing algorithms playing Awale, we  only present the extensive form. We also restrict this section to zero-sum  two-players finite games.
A  <em>zero-sum two-players finite game in extensive form</em>  is an ordered vector</p>
<div class="math notranslate nohighlight">
\[\Gamma = (N, V, E, x^{0}, (V_{i})_{i \in N}, O, u),\]</div>
<p>where:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(N= \{0,1\}\)</span> is the  set of  players,</p></li>
<li><p><span class="math notranslate nohighlight">\(x^{0}\)</span> is the initial state of the game,</p></li>
<li><p><span class="math notranslate nohighlight">\((V , E, x^{0})\)</span> is a  finite tree with root <span class="math notranslate nohighlight">\(x^{0}\)</span> called the game tree,</p></li>
<li><p><span class="math notranslate nohighlight">\((V_{0}, V_{1})\)</span> is a partition of the set of nodes that are not leaves,</p></li>
<li><p><span class="math notranslate nohighlight">\(O \subseteq \mathbb{R}\)</span> is the set of possible game outcomes,</p></li>
<li><p><span class="math notranslate nohighlight">\(u\)</span> is a function associating every leaf of the tree with a game outcome in the set <span class="math notranslate nohighlight">\(O\)</span>.</p></li>
</ul>
</div></blockquote>
<p>An outcome is a description of what happens when the game terminates. For zero-sum games, it is a real number corresponding to the gain of player 0 or, equivalently, the loss of player 1.</p>
<p>The set <span class="math notranslate nohighlight">\(V_{i}\)</span> contains all nodes at which player <span class="math notranslate nohighlight">\(i\)</span> is to play. In <em>sequential games</em>, players take turns.  This implies that a node at depth <span class="math notranslate nohighlight">\(i\)</span> belongs to <span class="math notranslate nohighlight">\(V_{0}\)</span> iff <span class="math notranslate nohighlight">\(i\)</span> is even.</p>
<div class="proof proof-type-application">

    <div class="proof-title">
        <span class="proof-type">Application </span>
        
    </div><div class="proof-content">
<p>Awale is a sequential zero-sum game where the  players 0 and 1 are respectively called South and North and <span class="math notranslate nohighlight">\(O=\{+1,-1,0\}\)</span>, respectively  meaning South wins, North wins or draw. Each node represents a state of the game and belongs either to <span class="math notranslate nohighlight">\(V_{0}\)</span> or <span class="math notranslate nohighlight">\(V_{1}\)</span>. In the first case, South is to play whereas, in the second one, North is to play. Each node has between 0 and 6 children corresponding to the possible states resulting from the move of the player ‘owning’ that node.</p>
<p>For instance, the root <span class="math notranslate nohighlight">\(x^{0}\)</span> of the game tree (the initial state) belongs to <span class="math notranslate nohighlight">\(V_{0}\)</span>, meaning South is to play in the initial state (see <a class="reference internal" href="#fig-initial-board"><span class="std std-numref">Figure 2</span></a>).  The root <span class="math notranslate nohighlight">\(x^{0}\)</span> has six children corresponding to the six possible states resulting from  South’s move. Each of these children belongs to <span class="math notranslate nohighlight">\(V_{1}\)</span>, meaning North is to play in these six states. Each of these six states at depth 1  in turn has six children corresponding to the six possible states resulting from North’s move. We thus have 36 states at depth 2 and they all belong to <span class="math notranslate nohighlight">\(V_{0}\)</span>, and so on.</p>
</div></div><p>A <em>perfect information</em> game is such that every player who is to take an action knows the current state of the game, meaning that they know all the actions in the game that led to the current point in the play. This is not the case if, for instance, the players have cards and hide them as in poker.</p>
<div class="proof proof-type-application">

    <div class="proof-title">
        <span class="proof-type">Application </span>
        
    </div><div class="proof-content">
<p>It is easy to see that Awale is a perfect information game.</p>
</div></div><p>Let us define a mapping <span class="math notranslate nohighlight">\(A\)</span> associating to each node <cite>x</cite> of a game tree the set <span class="math notranslate nohighlight">\(A(x)\)</span> of its children.  A <em>strategy</em> for player <span class="math notranslate nohighlight">\(i\)</span> is a function <span class="math notranslate nohighlight">\(s_{i}\)</span> mapping each node <span class="math notranslate nohighlight">\(x \in V_{i}\)</span> to an element in <span class="math notranslate nohighlight">\(A(x)\)</span>. In other words, a strategy for player <span class="math notranslate nohighlight">\(i\)</span> tells us what player <span class="math notranslate nohighlight">\(i\)</span> is going to play at each node of the tree where they are to play. The set of all possible strategies for player <span class="math notranslate nohighlight">\(i\)</span> is denoted by <span class="math notranslate nohighlight">\(S_{i}\)</span>.
A <em>strategy vector</em> is a pair of strategies <span class="math notranslate nohighlight">\(s = (s_{0}, s_{1} )\)</span>, one for each player. Notice that a strategy vector completely specifies a path in the game tree down to a leaf. A strategy vector <span class="math notranslate nohighlight">\(s\)</span> therefore identifies a single outcome and <span class="math notranslate nohighlight">\(u(s)\)</span> can be used to denote that outcome.</p>
<div class="proof proof-type-application">

    <div class="proof-title">
        <span class="proof-type">Application </span>
        
    </div><div class="proof-content">
<p>In the case of Awale, for any <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(A(x)\)</span> contains at most six nodes.</p>
</div></div><p>When the only outcomes of a two-player game are ‘player 0 wins’, ‘player 1 wins’ and ‘draw’,
it is convenient to code these outcomes by <span class="math notranslate nohighlight">\(+1, -1\)</span> and <span class="math notranslate nohighlight">\(0\)</span> respectively, as we did higher for Awale.
A <em>winning strategy for player 0</em>  is then defined as a strategy <span class="math notranslate nohighlight">\((s_{0},s_{1})\)</span>
such that <span class="math notranslate nohighlight">\(u(s_{0},s_{1}) = 1\)</span>  for all <span class="math notranslate nohighlight">\(s_{1} \in S_{1}\)</span>. A strategy <span class="math notranslate nohighlight">\(s_{0}\)</span> of
player 0 is called a strategy guaranteeing at least a draw if
<span class="math notranslate nohighlight">\(u(s_{0}, s_{1}) \in \{0, 1\}\)</span>, for all <span class="math notranslate nohighlight">\(s_{1} \in S_{1}\)</span>.
Similar definitions hold  for player 1.
We can now state an important result due to the founder of game theory.</p>
<div class="proof proof-type-theorem" id="id61">
<span id="theo-vonneumann"></span>
    <div class="proof-title">
        <span class="proof-type">Theorem 1</span>
        
            <span class="proof-title-name">(<a class="bibtex reference internal" href="#vonneumann1928" id="id14">[Neumann, 1928]</a>)</span>
        
    </div><div class="proof-content">
<p>In every two-player extensive form game with perfect information in which the set of outcomes is  <span class="math notranslate nohighlight">\(\{-1, 0, +1\}\)</span>, one and only one of the following three alternatives holds:</p>
<ol class="arabic simple">
<li><p>Player 0 has a winning strategy.</p></li>
<li><p>Player 1 has a winning strategy.</p></li>
<li><p>Each of the two players has a strategy guaranteeing at least a draw.</p></li>
</ol>
</div></div><div class="proof proof-type-application">

    <div class="proof-title">
        <span class="proof-type">Application </span>
        
    </div><div class="proof-content">
<p>This theorem obviously applies to Awale but the game tree of Awale is so large that it is very difficult to know which of the three statements is correct. This question has been solved only in 2003 (see <a class="reference internal" href="#sec-retrograde"><span class="std std-numref">Section 4.3</span></a>).</p>
</div></div><p>If player 0 chooses strategy <span class="math notranslate nohighlight">\(s_{0}\)</span>, they get <span class="math notranslate nohighlight">\(u(s_{0},s_{1})\)</span>, depending on the strategy <span class="math notranslate nohighlight">\(s_{1}\)</span> chosen by player 1. In the worst case, player 0 gets <span class="math notranslate nohighlight">\(\min_{s_{1} \in S_{1}} u(s_{0},s_{1})\)</span>. If player 0 wants to play safe, they better choose a strategy maximizing <span class="math notranslate nohighlight">\(\min_{s_{1} \in S_{1}} u(s_{0},s_{1})\)</span>.
Hence the <em>security level  of a game for player 0</em> is defined by</p>
<div class="math notranslate nohighlight">
\[\underline{v} = \max_{s_{0} \in S_{0}} \min_{s_{1} \in S_{1}} u(s_{0},s_{1}).\]</div>
<p>It is also called the <em>maximin value</em> of the game.
This is the payoff player 0 can  guarantee for himself, whatever the other player does.
A strategy <span class="math notranslate nohighlight">\(s^{*}_{0} \in S_{0}\)</span> is a <em>maximin strategy</em>  if <span class="math notranslate nohighlight">\(u(s^{*}_{0},s_{1}) \geq
\underline{v}_{0}\)</span> for all <span class="math notranslate nohighlight">\(s_{1} \in S_{1}\)</span>. A maximin strategy needs not to be unique.</p>
<p>We can also define the <em>minimax value</em> of a game as</p>
<div class="math notranslate nohighlight">
\[\overline{v} = \min_{s_{1} \in S_{1}} \max_{s_{0} \in S_{0}} u(s_{0},s_{1}).\]</div>
<p>Player 1 can guarantee that they will pay no more than <span class="math notranslate nohighlight">\(\overline{v}\)</span>.  A strategy of Player 1 that guarantees <span class="math notranslate nohighlight">\(\overline{v}\)</span> is called a minimax strategy. The maximin strategy of player 0 and the minimax strategy of player 1 are called <em>optimal strategies</em>.
Since we consider zero-sum games, a payment made by player 1 is a gain for player 0 and player 0 is guaranteed to receive no more than <span class="math notranslate nohighlight">\(\overline{v}\)</span> (if player 1 plays his minimax strategy). Hence, if  players 0 and 1 respectively play their maximin and minimax strategies, the gain of player 0 is at least <span class="math notranslate nohighlight">\(\underline{v}\)</span> and at most <span class="math notranslate nohighlight">\(\overline{v}\)</span>. It follows that <span class="math notranslate nohighlight">\(\underline{v} \leq \overline{v}\)</span>.</p>
<p>If <span class="math notranslate nohighlight">\(\underline{v} = \overline{v}\)</span>, then we say <em>the game has a value</em> and <span class="math notranslate nohighlight">\(\underline{v}=\overline{v}\)</span> is called the <em>value of the game</em>,  simply denoted by <span class="math notranslate nohighlight">\(v\)</span>. The value of the game represents the gain of player 0 (or the loss of player 1). Any of the  maximin and minimax strategies of players 0 and 1 respectively are then called <em>optimal strategies</em>.
Calculating the value of a game (when it exists), is called <em>solving the game</em>. it can be done by computing the maximin value or the minimax value (because they are equal).</p>
<p>Consider  a finite two-players zero-sum game with perfect information with <span class="math notranslate nohighlight">\(O=\{-1, 0, +1\}\)</span>  and let us apply <a class="reference internal" href="#theo-vonneumann"><span class="std std-numref">Theorem 1</span></a>.  There are three cases.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>If player 0 has a winning strategy, then <span class="math notranslate nohighlight">\(\underline{v}=1\)</span> and by the zero-sum property, <span class="math notranslate nohighlight">\(\overline{v}=1\)</span>. Whence the game has a value and it is 1.</p></li>
<li><p>If player 1 has a winning strategy, then <span class="math notranslate nohighlight">\(\underline{v}=-1\)</span> and by the zero-sum property, <span class="math notranslate nohighlight">\(\overline{v}=-1\)</span>. Whence the game has a value and it is -1.</p></li>
<li><p>If each of the two players has a strategy guaranteeing at least a draw, then each of them  plays such a strategy and the outcome of the game is a draw. So, <span class="math notranslate nohighlight">\(\underline{v}=0\)</span> and  <span class="math notranslate nohighlight">\(\overline{v}=0\)</span>. Whence anew the game has a value and it is 0.</p></li>
</ol>
</div></blockquote>
<p>We have just proved the following:</p>
<div class="proof proof-type-theorem" id="id62">
<span id="theo-value"></span>
    <div class="proof-title">
        <span class="proof-type">Theorem 2</span>
        
    </div><div class="proof-content">
<p>Every finite two-player zero-sum extensive-form game with perfect information and with <span class="math notranslate nohighlight">\(O=\{-1, 0, +1\}\)</span> has a value.</p>
</div></div><p>This is a special case of Theorem 4.43 in <a class="bibtex reference internal" href="#maschlersolanzamir2013" id="id15">[Maschler, 2013]</a>.</p>
<div class="proof proof-type-application">

    <div class="proof-title">
        <span class="proof-type">Application </span>
        
    </div><div class="proof-content">
<p>Awale has a value <span class="math notranslate nohighlight">\(v\)</span> and it belongs to <span class="math notranslate nohighlight">\(\{-1, 0, +1\}\)</span>. It is therefore possible  to solve Awale (see <a class="reference internal" href="#sec-retrograde"><span class="std std-numref">Section 4.3</span></a>).
When both players play their optimal strategy, South wins <span class="math notranslate nohighlight">\(v\)</span> and North pays <span class="math notranslate nohighlight">\(v\)</span>. If a player has a winning strategy, then it is also an optimal strategy. Any maximin strategy is an optimal policy.</p>
</div></div><p>Let us consider a game <span class="math notranslate nohighlight">\(\Gamma\)</span> with game tree <span class="math notranslate nohighlight">\((V,E,x^{0})\)</span>.
Given a node <span class="math notranslate nohighlight">\(x \in V\)</span>, we may consider the subtree with root <span class="math notranslate nohighlight">\(x\)</span>, which is  obtained by removing all nodes of <span class="math notranslate nohighlight">\(V\)</span> that are not descendants of <span class="math notranslate nohighlight">\(x\)</span>. The partition <span class="math notranslate nohighlight">\((V_{0},V_{1})\)</span> of the original game <span class="math notranslate nohighlight">\(\Gamma\)</span> naturally defines a partition of the nodes of the subtree. Similarly, the function <span class="math notranslate nohighlight">\(u\)</span> of the original game naturally associates every leaf of the subtree to a game outcome. Therefore,
the subtree of the game tree, which we will denote by <span class="math notranslate nohighlight">\(\Gamma(x)\)</span>, corresponds to a game that is called the subgame beginning at <span class="math notranslate nohighlight">\(x\)</span>.</p>
<div class="proof proof-type-application">

    <div class="proof-title">
        <span class="proof-type">Application </span>
        
    </div><div class="proof-content">
<p>Every subgame of Awale is a finite two-player zero-sum extensive-form game with perfect information and we can therefore appeal to <a class="reference internal" href="#theo-value"><span class="std std-numref">Theorem 2</span></a>. So, for every node <span class="math notranslate nohighlight">\(x \in V\)</span>, the subgame <span class="math notranslate nohighlight">\(\Gamma(x)\)</span> has a value, which is equal to the maximin value and the minimax value. It is also called the value of node <span class="math notranslate nohighlight">\(x\)</span>, denoted <span class="math notranslate nohighlight">\(v(x)\)</span>. It represents the gain of player 0 if, starting from node <span class="math notranslate nohighlight">\(x\)</span>, both players play their optimal strategy, i.e. maximin for player 0 and minimax for player 1.</p>
<p>Example. Suppose North has two seeds in pit  6’ while South has one seed in pit 2 and one in 4 (see <a class="reference internal" href="#fig-game"><span class="std std-numref">Figure 10</span></a>).
Suppose also both South and North have  captured 22 seeds. Suppose finally  South is to play. If South plays 2, then North plays 6’ and has no more seeds in his half board. The game ends with a draw because no player has captured more seeds than the other. If, on the contrary, South plays 4, then North plays 6’, captures two seeds in pit 2 and has no more seeds in his half board.  The game ends with a win for North because they have captured more seeds than South. This subgame tree is represented in <a class="reference internal" href="#fig-tree"><span class="std std-numref">Figure 11</span></a>. The optimal strategy for South is obviously to play 2 whereas the optimal strategy for North is the only available strategy, that is playing 6’. If both players apply their optimal strategy, the outcome is a draw and the value of the game is 0.</p>
</div></div><figure class="align-default" id="id63">
<span id="fig-game"></span><img alt="_images/index_46_0.svg" src="_images/index_46_0.svg" /><figcaption>
<p><span class="caption-number">Figure 10 </span><span class="caption-text">An nearly final position of Awale</span><a class="headerlink" href="#id63" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id64">
<span id="fig-tree"></span><a class="reference internal image-reference" href="_images/subgame.svg"><img alt="_images/subgame.svg" src="_images/subgame.svg" width="30%" /></a>
<figcaption>
<p><span class="caption-number">Figure 11 </span><span class="caption-text">The subgame tree corresponding to the position depicted in <a class="reference internal" href="#fig-game"><span class="std std-numref">Figure 10</span></a>.</span><a class="headerlink" href="#id64" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>The minimax tree of a game with game tree <span class="math notranslate nohighlight">\((V,E,x^{0})\)</span> is the 4-tuple <span class="math notranslate nohighlight">\((V,E,x^{0},m)\)</span> where <span class="math notranslate nohighlight">\(m:V\to \mathbb{R}\)</span> associates to each node its minimax value.</p>
<div class="proof proof-type-application">

    <div class="proof-title">
        <span class="proof-type">Application </span>
        
    </div><div class="proof-content">
<p>By <a class="reference internal" href="#theo-value"><span class="std std-numref">Theorem 2</span></a>, the minimax value of an Awale subgame is equal to the value of the subgame. The minimax tree can thus be used to find the optimal strategies.</p>
</div></div></section>
<section id="implementation-of-the-tree-representation">
<span id="sec-implem-tree"></span><h2><a class="toc-backref" href="#id82"><span class="section-number">3.2. </span>Implementation of the tree representation</a><a class="headerlink" href="#implementation-of-the-tree-representation" title="Permalink to this headline">¶</a></h2>
<p>We just saw that Awale can be represented as a tree where each node represents a state of the game and edges represent actions of the players. As many algorithms use this tree representation, we implement it in Python by inheriting from the <code class="code docutils literal notranslate"><span class="pre">Game()</span></code> class previously defined so that a state can hold references to its parent and children.</p>
<blockquote>
<div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">weakref</span> <span class="kn">import</span> <span class="n">ref</span><span class="p">,</span> <span class="n">ReferenceType</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">TreeGame</span><span class="p">(</span><span class="n">Game</span><span class="p">):</span>
    <span class="c1"># Hold an optional reference to the parent state</span>
    <span class="n">parent</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ReferenceType</span><span class="p">[</span><span class="n">Game</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># Hold a list of 6 optional references to the children</span>
    <span class="n">children</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">Game</span><span class="p">]]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div></blockquote>
<p>Next, we overload the <code class="docutils literal notranslate"><span class="pre">Game.step(i)</span></code> method so that we do not compute twice a state if it was already in the tree. If a new node was generated, we keep a reference to the parent when we create a new child.</p>
<blockquote>
<div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TreeGame</span><span class="p">(</span><span class="n">TreeGame</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># If we already did compute the children node, just return it</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">action</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">new_game</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">action</span><span class="p">]</span>
            <span class="n">captures</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">new_game</span><span class="o">.</span><span class="n">captures</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">current_player</span><span class="p">]</span>
                <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">captures</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">current_player</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">new_game</span><span class="p">,</span> <span class="n">captures</span><span class="p">,</span> <span class="n">new_game</span><span class="o">.</span><span class="n">game_finished</span>
        <span class="c1"># If not, call the original `step()` method and keep references in both directions</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_game</span><span class="p">,</span> <span class="n">captures</span><span class="p">,</span> <span class="n">finished</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">new_game</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="n">ref</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">new_game</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_game</span>
            <span class="k">return</span> <span class="n">new_game</span><span class="p">,</span> <span class="n">captures</span><span class="p">,</span> <span class="n">finished</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TreeGame</span><span class="p">(</span><span class="n">TreeGame</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">successors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">children</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">successors</span> <span class="o">=</span> <span class="n">children</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">successors</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">children</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">successors</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">unvisited_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">legal_unvisited_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unvisited_actions</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">legal_actions</span><span class="p">)))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">expanded_children</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_fully_expanded</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">legal_actions</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">legal_actions</span><span class="p">)</span>
        <span class="n">unvisited_actions</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unvisited_actions</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">legal_actions</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">unvisited_actions</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_leaf_game</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span> <span class="o">==</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="mi">6</span>
</pre></div>
</div>
</div></blockquote>
</section>
</section>
<section id="artificial-intelligence-approaches-to-play-awale">
<span id="sec-ai-awale"></span><h1><a class="toc-backref" href="#id83"><span class="section-number">4. </span>Artificial Intelligence approaches to play Awale</a><a class="headerlink" href="#artificial-intelligence-approaches-to-play-awale" title="Permalink to this headline">¶</a></h1>
<p>Many algorithms have been proposed and studied to play zero-sum sequential perfect information games.
We start by describing simple algorithms to be used as a baseline (random and greedy) and then continue with algorithms computing the exact minimax tree, either starting from the root (<span class="math notranslate nohighlight">\(\alpha\beta\)</span> pruning Minimax) or the leaves (retrograde analysis). As those are often impractical for big game trees, we present their depth-limited variants (depth-limited minimax and end-game databases). We then explore approaches that overcome the limitation of the previous algorithms by iteratively estimating the value of promising sub-trees of the game such as Monte Carlo tree search (MCTS) and the most recent approach from Deepmind: Alpha Zero <a class="bibtex reference internal" href="#alphazero" id="id16">[Silver, 2018]</a>.</p>
<p>We quickly present and implement the above-mentioned algorithms and then focus on MCTS and its variants as they are computationally feasible and do not require expert knowledge about the given game to make reasonable decisions.</p>
<div class="code-intro"><p>Before presenting those, we describe a <code class="code docutils literal notranslate"><span class="pre">Player</span></code> class that every algorithm implementation will reuse.
The <code class="code docutils literal notranslate"><span class="pre">Player</span></code> class keeps track of the game state internally.
At each turn of the game, the <code class="code docutils literal notranslate"><span class="pre">Player</span></code> is called with the method <code class="code docutils literal notranslate"><span class="pre">play()</span></code> to inform it of the action played by their opponent
(and thus update their internal state) and then chooses an action with <code class="code docutils literal notranslate"><span class="pre">get_action()</span></code>,
updates once more their internal state and then outputs their action for the opposing <code class="code docutils literal notranslate"><span class="pre">Player</span></code> to use.</p>
</div><div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Player</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">their_action</span><span class="p">):</span>
        <span class="c1"># If we are the first player, there is no previous action</span>
        <span class="k">if</span> <span class="n">their_action</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Play the opponent&#39;s move</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">their_action</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">player_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Only the first player can have their_action=-1&quot;</span>

        <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_action</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">action</span>
</pre></div>
</div>
</div><section id="naive-agents">
<span id="sec-naive"></span><h2><a class="toc-backref" href="#id84"><span class="section-number">4.1. </span>Naive agents</a><a class="headerlink" href="#naive-agents" title="Permalink to this headline">¶</a></h2>
<p>In addition to the above-listed algorithms, we also implement the two most basic agents: a random and a greedy player.
While not having any interest per se due to their simplicity and low strength, these will serve us later as a baseline to compare their strength to some more advanced algorithms.</p>
<p>The <em>random agent</em> is the simplest algorithm we can think of and does not use any intelligence at all: it lists all the legal actions it can play and chooses one uniformly at random.</p>
<p>A pseudocode implementation of this agent can be found below, where the <span class="math notranslate nohighlight">\(\textrm{GetAction()}\)</span> procedure is called every time the agent has to pick a move at its turn and <span class="math notranslate nohighlight">\(x\)</span> is the node of the game tree representing the current state of the game.</p>
<pre class="pseudocode"  data-controller="pseudocode">

          \begin{algorithm}
          \caption{Random agent}
          \begin{algorithmic}
          \PROCEDURE{GetAction}{node $x$}
             \RETURN \CALL{ChooseAtRandom}{$A(x)$}
          \ENDPROCEDURE
          \end{algorithmic}
          \end{algorithm}

</pre><div class="code-intro"><p>This is then implemented in Python with the following code.</p>
</div><div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RandomPlayer</span><span class="p">(</span><span class="n">Player</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">player_id</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">Game</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">player_id</span> <span class="o">=</span> <span class="n">player_id</span>

    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">legal_actions</span><span class="p">)</span>
</pre></div>
</div>
</div><p>The second simplest algorithm is <span class="math notranslate nohighlight">\(\varepsilon\)</span>-<em>Greedy</em>: an agent that tries to maximize an <em>immediate reward</em> at each turn: the number of seeds captured during that turn.
The <span class="math notranslate nohighlight">\(\varepsilon \in [0, 1]\)</span> parameter introduces randomness: at each turn, the agent draws a number <span class="math notranslate nohighlight">\(e\)</span> in the uniform distribution <span class="math notranslate nohighlight">\(\mathcal{U}(0, 1)\)</span>, if <span class="math notranslate nohighlight">\(e &gt; \varepsilon\)</span>, the agent chooses an action uniformly at random, else it maximizes the immediate reward.</p>
<pre class="pseudocode"  data-controller="pseudocode">

          \begin{algorithm}
          \caption{$\varepsilon$-Greedy agent}
          \begin{algorithmic}
          \PROCEDURE{ImmediateReward}{node $x$}
              \IF{$x$ is a final node}
                  \IF{agent wins}
                      \RETURN $\infty$
                  \ELSE
                      \RETURN $-\infty$
                  \ENDIF
              \ELSE
                  \RETURN amount of stones captured by playing $x$
              \ENDIF
          \ENDPROCEDURE
          \PROCEDURE{GetAction}{node $x$}
            \IF{$\mathcal{U}(0, 1) < \varepsilon$}
              \RETURN \CALL{ChooseAtRandom}{$A(x)$}
            \ELSE
              \RETURN $\operatorname{argmax}_{y \in A(x)}$ \CALL{ImmediateReward}{$y$}
            \ENDIF
          \ENDPROCEDURE
          \end{algorithmic}
          \end{algorithm}

</pre><div class="code-intro"><p>Implemented in Python as</p>
</div><div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GreedyPlayer</span><span class="p">(</span><span class="n">Player</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">player_id</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">Game</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">player_id</span> <span class="o">=</span> <span class="n">player_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>

    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Choose a move</span>
        <span class="n">children</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">legal_action</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">legal_actions</span><span class="p">:</span>
            <span class="n">new_state</span><span class="p">,</span> <span class="n">captures</span><span class="p">,</span> <span class="n">finished</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">legal_action</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">new_state</span><span class="o">.</span><span class="n">winner</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">win</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">elif</span> <span class="n">new_state</span><span class="o">.</span><span class="n">winner</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">player_id</span><span class="p">:</span>
                <span class="n">win</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">win</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="n">children</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">legal_action</span><span class="p">,</span> <span class="n">captures</span><span class="p">,</span> <span class="n">win</span><span class="p">))</span>

        <span class="c1"># order wins first, then by captures, then random</span>
        <span class="n">sorted_children</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">children</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">c</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="n">c</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="o">-</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()))</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">legal_actions</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">sorted_children</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">action</span>
</pre></div>
</div>
</div></section>
<section id="depth-limited-minimax">
<span id="sec-minimax"></span><h2><a class="toc-backref" href="#id85"><span class="section-number">4.2. </span>Depth-limited Minimax</a><a class="headerlink" href="#depth-limited-minimax" title="Permalink to this headline">¶</a></h2>
<p>The <em>minimax algorithm</em> performs a complete depth-first search used to compute the minimax tree.
It is a recursive algorithm that computes the value of a node based on the value of its children. In the case of a terminal node, the value is trivial to compute and depends solely on the winner. Otherwise, for <em>inner</em> (non-terminal) nodes, the value is computed as the max (resp. min) of the value of the children if the node is at an even (resp. odd) depth.</p>
<p>In Awale and other complex games, as shown before, generating the whole tree is computationally very hard and not practical. <a class="bibtex reference internal" href="#shannon1988" id="id17">[Shannon, 1988]</a> proposed an adaptation of the minimax where instead of generating the whole tree, it is generated up to depth <span class="math notranslate nohighlight">\(d\)</span>. Nodes at depth <span class="math notranslate nohighlight">\(d\)</span> are then considered as leaves and their value are estimated using a heuristic instead of being computed by recursively computing the values of their children.</p>
<p>The heuristic used should estimate the value of the node only by inspecting the state of the game and can be of varying complexity. A simple approach as shown here is to count the difference in the number of seeds each player has captured. Because heuristics are most often crafted by hand using human knowledge of the game, exploring more complex ones is beyond the scope of this work.</p>
<p>The complexity of the depth-limited minimax algorithm is <span class="math notranslate nohighlight">\(O(b^d)\)</span> where <span class="math notranslate nohighlight">\(b\)</span> is the average branching factor. A well-known optimization of this algorithm called <em>alpha-beta pruning minimax</em> (<span class="math notranslate nohighlight">\(\alpha\beta\)</span> minimax) returns the same result and has a best-case performance of <span class="math notranslate nohighlight">\(O(\sqrt{b^d})\)</span> <a class="bibtex reference internal" href="#russell2019artificial" id="id18">[Russell, 2019]</a>.
The algorithm keeps track of two values, <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>, which hold the minimum score that the maximizing player is assured of and the maximum score that the minimizing player is assured of.
Initially, <span class="math notranslate nohighlight">\(\alpha = -\infty\)</span> and <span class="math notranslate nohighlight">\(\beta = +\infty\)</span>: both players begin with their worst possible score.
If the maximum score that the minimizing player is assured of becomes less than the minimum score that the maximizing player is assured of (so <span class="math notranslate nohighlight">\(\beta &lt; \alpha\)</span>), the maximizing player does not need to consider further children of this node (it prunes the node) as they are certain that the minimizing player would never play this move.
This pruning of entire sub-trees is where the complexity gain arises from.
As <span class="math notranslate nohighlight">\(\alpha\beta\)</span> minimax has no disadvantage over minimax and has lower computational complexity, this is the one shown here.</p>
<pre class="pseudocode"  data-controller="pseudocode">

          \begin{algorithm}
          \caption{Depth-limited $\alpha\beta$-minimax}
          \begin{algorithmic}
          \PROCEDURE{GetAction}{node $x$}
            \RETURN $\operatorname{argmax}_{y \in A(x)}$ \CALL{Minimax}{$y$, CutoffDepth, $-\infty$, $\infty$, False}
          \ENDPROCEDURE
          \PROCEDURE{Minimax}{node $x$, depth, alpha, beta, isMaximizing}
            \IF{depth = 0 \OR $x$ is final}
              \RETURN \CALL{Evaluate}{$x$}
            \ENDIF

            \IF{isMaximizing}
              \STATE  value $\gets -\infty$
              \FORALL{$y$ in $A(x)$}
                  \STATE  value $\gets$ max(value, \CALL{Minimax}{y, depth - 1, alpha, beta, False})
                  \STATE  alpha $\gets$ max(alpha, value)
                  \IF{alpha >= beta}
                      \BREAK
                  \ENDIF
              \ENDFOR
              \RETURN value
            \ELSE
                \STATE  value $\gets \infty$
                \FORALL{$y$ in $A(x)$}
                  \STATE  value $\gets$ min(value, \CALL{Minimax}{y, depth - 1, alpha, beta, True})
                  \STATE  alpha $\gets$ min(beta, value)
                  \IF{alpha >= beta}
                      \BREAK
                  \ENDIF
              \ENDFOR
              \RETURN value
            \ENDIF

          \ENDPROCEDURE
          \end{algorithmic}
          \end{algorithm}

</pre></section>
<section id="retrograde-analysis">
<span id="sec-retrograde"></span><h2><a class="toc-backref" href="#id86"><span class="section-number">4.3. </span>Retrograde analysis</a><a class="headerlink" href="#retrograde-analysis" title="Permalink to this headline">¶</a></h2>
<p>Board games can mostly be divided into two separate categories. The first category consists
of games where the number of pieces on the board increases over time, because players add pieces on the board during their turn. The state space increases over time: these are called <em>divergent games</em>.
Examples of these games are Tick Tack Toe, Connect Four and Go.
The second category consists of games where the number of pieces on the board decreases over time because players may capture pieces over time. Those are called <em>convergent games</em>.
Games that belong to this category are Chess, Checkers, Backgammon and Awale <a class="bibtex reference internal" href="#vandenherik2002" id="id19">[Herik, 2002]</a>.</p>
<p>For both divergent and convergent games, search algorithms can compute the game value for positions near
the end of a game. However, for divergent games, the number of endgame
positions is so big that enumerating them all is computationally impossible (except for trivial
games like Tic-Tac-Toe). However, for convergent games, the number of positions
near the end of the game is small. Usually small enough to traverse them all, and collect
their game values in a database, a so-called <em>endgame database</em>.</p>
<p><em>Retrograde Analysis</em> computes endgame databases by going backwards from values of final
positions towards the initial position <a class="bibtex reference internal" href="#goot2001" id="id20">[Goot, 2000]</a>.
First, Retrograde Analysis identifies all final positions in which the game value is known.
By making reverse moves from these final positions the game value of some non-final positions can be deduced. And by making reverse moves from these newly computed non-final positions, the game value of other non-final positions can be deduced. This can continue either by running of available memory or by having enumerated all the legal positions in the game.</p>
<p>Ströhlein is the first researcher who came up with the idea to create endgame databases and applied his idea to Chess <a class="bibtex reference internal" href="#endgame1970" id="id21">[Ströhlein, 1970]</a>.
The first endgame database for Awale has been created by <a class="bibtex reference internal" href="#allis1995" id="id22">[Bal, 1995]</a> and was followed by many others, while the quest was ended by <a class="bibtex reference internal" href="#romein2003solving" id="id23">[Romein, 2003]</a> publishing a database for all legal positions.</p>
<p>The above-mentioned results for Kalah and Awale both use an almost brute-force
method to solve the game and use a database of all possible states. The database
used by <a class="bibtex reference internal" href="#romein2003solving" id="id24">[Romein, 2003]</a> for the 48 stone positions alone has 204 billion entries and weighs 178GiB.
Such a huge database is of course not practical and we thus think there is still room for
improvement if we can create an agent with a policy that does not need an
exhaustive database, even if the agent is not capable of a perfect play.</p>
</section>
<section id="monte-carlo-tree-search">
<span id="sec-mcts"></span><h2><a class="toc-backref" href="#id87"><span class="section-number">4.4. </span>Monte Carlo Tree Search</a><a class="headerlink" href="#monte-carlo-tree-search" title="Permalink to this headline">¶</a></h2>
<p>Monte Carlo Tree Search (MCTS) has been introduced by <a class="bibtex reference internal" href="#coulom2006mcts" id="id25">[Coulom, 2007]</a> as a formalization of Monte Carlo methods applied to tree search that were previously explored by others, among which <a class="bibtex reference internal" href="#bouzy2004montecarlo" id="id26">[Bouzy, 2004]</a>. Since then, MCTS has been a major advancement and topic of interest in the field of artificial intelligence research, particularly for games and planning problems.</p>
<p>MCTS explores the game tree based on random sampling of the game space. The principle of Monte Carlo tree search in games is based on many playouts. In each playout, a game is simulated out to the end by selecting moves at random. The final game value of each playout is then used to estimate the value of the non-terminal nodes in the game tree. This estimation is refined by every successive playout</p>
<p>A great benefit of MCTS is that, unlike depth-limited minimax, it is aheuristic: there is no need to estimate the value of non-terminal nodes with a domain specific heuristic. This, in turn, greatly reduces (or even removes) the need to acquire and incorporate domain knowledge. This explains our interest in the subject and the title of this work.</p>
<p>Because MCTS incrementally samples the game tree, we can stop the algorithm after any number of iterations (e.g. when our computational budget is exhausted) and still get a result without the need to explore the tree to a fixed depth like in <span class="math notranslate nohighlight">\(\alpha\beta\)</span> minimax.</p>
<section id="algorithm">
<span id="sec-mcts-algo"></span><h3><a class="toc-backref" href="#id88"><span class="section-number">4.4.1. </span>Algorithm</a><a class="headerlink" href="#algorithm" title="Permalink to this headline">¶</a></h3>
<figure class="align-default" id="id65">
<img alt="_images/mcts-algorithm.svg" src="_images/mcts-algorithm.svg" /><figcaption>
<p><span class="caption-number">Figure 12 </span><span class="caption-text">The 4 steps of MCTS <a class="bibtex reference internal" href="#chaslot2008monte" id="id27">[Chaslot, 2008]</a></span><a class="headerlink" href="#id65" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>To compute an estimate of the value <span class="math notranslate nohighlight">\(v(x)\)</span> of node <span class="math notranslate nohighlight">\(x\)</span>, game simulations (<em>playouts</em>) are run multiple times until the budget (usually a time or memory constraint) of the agent is exceeded. Each playout consists of these four steps: selection, expansion, simulation and back-propagation.</p>
<p>To be able to execute these steps, the algorithm needs to hold 3 counter for each node <span class="math notranslate nohighlight">\(y\)</span> it encounters during the simulation : <span class="math notranslate nohighlight">\(N_y\)</span> (the number of simulation that encountered node <span class="math notranslate nohighlight">\(y\)</span>), <span class="math notranslate nohighlight">\(W^S_y\)</span> and <span class="math notranslate nohighlight">\(W^N_y\)</span> (the number of simulations that encountered <span class="math notranslate nohighlight">\(y\)</span> and leading to a win respectively for South and North). The number of draws, <span class="math notranslate nohighlight">\(D_y = N_y - (W^S_y + W^N_y)\)</span> can be computed from the others counters. From these counters, a probability of North winning can be estimated by <span class="math notranslate nohighlight">\(W^N_y / N_y\)</span> if both players play randomly from <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>The MCTS algorithm starts by creating a tree <span class="math notranslate nohighlight">\(T\)</span> containing a single node: the game state we want to estimate the value of.
Then, for each playout, we repeat these four steps, starting at the root of the tree:</p>
<ol class="arabic simple">
<li><p>Selection: a leaf from <span class="math notranslate nohighlight">\(T\)</span> is selected by starting at the root node and repeatedly selecting a child until a leaf <span class="math notranslate nohighlight">\(l\)</span> of <span class="math notranslate nohighlight">\(T\)</span> is reached.</p></li>
<li><p>Expansion: create a node <span class="math notranslate nohighlight">\(c\)</span> by playing a move at random from <span class="math notranslate nohighlight">\(l\)</span> and adding it to <span class="math notranslate nohighlight">\(T\)</span> it as a child of <span class="math notranslate nohighlight">\(l\)</span>.</p></li>
<li><p>Simulation: play a game starting from <span class="math notranslate nohighlight">\(c\)</span> until a terminal node <span class="math notranslate nohighlight">\(e\)</span> of the game tree is reached.</p></li>
<li><p>Back-propagation: update the counters described above for each ancestor of <span class="math notranslate nohighlight">\(e\)</span> in <span class="math notranslate nohighlight">\(T\)</span> with the result of the simulation.</p></li>
</ol>
<p>The method for node selection during step 1 is called the <em>tree policy</em>. In the most basic version of MCTS, nodes are chosen at random. Variants (such as UCT in <a class="reference internal" href="#sec-uct"><span class="std std-numref">Section 5.1</span></a>) can use more sophisticated heuristics to choose more often nodes that should be explored first. In the simulation step, nodes to be played are chosen according to a <em>default policy</em>. In most variants of MCTS, the default policy is to make uniformly random moves but some variants may also use heuristics. We intentionally choose not to use heuristics for both policies in the pure MCTS implementation so we can compare it later to UCT that chooses moves in a formalized way with no domain knowledge.</p>
<pre class="pseudocode"  data-controller="pseudocode">

          \begin{algorithm}
          \caption{MCTS}
          \begin{algorithmic}
              \PROCEDURE{GetAction}{node $x$, duration}
                \STATE startTime $\gets$ \CALL{GetCurrentTime}{}
                \STATE endTime $\gets$ startTime + duration
                \WHILE{\CALL{GetCurrentTime}{} < endTime}
                  \STATE $y \gets$ \CALL{TreePolicy}{$x$}
                  \WHILE{$x$ is not final}
                    \STATE $y \gets$ \CALL{DefaultPolicy}{$y$}
                  \ENDWHILE
                  \STATE \CALL{BacktrackStats}{$y$}
                \ENDWHILE
                \RETURN $\operatorname{argmax}_{y \in A(x)}$ \CALL{Score}{$y$}
              \ENDPROCEDURE

              \PROCEDURE{TreePolicy}{node $x$}
                \WHILE{$ \exists y \in A(x) | N_y > 0$}
                \COMMENT{While at least a child of the node has been visited}
                  \STATE $unvisited$ $\gets$ $\{y \in A(x) | N_y = 0\}$
                  \IF{$unvisited \neq \emptyset$}

                    \STATE $x \gets$ \CALL{ChooseAtRandom}{$unvisited$}
                  \ELSE
                    \STATE $x \gets$ \CALL{ChooseAtRandom}{$A(x)$}
                  \ENDIF
                \ENDWHILE
                \RETURN x
              \ENDPROCEDURE

              \PROCEDURE{DefaultPolicy}{node $x$}
                \RETURN \CALL{ChooseAtRandom}{$A(x)$}
              \ENDPROCEDURE

              \PROCEDURE{Score}{node $x$}
                \RETURN $\frac{W_x - L_x}{N_x}$
              \ENDPROCEDURE

          \end{algorithmic}
          \end{algorithm}

</pre></section>
<section id="strength">
<span id="sec-mcts-perf"></span><h3><a class="toc-backref" href="#id89"><span class="section-number">4.4.2. </span>Strength</a><a class="headerlink" href="#strength" title="Permalink to this headline">¶</a></h3>
<p>We show that, despite its simplicity, this pure MCTS method is already better than a random agent.
The estimated value <span class="math notranslate nohighlight">\(\hat{v}(x) = (W^S_x- W^N_x)/N_x\)</span> of node <span class="math notranslate nohighlight">\(x\)</span> when <span class="math notranslate nohighlight">\(N_x\)</span> is large converges to a weighted average of the true value of the leaves of the subtree <span class="math notranslate nohighlight">\(\Gamma(x)\)</span> rooted at <span class="math notranslate nohighlight">\(x\)</span>.
Indeed, for every leaf <span class="math notranslate nohighlight">\(l\)</span> of the game, <span class="math notranslate nohighlight">\(\hat{v}(l) = v(l)\)</span> if <span class="math notranslate nohighlight">\(N_l &gt; 0\)</span> and for every other node, <span class="math notranslate nohighlight">\(\lim_{N_{X} \to\infty} \hat{v}(x) = m(x)\)</span>, where</p>
<div class="math notranslate nohighlight">
\[m(x) = \sum_{y \in A(x)} \frac{\hat{v}(y)}{|A(x)|}.\]</div>
<p>So, if all children of a node are leaves, the estimated value of the node is the mean of the true values of its children. For any other node, its estimated value is a weighted (depending on the topology of the sub-tree) average of the values of all the leaves in its sub-tree.</p>
<p>Suppose a node <span class="math notranslate nohighlight">\(x\)</span> where an agent M is to play and <span class="math notranslate nohighlight">\(A(x)\)</span> only contains terminal nodes. If M plays <span class="math notranslate nohighlight">\(\operatorname{arg max}_{y \in A(x)} \hat{v}(y)\)</span>, since <span class="math notranslate nohighlight">\(\hat{v}(y) = v(y)\)</span>, it plays the best move and always wins <span class="math notranslate nohighlight">\(v(y)\)</span>. If M plays at random, it wins on average <span class="math notranslate nohighlight">\(m(y)\)</span>. For every other <span class="math notranslate nohighlight">\(x\)</span>, if M plays <span class="math notranslate nohighlight">\(\operatorname{arg max}_{y \in A(x)} \hat{v}(y)\)</span> and the opponent plays at random, M wins on average <span class="math notranslate nohighlight">\(\max_{y \in A(x)} \hat{v}(y)\)</span>, where if M plays at random, M wins <span class="math notranslate nohighlight">\(m(y)\)</span>.</p>
<p>We have thus shown that MCTS is better than playing at random. However, it is still sub-optimal as branches of the game with a low value that will never be taken by a real player still influence the estimated values of nodes above them. A lot of research has been done, as early as the first mention of MCTS <a class="bibtex reference internal" href="#coulom2006mcts" id="id28">[Coulom, 2007]</a> to limit the impact of those branches by playing more simulations starting from nodes that look best according to various heuristics, often specific to the game and driven by human knowledge.</p>
</section>
<section id="implementation">
<h3><a class="toc-backref" href="#id90"><span class="section-number">4.4.3. </span>Implementation</a><a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h3>
<p>This section contains details about the Python implementation of Algorithm 4 described above. The reader can be safely ignore it by going directly to <a class="reference internal" href="#sec-variants"><span class="std std-numref">Section 5</span></a> if they are not interested in the details of the code.</p>
<div class="code-intro"><p>First, we subclass <code class="code docutils literal notranslate"><span class="pre">TreeGame</span></code> so in addition to holding the game state, each node also holds three counters needed for MCTS and its variants: the number of simulations this node was used into and the amount of those simulations that resulted in a win for each player.</p>
</div><div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">TreeStatsGame</span><span class="p">(</span><span class="n">TreeGame</span><span class="p">):</span>
    <span class="n">wins</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">))</span>
    <span class="n">n_playouts</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">update_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">winner</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">winner</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wins</span><span class="p">[</span><span class="n">winner</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_playouts</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="p">()</span><span class="o">.</span><span class="n">update_stats</span><span class="p">(</span><span class="n">winner</span><span class="p">)</span>
</pre></div>
</div>
</div><div class="code-intro"><p>The MCTS first chooses a node to expand with the <code class="code docutils literal notranslate"><span class="pre">tree_policy()</span></code> when the node is found, it is expanded with the <code class="code docutils literal notranslate"><span class="pre">default_policy()</span></code>. When reaching a terminal node, the counters are updated. This is repeated while <code class="code docutils literal notranslate"><span class="pre">budget</span></code> seconds have not elapsed and then the final action is chosen as the action that has the highest estimated game value (game value is 1 for wins, 0 for draws, -1 for losses).</p>
<p>Both tree policy and default policy in this initial implementation are random walks.</p>
</div><div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MCTSPlayer</span><span class="p">(</span><span class="n">Player</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">player_id</span><span class="p">,</span> <span class="n">budget</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">TreeStatsGame</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">player_id</span> <span class="o">=</span> <span class="n">player_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">budget</span> <span class="o">=</span> <span class="n">budget</span>

    <span class="k">def</span> <span class="nf">tree_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">node</span><span class="o">.</span><span class="n">is_leaf_game</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">is_fully_expanded</span><span class="p">:</span>
                <span class="n">node</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">expanded_children</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">legal_unvisited_actions</span><span class="p">)</span>
                <span class="n">node</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">node</span>

    <span class="k">def</span> <span class="nf">explore_tree</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Choose a starting node</span>
        <span class="n">node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree_policy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">)</span>

        <span class="c1"># Run a simulation on that node</span>
        <span class="n">finished</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">game_finished</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">finished</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_policy</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
            <span class="n">node</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">finished</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="c1"># Backtrack stats</span>
        <span class="n">node</span><span class="o">.</span><span class="n">update_stats</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">winner</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">default_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
        <span class="c1"># Random walk</span>
        <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">legal_actions</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">action_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">node</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">wins</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">player_id</span><span class="p">]</span> <span class="o">-</span> <span class="n">node</span><span class="o">.</span><span class="n">wins</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">player_id</span><span class="p">])</span> <span class="o">/</span> <span class="n">node</span><span class="o">.</span><span class="n">n_playouts</span>

    <span class="k">def</span> <span class="nf">final_selection</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">legal_actions</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">action_score</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">budget</span>
        <span class="k">while</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">end</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">explore_tree</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_selection</span><span class="p">()</span>
</pre></div>
</div>
</div></section>
</section>
</section>
<section id="monte-carlo-tree-search-variants">
<span id="sec-variants"></span><h1><a class="toc-backref" href="#id91"><span class="section-number">5. </span>Monte Carlo tree search variants</a><a class="headerlink" href="#monte-carlo-tree-search-variants" title="Permalink to this headline">¶</a></h1>
<p>The basic version of MCTS presented above has proven to be effective in a variety of problems. Variants and enhancements to MCTS have been studied extensively and were shown to bring substantial benefits <a class="bibtex reference internal" href="#browne2012survey" id="id29">[Browne, 2012]</a>. In this section, we present a few of them and apply them to Awale.</p>
<section id="upper-confidence-bounds-for-trees">
<span id="sec-uct"></span><h2><a class="toc-backref" href="#id92"><span class="section-number">5.1. </span>Upper Confidence Bounds for Trees</a><a class="headerlink" href="#upper-confidence-bounds-for-trees" title="Permalink to this headline">¶</a></h2>
<p>Because basic MCTS samples uniformly the game tree, it spends computing time estimating the value of uninteresting nodes that will never be played in a real game. A more efficient method would instead explore more often the interesting parts of the tree: an asymmetric method.</p>
<p>This is where we can see a similarity between MCTS and a well known theoretical problem in reinforcement learning: the <em>multi-armed bandit</em> where an agent must allocate a limited set of resources between multiple choices while maximising its expected gain, when each choice’s properties are only partially known at the time of allocation, and becomes better known by allocating resources to the choice.</p>
<p>Basic MCTS, during the tree policy, chooses a child at random even if the child is likely to have a low estimated value and thus a low probability to be played during a real game. We can instead treat the choice of a child as a multi-armed bandit problem: picking a child that has a high value is analogous to picking a slot machine that has a high reward probability.</p>
<p>When considering the selection phase as a multi-armed bandit, attention has to be given to the fact that the bandits are not stationary: as the estimated value of a node depends not only on the estimated value of its children but also on the number of times these children have been sampled themselves, the mean value of a bandit will change over time as its children are not sampled uniformly over time.</p>
<p>One popular solution to the multi-armed bandit problem is <em>Upper Confidence Bounds</em> (UCB). This method was adapted to MCTS by  <a class="bibtex reference internal" href="#kocsis2006bandit" id="id30">[Kocsis, 2006]</a> and named <em>Upper Confidence Bounds for Trees</em> (UCT) algorithm.
The breakthrough of this method was to prove that UCB handles non-stationary bandits without problem and that the estimated value of the nodes converges to the game theoretic value given a sufficient number of samples.</p>
<p>UCT adapts UCB to MCTS and gives us the following formula for the upper confidence bound for each node:</p>
<div class="math notranslate nohighlight">
\[\frac{W}{N} + c \times \sqrt{\frac{ln N'}{N}},\]</div>
<p>where <span class="math notranslate nohighlight">\(N'\)</span> is the number of times the
parent node has been visited and <span class="math notranslate nohighlight">\(c\)</span> is a parameter that can be tuned to balance exploitation of known wins and exploration of
less visited nodes.</p>
<p>The tree policy from MCTS is then replaced by a policy always choosing the node with the highest upper confidence bound, resolving ties by a coin toss.</p>
<pre class="pseudocode"  data-controller="pseudocode">

          \begin{algorithm}
          \caption{UCT}
          \begin{algorithmic}
          \PROCEDURE{Score}{node $x$}
              \RETURN $\frac{W_x}{N_x} + c \times \sqrt{\frac{ln N'_x}{N_x}}$
          \ENDPROCEDURE
          \PROCEDURE{TreePolicy}{node $x$}
              \WHILE{$ \exists y \in A(x) | N_y > 0$}
              \COMMENT{While at least a child of the node has been visited}
                  \STATE $unvisited$ $\gets$ $\{y \in A(x) | N_y = 0\}$
                  \IF{$unvisited \neq \emptyset$}
                      \STATE $x \gets$ \CALL{ChooseAtRandom}{$unvisited$}
                  \ELSE
                      \RETURN $\operatorname{argmax}_{y \in A(x)}$ \CALL{Score}{$y$}
                  \ENDIF
              \ENDWHILE
              \RETURN x
          \ENDPROCEDURE
          \end{algorithmic}
          \end{algorithm}

</pre><div class="code-intro"><p><code class="code docutils literal notranslate"><span class="pre">UCTPlayer</span></code> thus reuses the MCTS agent but subclasses the <code class="code docutils literal notranslate"><span class="pre">tree_policy</span></code>.</p>
</div><div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lib.utils</span> <span class="kn">import</span> <span class="n">max_rand</span>

<span class="k">class</span> <span class="nc">UCTPlayer</span><span class="p">(</span><span class="n">MCTSPlayer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">player_id</span><span class="p">,</span> <span class="n">budget</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">timedelta</span><span class="p">],</span> <span class="n">c</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">player_id</span><span class="p">,</span> <span class="n">budget</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span>

    <span class="k">def</span> <span class="nf">node_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
        <span class="n">draws</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">n_playouts</span> <span class="o">-</span> <span class="n">node</span><span class="o">.</span><span class="n">wins</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">wins</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">current_opponent</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">draws</span>
        <span class="n">exporation</span> <span class="o">=</span> <span class="n">w</span> <span class="o">/</span> <span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">n_playouts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">exploitation</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">parent</span><span class="p">()</span><span class="o">.</span><span class="n">n_playouts</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">n_playouts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">exporation</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">*</span> <span class="n">exploitation</span>

    <span class="k">def</span> <span class="nf">tree_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">node</span><span class="o">.</span><span class="n">is_leaf_game</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">is_fully_expanded</span><span class="p">:</span>
                <span class="n">node</span> <span class="o">=</span> <span class="n">max_rand</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">expanded_children</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">node_score</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">legal_unvisited_actions</span><span class="p">)</span>
                <span class="n">node</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">node</span>
</pre></div>
</div>
</div></section>
<section id="heavy-playouts">
<h2><a class="toc-backref" href="#id93"><span class="section-number">5.2. </span>Heavy playouts</a><a class="headerlink" href="#heavy-playouts" title="Permalink to this headline">¶</a></h2>
<p>We feel like there is still room for improvement in another part of the MCTS method: the detault policy where for now, moves are being played at random. This makes us think that it is not ideal as, in a real game, no player would play like that and there might be no point in simulating moves that are certain to put the player in a bad situation.</p>
<p>To counter this problem, an approach called <em>heavy playouts</em> can be used where moves selection can be biased using domain-specific heuristics. Here we try this approach by modifying the UCT algorithm from the previous section and replacing the uniformly random selection from the simulation phase with weighted random selection where the probability of choosing the node is weighted by the number of stones that would be captured by playing the move.</p>
<pre class="pseudocode"  data-controller="pseudocode">

          \begin{algorithm}
          \caption{Informed UCT}
          \begin{algorithmic}
            \PROCEDURE{DefaultPolicy}{node $x$}
              \STATE weights $\gets$ 1 +  stones captured by playing $y$ while being in state $x$, $\forall y \in A(x)$
              \RETURN \CALL{ChooseAtRandomWithWeights}{$y \in A(x)$, weights}
            \ENDPROCEDURE
          \end{algorithmic}
          \end{algorithm}

</pre><div class="code-intro"><p><code class="code docutils literal notranslate"><span class="pre">GreedyUCTPlayer</span></code> subclasses <code class="code docutils literal notranslate"><span class="pre">UCTPlayer</span></code> and changes the <code class="code docutils literal notranslate"><span class="pre">default_policy</span></code> to weigh more the actions that will give more immediate rewards.</p>
</div><div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GreedyUCTPlayer</span><span class="p">(</span><span class="n">UCTPlayer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">default_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
        <span class="c1"># Greedy walk</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">legal_actions</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span>
        <span class="n">captures</span> <span class="o">=</span> <span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">legal_actions</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">legal_actions</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">captures</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div></section>
<section id="other-approaches-and-related-work">
<h2><a class="toc-backref" href="#id94"><span class="section-number">5.3. </span>Other approaches and related work</a><a class="headerlink" href="#other-approaches-and-related-work" title="Permalink to this headline">¶</a></h2>
<p>This section enumerates a few methods and related research that were encountered while reading the litterature during the preparation of this work but were not investigated further but still might be of interest to the reader.</p>
<section id="all-moves-as-first">
<h3><a class="toc-backref" href="#id95"><span class="section-number">5.3.1. </span>All moves as first</a><a class="headerlink" href="#all-moves-as-first" title="Permalink to this headline">¶</a></h3>
<p><em>All Moves As First</em> (AMAF) and its successor <em>Rapid Action Value Estimation</em> (RAVE) are enhancements that have often been proved very successful when applying MCTS to the game of Go <a class="bibtex reference internal" href="#gelly20111rave" id="id31">[Gelly, 2011]</a>.
The basic idea is to update statistics for all actions selected during a simulation as if they were the first action applied. This method is particularly well suited for incremental games such as Go, where the value of a move is often dependent on the state of the board in its close proximity and unaffected by moves played elsewhere on the board.
Due to the popularity of AMAF, these methods are mentioned here for completeness but will not be pursued further due to the lack of applicability to Awale where the value of moves are dependent on the whole board and on the advancement of the game.</p>
</section>
<section id="alpha-zero">
<h3><a class="toc-backref" href="#id96"><span class="section-number">5.3.2. </span>Alpha Zero</a><a class="headerlink" href="#alpha-zero" title="Permalink to this headline">¶</a></h3>
<p>To replace the random play with heavy playouts in the simulation step of MCTS, <a class="bibtex reference internal" href="#alphago" id="id32">[Silver, 2016]</a><a class="bibtex reference internal" href="#alphagozero" id="id33">[Silver, 2017]</a><a class="bibtex reference internal" href="#alphazero" id="id34">[Silver, 2018]</a> proposes to use deep convolutional neural networks trained on TPUs (Tensor Processing Units) to estimate the value of a game state without having to play it. This can greatly enhance the performance
of the algorithm because much less playouts are required. While these methods seem to be extremely promising, due to the size of the networks, the time and price of the hardware required to train them, we chose not to implement these techniques.</p>
</section>
<section id="related-work">
<h3><a class="toc-backref" href="#id97"><span class="section-number">5.3.3. </span>Related work</a><a class="headerlink" href="#related-work" title="Permalink to this headline">¶</a></h3>
<p>The amount of work being done on MCTS applied to games and, in particular, to the game of Go, is too big to be cited here and mentioning them here would be out of the scope of this work. But we do think that some of these works still might interest the reader as they apply to Mancala games. <a class="bibtex reference internal" href="#davis2002" id="id35">[Davis, 2002]</a> uses a genetic algorithm to optimize weights of a handcrafted evaluation function while <a class="bibtex reference internal" href="#pekar2020" id="id36">[Pekař, 2020]</a> surveys the research on Mancala games and suggests a novel heuristic. Other theses also have been written on the subject such as <a class="bibtex reference internal" href="#berkman2016" id="id37">[Berkman, 2016]</a><a class="bibtex reference internal" href="#rovaris2016" id="id38">[Rovaris, 2016]</a><a class="bibtex reference internal" href="#birell2019" id="id39">[Birell, 2019]</a>.</p>
</section>
</section>
</section>
<section id="method">
<span id="sec-method"></span><h1><a class="toc-backref" href="#id98"><span class="section-number">6. </span>Method</a><a class="headerlink" href="#method" title="Permalink to this headline">¶</a></h1>
<p>This section describes the methods used to compare agents and details the experimental setup in which the games between agents are played as well as the method used to run the experiments in a massively parallel setup to be able to record enough games to have statistically strong results.</p>
<section id="comparing-algorithms">
<span id="sec-compare"></span><h2><a class="toc-backref" href="#id99"><span class="section-number">6.1. </span>Comparing algorithms</a><a class="headerlink" href="#comparing-algorithms" title="Permalink to this headline">¶</a></h2>
<p>We first describe the statistical framework used to compare two agents and show that the strength relation is not necessarily transitive.
Then we suggest playing a tournament to compare and rank multiple agents and we show how to limit the size of the tournament under some plausible assumptions.</p>
<section id="how-to-compare-a-and-b">
<span id="sec-compare-ab"></span><h3><a class="toc-backref" href="#id100"><span class="section-number">6.1.1. </span>How to compare A and B</a><a class="headerlink" href="#how-to-compare-a-and-b" title="Permalink to this headline">¶</a></h3>
<p>Because the outcome of a match between two agents is not deterministic, we can not rely on a single match to ascertain that the winner of a match is better than the loser. So the first step is to define a statistical method to compare two arbitrarily chosen agents: A and B.</p>
<p>The probability that A wins is denoted by <span class="math notranslate nohighlight">\(p_A\)</span>, the probability that B wins is <span class="math notranslate nohighlight">\(p_B\)</span> and the probability of a draw is <span class="math notranslate nohighlight">\(p_d\)</span>. All are unknown. Because every game outcome is either A wins, B wins or a draw, <span class="math notranslate nohighlight">\(p_A + p_B + p_d = 1\)</span>.
Our null hypothesis (<span class="math notranslate nohighlight">\(H_0\)</span>) is that both agents are equally strong (<span class="math notranslate nohighlight">\(p_A=p_B\)</span>) and the alternative hypothesis is that they are of different strength (<span class="math notranslate nohighlight">\(p_A \neq p_B\)</span>).</p>
<p>We define <span class="math notranslate nohighlight">\(\pi_A\)</span> as <span class="math notranslate nohighlight">\(p_A + \frac{1}{2}\ p_d\)</span> and <span class="math notranslate nohighlight">\(\pi_B\)</span> as <span class="math notranslate nohighlight">\(p_B + \frac{1}{2}\ p_d\)</span> and put forward another hypothesis <span class="math notranslate nohighlight">\(H'_0: \pi_A = 0.5\)</span>. We then prove with the following that <span class="math notranslate nohighlight">\(H_0\)</span> and <span class="math notranslate nohighlight">\(H'_0\)</span> are equivalent. Let us start from <span class="math notranslate nohighlight">\(H'_0\)</span>:</p>
<figure class="align-default">
<img alt="_images/proof-h0.svg" src="_images/proof-h0.svg" /></figure>
<p>which is our initial hypothesis <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<p>To compare agents A and B, we run <span class="math notranslate nohighlight">\(N\)</span> matches. Agent A wins <span class="math notranslate nohighlight">\(n_A\)</span> times, agent B wins <span class="math notranslate nohighlight">\(n_B\)</span> times and there are <span class="math notranslate nohighlight">\(n_d\)</span> draws.</p>
<p>We then compute the p-value.
If it is lower than <span class="math notranslate nohighlight">\(5\%\)</span>, we reject the null hypothesis.
This guarantees that, conditional on <span class="math notranslate nohighlight">\(H_0\)</span> being true, the probability of making an incorrect decision is <span class="math notranslate nohighlight">\(5\%\)</span>.
But if <span class="math notranslate nohighlight">\(H_1\)</span> is true, the probability of an incorrect decision is not necessarily <span class="math notranslate nohighlight">\(5\%\)</span>: it depends on the number <span class="math notranslate nohighlight">\(N\)</span> of matches and on the true value of <span class="math notranslate nohighlight">\(\pi_A\)</span>.
To ensure that the probability of an incorrect decision, conditional on <span class="math notranslate nohighlight">\(H_1\)</span>, be acceptable, we resort to the concept of statistical power.</p>
<p>Suppose the true probability <span class="math notranslate nohighlight">\(\pi_A\)</span> is <span class="math notranslate nohighlight">\(0.75\)</span>. This is very far from the null hypothesis. In that case, we want the probability of choosing <span class="math notranslate nohighlight">\(H_1\)</span> (not making an incorrect decision) to be high (for instance <span class="math notranslate nohighlight">\(95\%\)</span>). This probability is the <em>power</em> and can be computed by means of the R function <code class="code docutils literal notranslate"><span class="pre">powerBinom</span></code> implemented in the R package <code class="code docutils literal notranslate"><span class="pre">exactci</span></code>. The output of this function is the number <span class="math notranslate nohighlight">\(N\)</span> of matches needed to achieve the desired power and it is 49. As we always play an even number of matches between two agents (A vs. B and B vs. A), we decide that we need <span class="math notranslate nohighlight">\(N=50\)</span> matches.</p>
<p>Now that we know the number of matches we need to play to be able to ascertain that <span class="math notranslate nohighlight">\(H_1\)</span> is probable enough, we still need to know how big <span class="math notranslate nohighlight">\(n_A\)</span> (or <span class="math notranslate nohighlight">\(n_B\)</span>) needs to win so we may declare <span class="math notranslate nohighlight">\(H_1\)</span> true. This can be done with the <code class="code docutils literal notranslate"><span class="pre">scipy.stats.binom_test</span></code> function.</p>
<div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">pvalue</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">binom_test</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s2">&quot;greater&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pvalue</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;If nₐ is at least&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="s2">&quot;we can reject H₀&#39; with a p-value of&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">pvalue</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="k">break</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If nₐ is at least 32 we can reject H₀&#39; with a p-value of 0.0325
</pre></div>
</div>
</div><p>With this method, we can then define a strength relation ‘<em>is stronger than</em>’, noted <span class="math notranslate nohighlight">\(\succ\)</span> over the set of agents where <span class="math notranslate nohighlight">\(A \succ B\)</span> if when playing 50 matches between A and B, <span class="math notranslate nohighlight">\(n_A + \frac{1}{2}\ n_d \geq 32\)</span>.
We can also define the relation ‘<em>is weakly stronger than</em>’, noted <span class="math notranslate nohighlight">\(\succeq\)</span> where <span class="math notranslate nohighlight">\(A \succ B \iff n_A + \frac{1}{2}\ n_d \geq 18\)</span>. Notice that <span class="math notranslate nohighlight">\(\succ\)</span> is the asymmetric part of <span class="math notranslate nohighlight">\(\succeq\)</span>.</p>
</section>
<section id="transitivity-of-the-strength-relation">
<h3><a class="toc-backref" href="#id101"><span class="section-number">6.1.2. </span>Transitivity of the strength relation</a><a class="headerlink" href="#transitivity-of-the-strength-relation" title="Permalink to this headline">¶</a></h3>
<p>We have a method to determine if an agent is stronger than another but we don’t have a way to order all our agents regarding their strength. It could be tempting to use a sorting algorithm to order the agents using the weak strength (<span class="math notranslate nohighlight">\(\succeq\)</span>) relation but for this to be correct, the relation has to be transitive and thus <span class="math notranslate nohighlight">\(\succ\)</span> has to be acyclic.</p>
<p>In the following mind experiment, we prove that the relation of weak strength between two agents is not transitive and thus a total order between all possible agents does not exist.</p>
<p>Let us define a theoretical game represented by the tree in <a class="reference internal" href="#fig-mind-exp"><span class="std std-numref">Figure 13</span></a>. Then, let us define three different agents designed to play this game: A, B and C with their strategies defined in the table below.</p>
<table class="docutils align-default" id="id66">
<caption><span class="caption-number">Table 1 </span><span class="caption-text">Strategies of the theoretical agents A, B and C</span><a class="headerlink" href="#id66" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 5%" />
<col style="width: 24%" />
<col style="width: 24%" />
<col style="width: 24%" />
<col style="width: 24%" />
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p><span class="math notranslate nohighlight">\(s(1)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(s(2)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(s(3)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(s(4)\)</span></p></td>
</tr>
<tr class="row-even"><td><p>A</p></td>
<td><p>2</p></td>
<td><p>5</p></td>
<td><p>8</p></td>
<td><p>9</p></td>
</tr>
<tr class="row-odd"><td><p>B</p></td>
<td><p>3</p></td>
<td><p>5</p></td>
<td><p>7</p></td>
<td><p>10</p></td>
</tr>
<tr class="row-even"><td><p>C</p></td>
<td><p>4</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
<td><p>9</p></td>
</tr>
</tbody>
</table>
<p>We see that in a match of A against B, A wins 1 wherein B against A, both win 0. So we can say <span class="math notranslate nohighlight">\(A \succ B\)</span>.
By enumerating all possible matches between ordered pairs of these agents, we see that <span class="math notranslate nohighlight">\(A \succ B\)</span>, <span class="math notranslate nohighlight">\(B \succ C\)</span> and <span class="math notranslate nohighlight">\(C \succ A\)</span>. This cycle in <span class="math notranslate nohighlight">\(\succ\)</span> proves that the relation <span class="math notranslate nohighlight">\(\succeq\)</span> is not transitive at least in some cases.</p>
<figure class="align-default" id="id67">
<span id="fig-mind-exp"></span><img alt="_images/mind-exp.svg" src="_images/mind-exp.svg" /><figcaption>
<p><span class="caption-number">Figure 13 </span><span class="caption-text">The tree representation of the theoretical game.
States are represented as circles, game values are written under the final states.</span><a class="headerlink" href="#id67" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="how-to-compare-more-than-two-agents">
<h3><a class="toc-backref" href="#id102"><span class="section-number">6.1.3. </span>How to compare more than two agents</a><a class="headerlink" href="#how-to-compare-more-than-two-agents" title="Permalink to this headline">¶</a></h3>
<p>As described above, transitivity can not be proved in all cases so we can not use a sorting algorithm to order our agents. We thus have to resort to a round-robin tournament where the relation <span class="math notranslate nohighlight">\(\succeq\)</span> is evaluated between every pair of agents.</p>
<p>We have 6 algorithms, each with some continuous or discrete parameters. Even if we restrict every parameter to a small finite set of values (let’s say 100), we would still have 600 agents to compare. This would in turn make a tournament of size <span class="math notranslate nohighlight">\(600^2\)</span> where each evaluation of the relation requires 50 matches. This method would thus require <span class="math notranslate nohighlight">\(600^2 * 50 = 18\,000\,000\)</span> matches. Playing such a big number of matches is hardly feasible so we resort to a more frugal approach.</p>
<p>The approach that we take is to first select, for each algorithm, the parameters that result in the best agent (a champion). This in turn reduces the number of agents playing in the round-robin tournament to 6 and the number of matches to play to <span class="math notranslate nohighlight">\(6^2 * 50 = 180\)</span>, a much more reasonable number. While this approach reduces drastically the number of computations needed, it might not be perfect.
We have no guarantee that the champion within a family (all agents derived from a single algorithm) is also the best family member against agents from other families. This is a known limitation and verifying this assumption is outside of the scope of this work.</p>
</section>
<section id="champion-selection">
<span id="sec-champion-select"></span><h3><a class="toc-backref" href="#id103"><span class="section-number">6.1.4. </span>Champion selection</a><a class="headerlink" href="#champion-selection" title="Permalink to this headline">¶</a></h3>
<p>Let  <span class="math notranslate nohighlight">\(A_x\)</span> be an algorithm <span class="math notranslate nohighlight">\(A\)</span> with a continuous parameter <span class="math notranslate nohighlight">\(x \in X\)</span> and <span class="math notranslate nohighlight">\(f_n(A_{x}, A_{y})\)</span>, the number of wins of <span class="math notranslate nohighlight">\(A_{x}\)</span> against <span class="math notranslate nohighlight">\(A_{y}\)</span> after <span class="math notranslate nohighlight">\(n\)</span> matches.
We make the assumption that with <span class="math notranslate nohighlight">\(n\)</span> big enough, <span class="math notranslate nohighlight">\(f_n(A_{x}, A_{y})\)</span> is smooth for all <span class="math notranslate nohighlight">\(x,y \in X\)</span> due to the fact that both agents <span class="math notranslate nohighlight">\(A_{x}\)</span> and <span class="math notranslate nohighlight">\(A_{y}\)</span> share the same algorithm. This smoothness property will be empirically confirmed later (see Sections <a class="reference internal" href="#sec-eps-tuning"><span class="std std-numref">7.1.1</span></a> and <a class="reference internal" href="#sec-uct-tuning"><span class="std std-numref">7.1.3</span></a>).</p>
<p>So, for <span class="math notranslate nohighlight">\(x_1\)</span> close to <span class="math notranslate nohighlight">\(x_2\)</span> and <span class="math notranslate nohighlight">\(y_1\)</span> close to <span class="math notranslate nohighlight">\(y_2\)</span>, the value of <span class="math notranslate nohighlight">\(f_n(A_{x_1}, A_{y_1})\)</span> gives us an indication about the value of <span class="math notranslate nohighlight">\(f_n(A_{x_2}, A_{y_2})\)</span>.
This assumption and the fact that we evaluate <span class="math notranslate nohighlight">\(f_n\)</span> over a dense sample of the parameter space allows us to compare agents from a single family by playing much fewer matches than the 50 matches derived from our statistical power analysis.</p>
<p>During the champion selection, contrary to the round-robin tournament, we also assume that the strength relation <span class="math notranslate nohighlight">\(\succ\)</span> over agents of a family satisfies a weaker property than transitivity:</p>
<p><span class="math notranslate nohighlight">\(\exists y \in X\)</span> such that, <span class="math notranslate nohighlight">\(\forall x \in X: x \neq y\)</span>,  we have <span class="math notranslate nohighlight">\(f_{n \to \infty} (A_{x}, A_{y}) \frac{1}{n} &gt; f_{n \to \infty} (A_{y}, A_{x}) \frac{1}{n}\)</span>: there exists an agent that wins more than half the time against every other agent of its family.</p>
</section>
<section id="tournament-solution">
<h3><a class="toc-backref" href="#id104"><span class="section-number">6.1.5. </span>Tournament solution</a><a class="headerlink" href="#tournament-solution" title="Permalink to this headline">¶</a></h3>
<p>Now that know how to select a champion for each algorithm, we can play a given number of matches between each pair of champions and compare each pair by means of the <span class="math notranslate nohighlight">\(\succeq\)</span> relation. By reusing the statistical framework from <a class="reference internal" href="#sec-compare-ab"><span class="std std-numref">6.1.1</span></a>, we know we have to play 50 matches between each pair and if a <span class="math notranslate nohighlight">\(A\)</span> wins more than 18 matches against B, then <span class="math notranslate nohighlight">\(A \succeq B\)</span>. By construction, this binary relation is complete and is thus a <em>weak tournament</em> <a class="bibtex reference internal" href="#brandt2016" id="id40">[Brandt, 2016]</a>.</p>
<p>We can represent our weak tournament as a binary matrix <span class="math notranslate nohighlight">\(M\)</span> indexed in both dimensions by the champions and where each entry <span class="math notranslate nohighlight">\(M_{ij} = 1 \iff i \succeq j\)</span>. A binary matrix <span class="math notranslate nohighlight">\(M\)</span> is a <em>step-type matrix</em> when each row is non-decreasing from left to right and each column is non-decreasing from top to bottom <a class="bibtex reference internal" href="#pirlotvincke97" id="id41">[Pirlot, 1997]</a>.</p>
<p>The <span class="math notranslate nohighlight">\(\succeq\)</span> is transitive if and only if it has a step-type matrix representation in which the order of the columns and of the lines is the same. If this is the case for our weak tournament, it will be not only complete but also transitive. It will therefore be a weak order i.e. an ordering of the champions from best to worst, possibly with ties <a class="bibtex reference internal" href="#roubensvincke85" id="id42">[Roubens, 1985]</a>.</p>
</section>
</section>
<section id="experimental-setup">
<span id="sec-setup"></span><h2><a class="toc-backref" href="#id105"><span class="section-number">6.2. </span>Experimental setup</a><a class="headerlink" href="#experimental-setup" title="Permalink to this headline">¶</a></h2>
<p>A match between two agents is played with the following code, where the variables <code class="code docutils literal notranslate"><span class="pre">player</span></code> and <code class="code docutils literal notranslate"><span class="pre">opponent</span></code> contain an instance of an agent (a class derived from <code class="code docutils literal notranslate"><span class="pre">Player</span></code>).
Because most games we played in our preliminary work finished in less than 200 moves, we limit games to 500 moves to avoid playing infinite games. A game that goes over the threshold of 500 moves is considered a draw, regardless of the score of both players.</p>
<div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">game</span> <span class="o">=</span> <span class="n">Game</span><span class="p">()</span>
<span class="n">opponent_action</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>

<span class="k">while</span> <span class="ow">not</span> <span class="n">game</span><span class="o">.</span><span class="n">game_finished</span> <span class="ow">and</span> <span class="n">depth</span> <span class="o">&lt;</span> <span class="mi">500</span><span class="p">:</span>
    <span class="n">player_action</span> <span class="o">=</span> <span class="n">player</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">opponent_action</span><span class="p">)</span>
    <span class="n">game</span><span class="p">,</span> <span class="n">captures</span><span class="p">,</span> <span class="n">finished</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">player_action</span><span class="p">)</span>

    <span class="n">player</span><span class="p">,</span> <span class="n">opponent</span> <span class="o">=</span> <span class="n">opponent</span><span class="p">,</span> <span class="n">player</span>
    <span class="n">opponent_action</span> <span class="o">=</span> <span class="n">player_action</span>
    <span class="n">depth</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">duration</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div><dl class="simple">
<dt>Relevant data from the match is then available in the following variables:</dt><dd><ul class="simple">
<li><p><code class="code docutils literal notranslate"><span class="pre">duration</span></code> is the total duration of the game in seconds,</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">depth</span></code> is the number of moves played by both agents,</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">score</span></code> is a 2-tuple of the score of South followed by the score of North,</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">winner</span></code> is <code class="code docutils literal notranslate"><span class="pre">0</span></code> if South won, <code class="code docutils literal notranslate"><span class="pre">1</span></code> if North won and <code class="code docutils literal notranslate"><span class="pre">None</span></code> if the game was a draw.</p></li>
</ul>
</dd>
</dl>
<div class="code-intro"><p>Those can be can then be recorded in a dictionary as below for further analysis.</p>
</div><div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;duration&quot;</span><span class="p">:</span> <span class="n">duration</span><span class="p">,</span>
    <span class="s2">&quot;depth&quot;</span><span class="p">:</span> <span class="n">depth</span><span class="p">,</span>
    <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">game</span><span class="o">.</span><span class="n">captures</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
    <span class="s2">&quot;winner&quot;</span><span class="p">:</span> <span class="n">game</span><span class="o">.</span><span class="n">winner</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;duration&#39;: 0.0022, &#39;depth&#39;: 52, &#39;score&#39;: [15, 27], &#39;winner&#39;: 1}
</pre></div>
</div>
</div><p>Because the number of matches we expect to play is quite high and a match between two agents might take a few minutes of CPU time, we have to be able to play a big number of run matches in parallel.</p>
<p>We use the infrastructure of Amazon Web Services (AWS) to be able to access hundreds of CPU cores at the same time and use AWS Batch to schedule the jobs across the different machines.</p>
<p>To this effect, we place the code to run a match in a standalone Python script that accepts parameters to give to the agents via environment variables and package it in a Docker container. When the match is finished, the dictionary showed above is then outputted to the standard output.</p>
<p>This Docker container is then used as a template to launch AWS Batch tasks in parallel, their standard output being sent to AWS Cloudwatch to be analyzed later.
Each match is run in a separate AWS Batch task and is allowed 1 vCPU with 500MB of RAM. Those tasks are running on C5 compute optimized EC2 instances <a class="footnote-reference brackets" href="#aws-c5" id="id43">3</a>.</p>
<div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lib.utils</span> <span class="kn">import</span> <span class="n">submit_aws_job</span>

<span class="k">def</span> <span class="nf">submit_match</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">pool</span><span class="p">,</span> <span class="n">side</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">600</span> <span class="p">,</span> <span class="n">local</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">submit_aws_job</span><span class="p">(</span>
        <span class="n">jobDefinition</span><span class="o">=</span><span class="s1">&#39;run-match&#39;</span><span class="p">,</span>
        <span class="n">jobName</span><span class="o">=</span><span class="n">pool</span><span class="p">,</span>
        <span class="n">jobQueue</span><span class="o">=</span><span class="s1">&#39;matches&#39;</span><span class="p">,</span>
        <span class="n">containerOverrides</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;command&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;python&quot;</span><span class="p">,</span> <span class="s2">&quot;simulate.py&quot;</span><span class="p">],</span>
            <span class="s1">&#39;environment&#39;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;PLAYER_A&#39;</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="n">a</span> <span class="o">%</span> <span class="mi">0</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;PLAYER_B&#39;</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="n">b</span> <span class="o">%</span> <span class="mi">1</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;POOL&#39;</span><span class="p">,</span><span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="n">pool</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;SIDE&#39;</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">side</span><span class="p">)},</span>
            <span class="p">]</span>
        <span class="p">},</span>
        <span class="n">timeout</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;attemptDurationSeconds&#39;</span><span class="p">:</span> <span class="n">timeout</span><span class="p">},</span>
        <span class="n">local</span><span class="o">=</span><span class="n">local</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div><p>Because we can not be sure an agent has the same strength if it is allowed to be the first player as if it is the second to play, each time we play a match between two agents (A and B), we play the match A vs. B and B vs. A.</p>
<div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sumbit_symmetric_match</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">pool</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">local</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">submit_match</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">pool</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">local</span><span class="o">=</span><span class="n">local</span><span class="p">)</span>
    <span class="n">submit_match</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">pool</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">local</span><span class="o">=</span><span class="n">local</span><span class="p">)</span>
</pre></div>
</div>
</div><p>Results of the jobs submitted to AWS Batch can then be found in AWS CloudWatch. They are downloaded with a script and stored in <code class="code docutils literal notranslate"><span class="pre">source/data/*.jsonl</span></code>. These results are then processed, normalized and made available in Pandas DataFrame <a class="bibtex reference internal" href="#pandas" id="id44">[McKinney, 2010]</a>.</p>
<div class="code-intro"><p>They are then importable with the following code:</p>
</div><div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lib.results</span> <span class="kn">import</span> <span class="n">results</span>
</pre></div>
</div>
</div></section>
</section>
<section id="experiments">
<span id="sec-experiments"></span><h1><a class="toc-backref" href="#id106"><span class="section-number">7. </span>Experiments</a><a class="headerlink" href="#experiments" title="Permalink to this headline">¶</a></h1>
<p>We first run a series of experiments for selecting a champion in each family of agents. We then play a tournament involving each champion and analyze the tournament result to present a ranking of the different agents.</p>
<section id="id45">
<h2><a class="toc-backref" href="#id107"><span class="section-number">7.1. </span>Champion selection</a><a class="headerlink" href="#id45" title="Permalink to this headline">¶</a></h2>
<section id="varepsilon-greedy">
<span id="sec-eps-tuning"></span><h3><a class="toc-backref" href="#id108"><span class="section-number">7.1.1. </span><span class="math notranslate nohighlight">\(\varepsilon\)</span>-Greedy</a><a class="headerlink" href="#varepsilon-greedy" title="Permalink to this headline">¶</a></h3>
<p>The first agent we have to tune is <span class="math notranslate nohighlight">\(\varepsilon\)</span>-Greedy and it has one parameter <span class="math notranslate nohighlight">\(\varepsilon\)</span> that can vary in the interval <span class="math notranslate nohighlight">\([0, 1]\)</span>. As running a match between two <span class="math notranslate nohighlight">\(\varepsilon\)</span>-Greedy agents takes less than 100ms, playing thousands of matches is computationally feasible.</p>
<p>We thus pick evenly spaced values of <span class="math notranslate nohighlight">\(\varepsilon\)</span> in the interval <span class="math notranslate nohighlight">\([0, 1]\)</span> and play 50 matches for each pair of values of <span class="math notranslate nohighlight">\(\varepsilon\)</span>.</p>
<div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">search_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">eps1</span> <span class="ow">in</span> <span class="n">search_space</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">eps2</span> <span class="ow">in</span> <span class="n">search_space</span><span class="p">:</span>
            <span class="n">player</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;GreedyPlayer(%s, </span><span class="si">{</span><span class="n">eps1</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="n">opponent</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;GreedyPlayer(%s, </span><span class="si">{</span><span class="n">eps2</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="n">sumbit_symmetric_match</span><span class="p">(</span><span class="n">player</span><span class="p">,</span> <span class="n">opponent</span><span class="p">,</span> <span class="s2">&quot;local-eps-matrix&quot;</span><span class="p">,</span> <span class="n">local</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div><p>The results of these matches is shown in <a class="reference internal" href="#fig-eps-matrix"><span class="std std-numref">Figure 14</span></a> below in which we can see despite the noise that a higher value of <span class="math notranslate nohighlight">\(\varepsilon\)</span> (meaning the agent chooses most often the greedy approach) is stronger than a lower value. Due to the noise in the data despite the high number of games played it is hard to know for sure if <span class="math notranslate nohighlight">\(\varepsilon = 1\)</span> is the optimum or if it is a bit lower. We keep a value of <span class="math notranslate nohighlight">\(\varepsilon = 0.95\)</span> for the rest of this work.</p>
<figure class="align-default" id="id68">
<span id="fig-eps-matrix"></span><img alt="_images/index_114_0.svg" src="_images/index_114_0.svg" /><figcaption>
<p><span class="caption-number">Figure 14 </span><span class="caption-text">Heatmap of the win ratio of the row player against the column player.</span><a class="headerlink" href="#id68" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="mcts">
<span id="sec-mcts-tuning"></span><h3><a class="toc-backref" href="#id109"><span class="section-number">7.1.2. </span>MCTS</a><a class="headerlink" href="#mcts" title="Permalink to this headline">¶</a></h3>
<p>The MCTS agent has a parameter <span class="math notranslate nohighlight">\(t\)</span> that states how much time the agent may spend on simulation during its turn.
As we have shown in <a class="reference internal" href="#sec-mcts-perf"><span class="std std-numref">Section 4.4.2</span></a>, given enough time, with MCTS, the estimated value of a node converges to the weighted average of the true value of the leaves of the subtree. So we know that the higher is <span class="math notranslate nohighlight">\(t\)</span>, the better the agent is. However, since we are constrained by the capacity of our computation resources, we have to choose a reasonable value of <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>Given our objective of producing an agent capable of playing against a human, choosing a value of <span class="math notranslate nohighlight">\(t\)</span> higher than 1 minute is unrealistic as the human will not want to wait for more than that at each turn of the game. While 1 minute is an upper bound, having a much smaller waiting time at each turn would be valuable. We think that  <span class="math notranslate nohighlight">\(t = 5s\)</span> is a reasonable value.</p>
<p>As stated earlier, we know that the strength of the agent is an increasing function of <span class="math notranslate nohighlight">\(t\)</span>. However, we don’t know the shape of this function. We compare the strength of MCTS(<span class="math notranslate nohighlight">\(t=5\)</span>) against a range of values of <span class="math notranslate nohighlight">\(t' \in \{0.5, 1, 1.5, 2, 3, 5, 7, 10, 15, 20, 30, 40\}\)</span> by playing 10 matches for each value of <span class="math notranslate nohighlight">\(t'\)</span>.</p>
<div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">search_space</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">time</span> <span class="ow">in</span> <span class="n">search_space</span><span class="p">:</span>
            <span class="n">player</span> <span class="o">=</span> <span class="s2">&quot;MCTSPlayer(</span><span class="si">%s</span><span class="s2">, td(seconds=5))&quot;</span>
            <span class="n">opponent</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;MCTSPlayer(%s, td(seconds=</span><span class="si">{</span><span class="n">time</span><span class="si">}</span><span class="s2">))&quot;</span>

            <span class="n">sumbit_symmetric_match</span><span class="p">(</span><span class="n">player</span><span class="p">,</span> <span class="n">opponent</span><span class="p">,</span> <span class="s2">&quot;mcts-5s-time-compare&quot;</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">60</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div><p>While the results shown in <a class="reference internal" href="#fig-mcts-time-5s"><span class="std std-numref">Figure 15</span></a> are also noisy, we indeed see that the strength of MCTS increases with <span class="math notranslate nohighlight">\(t\)</span> but the slope of the curve is not very important after <span class="math notranslate nohighlight">\(t=5s\)</span> so we decide that <span class="math notranslate nohighlight">\(t=5s\)</span> is a good compromise between strength and waiting time. These empirical results are compatible with the expected smoothness described in <a class="reference internal" href="#sec-champion-select"><span class="std std-numref">Section 6.1.4</span></a>.</p>
<figure class="align-default" id="id69">
<span id="fig-mcts-time-5s"></span><img alt="_images/index_119_0.svg" src="_images/index_119_0.svg" /><figcaption>
<p><span class="caption-number">Figure 15 </span><span class="caption-text">Strength of MCTS related to the allowed simulation time budget</span><a class="headerlink" href="#id69" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="uct">
<span id="sec-uct-tuning"></span><h3><a class="toc-backref" href="#id110"><span class="section-number">7.1.3. </span>UCT</a><a class="headerlink" href="#uct" title="Permalink to this headline">¶</a></h3>
<p>The UCT agent has 2 variables that we can tune, <span class="math notranslate nohighlight">\(t\)</span> as in MCTS and <span class="math notranslate nohighlight">\(c\)</span> the balance between exploration and exploitation. Like MCTS, the strength of UCT increases with <span class="math notranslate nohighlight">\(t\)</span> so we fix <span class="math notranslate nohighlight">\(t=5s\)</span> to be able to fairly compare MCTS and UTC later.</p>
<p><a class="bibtex reference internal" href="#kocsis2006bandit" id="id46">[Kocsis, 2006]</a> has shown that <span class="math notranslate nohighlight">\(c=\sqrt{2} / 2\)</span> is a good starting value. We thus play matches of <span class="math notranslate nohighlight">\(UCT(c=\sqrt{2} / 2)\)</span> against a range of 11 values equally spaced between 0.2 and 2.2</p>
<div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">search_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.2</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">search_space</span><span class="p">:</span>
            <span class="n">player</span> <span class="o">=</span> <span class="s2">&quot;UCTPlayer(</span><span class="si">%s</span><span class="s2">, td(seconds=5), c=math.sqrt(2)/2)&quot;</span>
            <span class="n">opponent</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;UCTPlayer(%s, td(seconds=5), c=</span><span class="si">{</span><span class="n">c</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span>

            <span class="n">sumbit_symmetric_match</span><span class="p">(</span><span class="n">player</span><span class="p">,</span> <span class="n">opponent</span><span class="p">,</span> <span class="s2">&quot;uct-tuning-c&quot;</span><span class="p">)</span>

<span class="n">fine_search_space</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">fine_search_space</span><span class="p">:</span>
            <span class="n">player</span> <span class="o">=</span> <span class="s2">&quot;UCTPlayer(</span><span class="si">%s</span><span class="s2">, td(seconds=5), c=math.sqrt(2)/2)&quot;</span>
            <span class="n">opponent</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;UCTPlayer(%s, td(seconds=5), c=</span><span class="si">{</span><span class="n">c</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span>

            <span class="n">sumbit_symmetric_match</span><span class="p">(</span><span class="n">player</span><span class="p">,</span> <span class="n">opponent</span><span class="p">,</span> <span class="s2">&quot;uct-tuning-c-fine&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div><p>What we see in <a class="reference internal" href="#fig-utc-tuning-c"><span class="std std-numref">Figure 16</span></a> is a bell curve with some noise and a plateau around <span class="math notranslate nohighlight">\(c = \sqrt(2) / 2\)</span>. Tt seems to confirm that it is the optimum value for UCT.</p>
<figure class="align-default" id="id70">
<span id="fig-utc-tuning-c"></span><img alt="_images/index_124_0.svg" src="_images/index_124_0.svg" /><figcaption>
<p><span class="caption-number">Figure 16 </span><span class="caption-text">Strength of UCT(<span class="math notranslate nohighlight">\(c=\sqrt{2} / 2\)</span>) against other values of <span class="math notranslate nohighlight">\(c\)</span>.</span><a class="headerlink" href="#id70" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>Under the assumption that the true curve is smooth, we can assume that <span class="math notranslate nohighlight">\(UCT(c = \sqrt(2) / 2)\)</span> wins against any value of <span class="math notranslate nohighlight">\(c \in [0.2, 2.2]\)</span>. While this result is convenient, we do not know whether the relation ‘stronger than’ is transitive.
Hence, while <span class="math notranslate nohighlight">\(UCT(\sqrt{2}/2)\)</span> wins against <span class="math notranslate nohighlight">\(UCT(y)\)</span> for all <span class="math notranslate nohighlight">\(y \in [0.2, 2.2]\)</span>, there might be <span class="math notranslate nohighlight">\(z \neq \sqrt{2}/2\)</span> such that <span class="math notranslate nohighlight">\(UCT(z)\)</span> beats <span class="math notranslate nohighlight">\(UCT(y)\)</span> for some or even many <span class="math notranslate nohighlight">\(y \in  [0.2, 2.2]\)</span>.
It could even be the case that <span class="math notranslate nohighlight">\(UCT(z)\)</span> beats <span class="math notranslate nohighlight">\(UCT(y)\)</span> by a larger margin than <span class="math notranslate nohighlight">\(UCT(\sqrt{2}/2)\)</span> beats <span class="math notranslate nohighlight">\(UCT(y)\)</span>.
This would weaken our conclusion that <span class="math notranslate nohighlight">\(\sqrt{2}/2\)</span> is the optimum.
To confirm our intuition, we should run the same experiment as above with various values of <span class="math notranslate nohighlight">\(c\)</span>, instead of <span class="math notranslate nohighlight">\(c=\sqrt{2}/2\)</span>.
We do it first for <span class="math notranslate nohighlight">\(c=1.5\)</span> and obtain the curve depicted in <a class="reference internal" href="#fig-uct-tuning-c-15"><span class="std std-numref">Figure 17</span></a>.
It is the same curve as in <a class="reference internal" href="#fig-utc-tuning-c"><span class="std std-numref">Figure 16</span></a> (shifted upward) and confirms that <span class="math notranslate nohighlight">\(c=\sqrt{2}/2\)</span> is optimal.
This result is so clear that we deem it superfluous to run the same experiment as above with other values of <span class="math notranslate nohighlight">\(c\)</span>.</p>
<div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">search_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.2</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">search_space</span><span class="p">:</span>
            <span class="n">player</span> <span class="o">=</span> <span class="s2">&quot;UCTPlayer(</span><span class="si">%s</span><span class="s2">, td(seconds=5), c=1.5)&quot;</span>
            <span class="n">opponent</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;UCTPlayer(%s, td(seconds=5), c=</span><span class="si">{</span><span class="n">c</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span>

            <span class="n">sumbit_symmetric_match</span><span class="p">(</span><span class="n">player</span><span class="p">,</span> <span class="n">opponent</span><span class="p">,</span> <span class="s2">&quot;uct-tuning-c-15&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div><p>While the curve in <a class="reference internal" href="#fig-uct-tuning-c-15"><span class="std std-numref">Figure 17</span></a> is not as smooth either, the result of the matches against <span class="math notranslate nohighlight">\(c = 1.5\)</span> seems to show the same curve with a maximum at <span class="math notranslate nohighlight">\(c = \sqrt(2) / 2\)</span>.</p>
<figure class="align-default" id="id71">
<span id="fig-uct-tuning-c-15"></span><img alt="_images/index_129_0.svg" src="_images/index_129_0.svg" /><figcaption>
<p><span class="caption-number">Figure 17 </span><span class="caption-text">Strength of <span class="math notranslate nohighlight">\(UCT(c=1.5\)</span>) against other values of <span class="math notranslate nohighlight">\(c\)</span>.</span><a class="headerlink" href="#id71" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id47">
<h3><a class="toc-backref" href="#id111"><span class="section-number">7.1.4. </span>Heavy playouts</a><a class="headerlink" href="#id47" title="Permalink to this headline">¶</a></h3>
<p>The Informed UCT agent also has 2 variables that we can tune, <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(c\)</span>. As for UCT, we fix <span class="math notranslate nohighlight">\(t=5s\)</span> to be able to fairly compare MCTS, UTC and Informed UCT later. To tune <span class="math notranslate nohighlight">\(c\)</span>, we use the same starting point as in <a class="reference internal" href="#sec-uct-tuning"><span class="std std-numref">Section 7.1.3</span></a> and find similar results. We thus also choose <span class="math notranslate nohighlight">\(c = \sqrt(2) / 2\)</span> as the value for our champion.</p>
<div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">search_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.2</span>
<span class="n">fine_search_space</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">search_space</span><span class="p">:</span>
            <span class="n">player</span> <span class="o">=</span> <span class="s2">&quot;GreedyUCTPlayer(</span><span class="si">%s</span><span class="s2">, td(seconds=5), c=math.sqrt(2)/2)&quot;</span>
            <span class="n">opponent</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;GreedyUCTPlayer(%s, td(seconds=5), c=</span><span class="si">{</span><span class="n">c</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span>

            <span class="n">sumbit_symmetric_match</span><span class="p">(</span><span class="n">player</span><span class="p">,</span> <span class="n">opponent</span><span class="p">,</span> <span class="s2">&quot;greedy-uct-tuning-c&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">fine_search_space</span><span class="p">:</span>
            <span class="n">player</span> <span class="o">=</span> <span class="s2">&quot;GreedyUCTPlayer(</span><span class="si">%s</span><span class="s2">, td(seconds=5), c=math.sqrt(2)/2)&quot;</span>
            <span class="n">opponent</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;GreedyUCTPlayer(%s, td(seconds=5), c=</span><span class="si">{</span><span class="n">c</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span>

            <span class="n">sumbit_symmetric_match</span><span class="p">(</span><span class="n">player</span><span class="p">,</span> <span class="n">opponent</span><span class="p">,</span> <span class="s2">&quot;greedy-uct-tuning-c-fine&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div><figure class="align-default">
<img alt="_images/index_133_0.svg" src="_images/index_133_0.svg" /></figure>
</section>
</section>
<section id="tournament-results">
<span id="sec-tournament"></span><h2><a class="toc-backref" href="#id112"><span class="section-number">7.2. </span>Tournament results</a><a class="headerlink" href="#tournament-results" title="Permalink to this headline">¶</a></h2>
<p>We select the best agent for every algorithm and make each of them play 50 match against each other.</p>
<div class="code-hide"><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">algos</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;RandomPlayer(</span><span class="si">%i</span><span class="s2">)&quot;</span><span class="p">,</span>
    <span class="s2">&quot;GreedyPlayer(</span><span class="si">%i</span><span class="s2">, 0.95)&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MCTSPlayer(</span><span class="si">%i</span><span class="s2">, td(seconds=5))&quot;</span><span class="p">,</span>
    <span class="s2">&quot;UCTPlayer(</span><span class="si">%i</span><span class="s2">, td(seconds=5), c=math.sqrt(2)/2)&quot;</span><span class="p">,</span>
    <span class="s2">&quot;GreedyUCTPlayer(</span><span class="si">%i</span><span class="s2">, td(seconds=5), c=math.sqrt(2)/2)&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">algos</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">algos</span><span class="p">:</span>
            <span class="n">sumbit_symmetric_match</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="s2">&quot;tournament&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div><p>The results are represented in a matrix (<a class="reference internal" href="#fig-matrix"><span class="std std-numref">Figure 18</span></a>, left) sorted in alphabetic order. It shows the ratio of win of the row player against the column player. We then transform this result in a binary weak tournament by computing the <span class="math notranslate nohighlight">\(\succeq\)</span> relation as explained in <a class="reference internal" href="#sec-compare-ab"><span class="std std-numref">Section 6.1.1</span></a>. The results are shown on the right of <a class="reference internal" href="#fig-matrix"><span class="std std-numref">Figure 18</span></a>.</p>
<figure class="align-default" id="id72">
<span id="fig-matrix"></span><img alt="_images/index_137_0.svg" src="_images/index_137_0.svg" /><figcaption>
<p><span class="caption-number">Figure 18 </span><span class="caption-text">Matrix representation of the valued and binary tournaments between every champion</span><a class="headerlink" href="#id72" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>We can see that this binary matrix representation of our tournament is not step-type. We can however use a method from <a class="bibtex reference internal" href="#roubensvincke85" id="id48">[Roubens, 1985]</a> to reorder the lines so that the sum of the values of the lines are increasing from top to bottom while keeping the same order for both lines and columns. This yields the matrix shown in <a class="reference internal" href="#fig-step-type"><span class="std std-numref">Figure 19</span></a>.</p>
<figure class="align-default" id="id73">
<span id="fig-step-type"></span><img alt="_images/index_140_0.svg" src="_images/index_140_0.svg" /><figcaption>
<p><span class="caption-number">Figure 19 </span><span class="caption-text">The step-type matrix representation of the weak tournament</span><a class="headerlink" href="#id73" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>We can see that this binary matrix is a representation of our weak tournament and is step-type. This means that our weak tournament is not only complete but also transitive and it yields the following weak order shown in <a class="reference internal" href="#fig-order"><span class="std std-numref">Figure 20</span></a>: the random and greedy agents do not have a significant strength difference between them; the basic MCTS beats them both and gets beaten by UCT and greedy UCT.</p>
<figure class="align-default" id="id74">
<span id="fig-order"></span><a class="reference internal image-reference" href="_images/order.svg"><img alt="_images/order.svg" src="_images/order.svg" width="70%" /></a>
<figcaption>
<p><span class="caption-number">Figure 20 </span><span class="caption-text">Graph representation of the weak order between our champions</span><a class="headerlink" href="#id74" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>While we did expect the random and greedy agents to have poor performance and UCT to outperform plain MCTS, we intuitively thought that heavy playouts could only improve the performance of the UCT algorithm, our results do not show a significant improvement over plain UCT. But this seems to be expected as in some cases, stronger rollouts can decrease the agent strength <a class="bibtex reference internal" href="#gelly2007" id="id49">[Gelly, 2007]</a>. Heavy playouts is still an open subject with research like <a class="bibtex reference internal" href="#swiechowski2014" id="id50">[Świechowski, 2014]</a> and <a class="bibtex reference internal" href="#soemers2019" id="id51">[Soemers, 2019]</a>.</p>
</section>
</section>
<section id="conclusion">
<span id="sec-conclusion"></span><h1><a class="toc-backref" href="#id113"><span class="section-number">8. </span>Conclusion</a><a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h1>
<p>In this work, we introduced Game Theory concepts and used those to explore different machine learning approaches to Awale, from the simple, greedy, algorithm to advanced variants of MCTS like UCT with heavy playouts.
After designing a statistical framework to compare the strength of different agents, we ran a massive amount of simulations and were able to rank our different implementations despite the strength relation not being transitive in all cases.</p>
<p>We showed that MCTS is a powerful method that is significantly better than a naive, greedy, agent.
We then showed that UCT, by applying to MCTS techniques solving the multi-armed bandit problem, is in turn vastly superior to the original MCTS due to the intelligent prioritization of some branches of the game tree. We then tried to improve UCT by using heavy playouts but, while not diminishing the strength of the algorithm, we were not able to improve it above the strength of the original algorithm. This was not a surprise as heavy playouts might decrease agent strength in some cases.</p>
<h1>Acknowledgements</h1><p>I would like to thank everybody that helped me and supported me during the writing of my thesis, with a particular mention to my parents that encouraged me to finish my studies, my partner that was always supportive, my promotor that followed me during the many years of my master studies and my colleague that gave me the opportunity to write while working. Thank you all from the bottom of my heart!</p>
<h1>References</h1><p id="bibtex-bibliography-index-0"><dl class="bibtex citation">
<dt class="bibtex label" id="crane1982"><span class="brackets"><a class="fn-backref" href="#id1">Crane, 1982</a></span></dt>
<dd><p>Louise Crane. <em>African Games of Strategy: A Teaching Manual</em>. Volume 2 of African outreach series. African Studies Program, University of Illinois at Urbana-Champaign, 1982.</p>
</dd>
<dt class="bibtex label" id="devoogt2008"><span class="brackets">Voogt, 2014</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id8">2</a>)</span></dt>
<dd><p>Alex de Voogt. <em>Encyclopaedia of the History of Science, Technology, and Medicine in Non-Western Cultures</em>. Springer Netherlands, Dordrecht, 2014. ISBN 978-94-007-3934-5. <a class="reference external" href="https://doi.org/10.1007/978-94-007-3934-5_9947-1">doi:10.1007/978-94-007-3934-5_9947-1</a>.</p>
</dd>
<dt class="bibtex label" id="owaresociety"><span class="brackets"><a class="fn-backref" href="#id4">Society, 2020</a></span></dt>
<dd><p>The Oware Society. The Oware Society. 2020. URL: <a class="reference external" href="http://www.oware.org/index.asp">http://www.oware.org/index.asp</a>.</p>
</dd>
<dt class="bibtex label" id="fandom-tournaments"><span class="brackets"><a class="fn-backref" href="#id5">World, 2020</a></span></dt>
<dd><p>Mancala World. 2020. URL: <a class="reference external" href="https://mancala.fandom.com/wiki/Tournaments">https://mancala.fandom.com/wiki/Tournaments</a>.</p>
</dd>
<dt class="bibtex label" id="irving2000solving"><span class="brackets"><a class="fn-backref" href="#id6">Irving, 2000</a></span></dt>
<dd><p>Geoffrey Irving, Jeroen Donkers, and Jos Uiterwijk. Solving kalah. <em>ICGA Journal</em>, 23(3):139–147, 2000. <a class="reference external" href="https://doi.org/10.3233/ICG-2000-23303">doi:10.3233/ICG-2000-23303</a>.</p>
</dd>
<dt class="bibtex label" id="russel1964"><span class="brackets"><a class="fn-backref" href="#id7">Russel, 1964</a></span></dt>
<dd><p>Richard Russel. Kalah: the game and the program. <em>Stanford Artificial Intelligence Project Memo</em>, 1964.</p>
</dd>
<dt class="bibtex label" id="icga-olympiad"><span class="brackets"><a class="fn-backref" href="#id9">Olympiad, 2000</a></span></dt>
<dd><p>Computer Olympiad. 2000. URL: <a class="reference external" href="https://icga.org/icga/news/Olympiad/MSOOlympiad/">https://icga.org/icga/news/Olympiad/MSOOlympiad/</a>.</p>
</dd>
<dt class="bibtex label" id="goot2001"><span class="brackets">Goot, 2000</span><span class="fn-backref">(<a href="#id10">1</a>,<a href="#id20">2</a>)</span></dt>
<dd><p>Roel van der Goot. Awari retrograde analysis. In <em>Computers and Games</em>, volume 2063 of Lecture Notes in Computer Science, 87–95. Berlin, Heidelberg, 2000. Springer. <a class="reference external" href="https://doi.org/10.1007/3-540-45579-5_6">doi:10.1007/3-540-45579-5_6</a>.</p>
</dd>
<dt class="bibtex label" id="jupyter"><span class="brackets"><a class="fn-backref" href="#id11">Kluyver, 2016</a></span></dt>
<dd><p>Thomas Kluyver, Benjamin Ragan-Kelley, Fernando Pérez, Brian Granger, Matthias Bussonnier, Jonathan Frederic, Kyle Kelley, Jessica Hamrick, Jason Grout, Sylvain Corlay, Paul Ivanov, Damián Avila, Safia Abdalla, Carol Willing, and Jupyter development team. Jupyter notebooks - a publishing format for reproducible computational workflows. In Fernando Loizides and Birgit Scmidt, editors, <em>Positioning and Power in Academic Publishing: Players, Agents and Agendas</em>, 87–90. Netherlands, 2016. IOS Press.</p>
</dd>
<dt class="bibtex label" id="maschlersolanzamir2013"><span class="brackets">Maschler, 2013</span><span class="fn-backref">(<a href="#id13">1</a>,<a href="#id15">2</a>)</span></dt>
<dd><p>M. Maschler, E. Solan, and S. Zamir. <em>Game Theory</em>. Cambridge University Press, Cambridge, 2013.</p>
</dd>
<dt class="bibtex label" id="vonneumann1928"><span class="brackets"><a class="fn-backref" href="#id14">Neumann, 1928</a></span></dt>
<dd><p>John von Neumann. Zur Theorie der Gesellschaftsspiele. <em>Mathematische Annalen</em>, 100:295–320, 1928. English translation in Tucker Albert William and Luce Robert Duncan (eds.), Contribution to the Theory of Games, Annals of Mathematics Studies, 40, 1959, 295–320.</p>
</dd>
<dt class="bibtex label" id="alphazero"><span class="brackets">Silver, 2018</span><span class="fn-backref">(<a href="#id16">1</a>,<a href="#id34">2</a>)</span></dt>
<dd><p>David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, and Demis Hassabis. A general reinforcement learning algorithm that masters chess, shogi, and go through self-play. <em>Science</em>, 362(6419):1140–1144, 2018. <a class="reference external" href="https://doi.org/10.1126/science.aar6404">doi:10.1126/science.aar6404</a>.</p>
</dd>
<dt class="bibtex label" id="shannon1988"><span class="brackets"><a class="fn-backref" href="#id17">Shannon, 1988</a></span></dt>
<dd><p>Claude Elwood Shannon. <em>Programming a Computer for Playing Chess</em>, pages 2–13. Springer New York, New York, NY, 1988. <a class="reference external" href="https://doi.org/10.1007/978-1-4757-1968-0_1">doi:10.1007/978-1-4757-1968-0_1</a>.</p>
</dd>
<dt class="bibtex label" id="russell2019artificial"><span class="brackets"><a class="fn-backref" href="#id18">Russell, 2019</a></span></dt>
<dd><p>S.J. Russell, S. Russell, and P. Norvig. <em>Artificial Intelligence: A Modern Approach</em>. Pearson series in artificial intelligence. Pearson, 4 edition, 2019.</p>
</dd>
<dt class="bibtex label" id="vandenherik2002"><span class="brackets"><a class="fn-backref" href="#id19">Herik, 2002</a></span></dt>
<dd><p>H. Jaap van den Herik, Jos W.H.M. Uiterwijk, and Jack van Rijswijck. Games solved: now and in the future. <em>Artificial Intelligence</em>, 134:277–311, 2002. <a class="reference external" href="https://doi.org/10.1016/S0004-3702(01)00152-7">doi:10.1016/S0004-3702(01)00152-7</a>.</p>
</dd>
<dt class="bibtex label" id="endgame1970"><span class="brackets"><a class="fn-backref" href="#id21">Ströhlein, 1970</a></span></dt>
<dd><p>Thomas Ströhlein. <em>Untersuchungen über Kombinatorische Spiele</em>. PhD thesis, Technische Hochschule München, 1970.</p>
</dd>
<dt class="bibtex label" id="allis1995"><span class="brackets"><a class="fn-backref" href="#id22">Bal, 1995</a></span></dt>
<dd><p>Henri Bal and Victor Allis. Parallel retrograde analysis on a distributed system. In <em>Proceedings of the 1995 ACM/IEEE Conference on Supercomputing</em>, Supercomputing ‘95, 73–73. 1995. <a class="reference external" href="https://doi.org/10.1145/224170.224470">doi:10.1145/224170.224470</a>.</p>
</dd>
<dt class="bibtex label" id="romein2003solving"><span class="brackets">Romein, 2003</span><span class="fn-backref">(<a href="#id23">1</a>,<a href="#id24">2</a>)</span></dt>
<dd><p>John W Romein and Henri E Bal. Solving awari with parallel retrograde analysis. <em>Computer</em>, 36(10):26–33, 2003. <a class="reference external" href="https://doi.org/10.1109/MC.2003.1236468">doi:10.1109/MC.2003.1236468</a>.</p>
</dd>
<dt class="bibtex label" id="coulom2006mcts"><span class="brackets">Coulom, 2007</span><span class="fn-backref">(<a href="#id25">1</a>,<a href="#id28">2</a>)</span></dt>
<dd><p>Rémi Coulom. Efficient selectivity and backup operators in monte-carlo tree search. In H. Jaap van den Herik, Paolo Ciancarini, and H. H. L. M. (Jeroen) Donkers, editors, <em>Computers and Games</em>, 72–83. Berlin, Heidelberg, 2007. Springer Berlin Heidelberg.</p>
</dd>
<dt class="bibtex label" id="bouzy2004montecarlo"><span class="brackets"><a class="fn-backref" href="#id26">Bouzy, 2004</a></span></dt>
<dd><p>B. Bouzy and B. Helmstetter. <em>Monte-Carlo Go Developments</em>, pages 159–174. Springer US, Boston, MA, 2004. <a class="reference external" href="https://doi.org/10.1007/978-0-387-35706-5_11">doi:10.1007/978-0-387-35706-5_11</a>.</p>
</dd>
<dt class="bibtex label" id="chaslot2008monte"><span class="brackets"><a class="fn-backref" href="#id27">Chaslot, 2008</a></span></dt>
<dd><p>Guillaume Chaslot, Sander Bakkes, Istvan Szita, and Pieter Spronck. Monte-carlo tree search: a new framework for game ai. In A. Nijholt, M. Pantic, M. Poel, and H. Hondorp, editors, <em>Proceedings of the BNAIC 2008, the twentieth Belgian-Dutch Artificial Intelligence Conference</em>, 389–390. University of Twente, 2008.</p>
</dd>
<dt class="bibtex label" id="browne2012survey"><span class="brackets"><a class="fn-backref" href="#id29">Browne, 2012</a></span></dt>
<dd><p>Cameron Browne, Edward Powley, Daniel Whitehouse, Simon Lucas, Peter Cowling, Philipp Rohlfshagen, Stephen Tavener, Diego Perez, Spyridon Samothrakis, and Simon Colton. A survey of monte carlo tree search methods. <em>IEEE Transactions on Computational Intelligence and AI in Games</em>, 4(1):1–43, 2012. <a class="reference external" href="https://doi.org/10.1109/TCIAIG.2012.2186810">doi:10.1109/TCIAIG.2012.2186810</a>.</p>
</dd>
<dt class="bibtex label" id="kocsis2006bandit"><span class="brackets">Kocsis, 2006</span><span class="fn-backref">(<a href="#id30">1</a>,<a href="#id46">2</a>)</span></dt>
<dd><p>Levente Kocsis and Csaba Szepesvári. Bandit based monte-carlo planning. In <em>European conference on machine learning</em>, 282–293. Springer Berlin Heidelberg, 2006. <a class="reference external" href="https://doi.org/10.1007/11871842_29">doi:10.1007/11871842_29</a>.</p>
</dd>
<dt class="bibtex label" id="gelly20111rave"><span class="brackets"><a class="fn-backref" href="#id31">Gelly, 2011</a></span></dt>
<dd><p>Sylvain Gelly and David Silver. Monte-carlo tree search and rapid action value estimation in computer go. <em>Artificial Intelligence</em>, 175(11):1856 – 1875, 2011. <a class="reference external" href="https://doi.org/https://doi.org/10.1016/j.artint.2011.03.007">doi:https://doi.org/10.1016/j.artint.2011.03.007</a>.</p>
</dd>
<dt class="bibtex label" id="alphago"><span class="brackets"><a class="fn-backref" href="#id32">Silver, 2016</a></span></dt>
<dd><p>David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. Mastering the game of Go with deep neural networks and tree search. <em>Nature</em>, 529:484–489, 2016. <a class="reference external" href="https://doi.org/10.1038/nature16961">doi:10.1038/nature16961</a>.</p>
</dd>
<dt class="bibtex label" id="alphagozero"><span class="brackets"><a class="fn-backref" href="#id33">Silver, 2017</a></span></dt>
<dd><p>David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, and others. Mastering the game of go without human knowledge. <em>Nature</em>, 550:354, 2017. <a class="reference external" href="https://doi.org/10.1038/nature24270">doi:10.1038/nature24270</a>.</p>
</dd>
<dt class="bibtex label" id="davis2002"><span class="brackets"><a class="fn-backref" href="#id35">Davis, 2002</a></span></dt>
<dd><p>J.E. Davis and G. Kendall. An investigation, using co-evolution, to evolve an awari player. In <em>Proceedings of the 2002 Congress on Evolutionary Computation. CEC’02 (Cat. No.02TH8600)</em>, volume 2, 1408–1413 vol.2. 2002. <a class="reference external" href="https://doi.org/10.1109/CEC.2002.1004449">doi:10.1109/CEC.2002.1004449</a>.</p>
</dd>
<dt class="bibtex label" id="pekar2020"><span class="brackets"><a class="fn-backref" href="#id36">Pekař, 2020</a></span></dt>
<dd><p>Libor Pekař, Radek Matušů, Jiří Andrla, and Martina Litschmannová. Review of kalah game research and the proposition of a novel heuristic–deterministic algorithm compared to tree-search solutions and human decision-making. <em>Informatics</em>, 2020.</p>
</dd>
<dt class="bibtex label" id="berkman2016"><span class="brackets"><a class="fn-backref" href="#id37">Berkman, 2016</a></span></dt>
<dd><p>Tadeáš Berkman. Algoritmy pro hry mankala. Master’s thesis, Univerzita Karlova, Matematicko-fyzikální fakulta, 2016.</p>
</dd>
<dt class="bibtex label" id="rovaris2016"><span class="brackets"><a class="fn-backref" href="#id38">Rovaris, 2016</a></span></dt>
<dd><p>Gabriele Rovaris. Design of artificial intelligence for mancala games. Master’s thesis, Politecnico Di Milano, 2016.</p>
</dd>
<dt class="bibtex label" id="birell2019"><span class="brackets"><a class="fn-backref" href="#id39">Birell, 2019</a></span></dt>
<dd><p>Tiffanie Birell. Padawan to jedi: using reinforcement learning to train an agent to play mancala. Master’s thesis, Abilene Christian University, 2019.</p>
</dd>
<dt class="bibtex label" id="brandt2016"><span class="brackets"><a class="fn-backref" href="#id40">Brandt, 2016</a></span></dt>
<dd><p>Felix Brandt, Markus Brill, and Paul Harrenstein. Tournament solutions. In Felix Brandt, Vincent Conitzer, Ulle Endriss, Jérôme Lang, and Ariel D. Procaccia, editors, <em>Handbook of Computational Social Choice</em>, pages 57–84. Cambridge University Press, 2016. <a class="reference external" href="https://doi.org/10.1017/CBO9781107446984.004">doi:10.1017/CBO9781107446984.004</a>.</p>
</dd>
<dt class="bibtex label" id="pirlotvincke97"><span class="brackets"><a class="fn-backref" href="#id41">Pirlot, 1997</a></span></dt>
<dd><p>M. Pirlot and P. Vincke. <em>Semiorders. Properties, representations, applications</em>. Theory and Decision Library. Kluwer Academic Publishers, Dordrecht, 1997.</p>
</dd>
<dt class="bibtex label" id="roubensvincke85"><span class="brackets">Roubens, 1985</span><span class="fn-backref">(<a href="#id42">1</a>,<a href="#id48">2</a>)</span></dt>
<dd><p>M. Roubens and P. Vincke. <em>Preference modelling</em>. Lecture Notes in Economics and Mathematical Systems. Springer-Verlag, Heidelberg, 1985.</p>
</dd>
<dt class="bibtex label" id="pandas"><span class="brackets"><a class="fn-backref" href="#id44">McKinney, 2010</a></span></dt>
<dd><p>Wes McKinney. Data Structures for Statistical Computing in Python. In Stéfan van der Walt and Jarrod Millman, editors, <em>Proceedings of the 9th Python in Science Conference</em>, 56 – 61. 2010. <a class="reference external" href="https://doi.org/10.25080/Majora-92bf1922-00a">doi:10.25080/Majora-92bf1922-00a</a>.</p>
</dd>
<dt class="bibtex label" id="gelly2007"><span class="brackets"><a class="fn-backref" href="#id49">Gelly, 2007</a></span></dt>
<dd><p>Sylvain Gelly and David Silver. Combining online and offline knowledge in uct. In <em>Proceedings of the 24th International Conference on Machine Learning</em>, ICML ‘07, 273–280. New York, NY, USA, 2007. Association for Computing Machinery. <a class="reference external" href="https://doi.org/10.1145/1273496.1273531">doi:10.1145/1273496.1273531</a>.</p>
</dd>
<dt class="bibtex label" id="swiechowski2014"><span class="brackets"><a class="fn-backref" href="#id50">Świechowski, 2014</a></span></dt>
<dd><p>Maciej Świechowski and Jacek Mańdziuk. Self-adaptation of playing strategies in general game playing. <em>IEEE Transactions on Computational Intelligence and AI in Games</em>, 6(4):367–381, 2014. <a class="reference external" href="https://doi.org/10.1109/TCIAIG.2013.2275163">doi:10.1109/TCIAIG.2013.2275163</a>.</p>
</dd>
<dt class="bibtex label" id="soemers2019"><span class="brackets"><a class="fn-backref" href="#id51">Soemers, 2019</a></span></dt>
<dd><p>Dennis J. N. J. Soemers, Éric Piette, and Cameron Browne. Biasing mcts with features for general games. In <em>2019 IEEE Congress on Evolutionary Computation (CEC)</em>, 450–457. 2019. <a class="reference external" href="https://doi.org/10.1109/CEC.2019.8790141">doi:10.1109/CEC.2019.8790141</a>.</p>
</dd>
</dl>
</p>
<h1>Notes</h1><dl class="footnote brackets">
<dt class="label" id="source-bao"><span class="brackets"><a class="fn-backref" href="#id3">1</a></span></dt>
<dd><p>Picture by Yintan under Creative Commons SA license <a class="reference external" href="https://commons.wikimedia.org/wiki/File:Bao_europe.jpg">https://commons.wikimedia.org/wiki/File:Bao_europe.jpg</a></p>
<dt class="label" id="loop"><span class="brackets"><a class="fn-backref" href="#id12">2</a></span></dt>
<dd><p>We did later encounter loops after running way more simulations. But this only happened using basic algorithms (greedy vs greedy for example). In the experiments, we thus simulate 500 turns, if we hit this threshold, we declare a tie.</p>
</dd>
<dt class="label" id="aws-c5"><span class="brackets"><a class="fn-backref" href="#id43">3</a></span></dt>
<dd><p>C5 instances contain a 2nd generation Intel Xeon Scalable Processor (Cascade Lake) with a sustained all core Turbo frequency of 3.6GHz.</p>
</dd>
</dl>
</dd>
</dl>
</section>


          </div>
          
        </div>
      </div>
  </div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="#">Playing Awale with MCTS</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Nikita Marchant.
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>