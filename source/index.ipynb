{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. raw:: html\n",
    "\n",
    "    <section class=\"first-page\">\n",
    "        <h1>Playing Awale with MCTS</h1>\n",
    "        <h2>Master thesis submitted in partial fulfilment of the requirements\n",
    "        for the degree of Master of Science in Applied Sciences and Engineering:&nbsp;Computer Science\n",
    "        </h2>\n",
    "\n",
    "        2020-2021\n",
    "    </section>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. contents:: Table of Contents\n",
    "   :depth: 3\n",
    "\n",
    ".. sectnum::"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "============\n",
    "Introduction\n",
    "============\n",
    "\n",
    "Awale is a popular board game played mainly in Africa. The board has two rows of six pits, each containing four seeds in the initial state.\n",
    "\n",
    "At each turn, the players move some seeds and can potentially capture some of them, according to deterministic rules. The goal of the game is to capture more seeds than one's opponent.\n",
    "\n",
    ".. _board:\n",
    "\n",
    ".. figure:: /_static/initial.jpg\n",
    "\n",
    "   A typical Awal√© board in the initial state with both players on their side of the board.\n",
    "   \n",
    "\n",
    ".. todo:: Explain here what i'm going to do in my thesis, why it is interesting and why it is new.\n",
    "\n",
    "In Section 2, we present Awale in detail. We then introduce Game Theory frameworks in Section 3.\n",
    "Section 4 reviews various approaches to solve Awale: retrograde analysis, :math:`\\alpha-\\beta`-pruning Minimax, and basic Monte Carlo Tree Search.\n",
    "In Section 5, we describe more advanced versions of MCTS and in particular UCT.\n",
    "Section 6 presents some empirical results (simulations) allowing to compare several MCTS algorithms and Section 7 concludes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=====\n",
    "Awale\n",
    "=====\n",
    "\n",
    "The subject of our study, Awale is an ancient, two player board game originating from Ghana.\n",
    "This game is also sometimes called Awele, Oware, Owari or Ayo in the neighboring countries, languages and cultures :cite:`crane1982`.\n",
    "\n",
    "Originally, the game is played on the ground, by digging two rows of six small pits, each containing\n",
    "stones, seeds or shells. In the present document, we will name them seeds. The game is also often played on a wooden board symbolizing the original dirt pits.\n",
    "The board can be schematized as in :numref:`Figure %s <fig:initial_board>`, every big circle representing a pit and every small disc representing a seed.\n",
    "Numbers at the bottom right of each pit are the counts of seeds in each pit for better readability.\n",
    "Each row of pits is owned by a player that sits in front of it (:numref:`see Fig. %s <board>`).\n",
    "For the sake of convenience, the players are named North and South.\n",
    "The 6 pits from the top row belong to North and the 6 from the bottom to South.\n",
    "\n",
    "The players take turns, a player removing all the seeds from a pit and placing them in other pits following the rules. This is called sowing the seeds. This can result in a configuration in which the player is allowed to capture some seeds according to the rules.\n",
    "The goal for each player is to capture more seeds than his opponent.\n",
    "The rules vary slightly across countries and will be detailed in :ref:`sec:rules`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": [
     "ha"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/nikita/Code/Thesis/source/lib/draw.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import import_ipynb\n",
    "from lib.draw import board_to_svg, pit_numbering\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hc",
     "fig:initial_board"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"180\" width=\"535\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\"/><text x=\"82.0\" y=\"82.0\">4</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\"/><text x=\"170.0\" y=\"82.0\">4</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\"/><text x=\"258.0\" y=\"82.0\">4</text><circle cx=\"312.0\" cy=\"48.0\" r=\"40\"/><text x=\"346.0\" y=\"82.0\">4</text><circle cx=\"400.0\" cy=\"48.0\" r=\"40\"/><text x=\"434.0\" y=\"82.0\">4</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\"/><text x=\"522.0\" y=\"82.0\">4</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\"/><text x=\"82.0\" y=\"170.0\">4</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\"/><text x=\"170.0\" y=\"170.0\">4</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\"/><text x=\"258.0\" y=\"170.0\">4</text><circle cx=\"312.0\" cy=\"136.0\" r=\"40\"/><text x=\"346.0\" y=\"170.0\">4</text><circle cx=\"400.0\" cy=\"136.0\" r=\"40\"/><text x=\"434.0\" y=\"170.0\">4</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\"/><text x=\"522.0\" y=\"170.0\">4</text>\n",
       "      <circle class=\"bean\" cx=\"57.96338621298683\" cy=\"45.04518441000729\" r=\"4\"/><circle class=\"bean\" cx=\"45.04518441000729\" cy=\"38.036613787013174\" r=\"4\"/><circle class=\"bean\" cx=\"38.03661378701317\" cy=\"50.95481558999271\" r=\"4\"/><circle class=\"bean\" cx=\"50.95481558999271\" cy=\"57.96338621298683\" r=\"4\"/><circle class=\"bean\" cx=\"139.6379811286054\" cy=\"38.265263572756005\" r=\"4\"/><circle class=\"bean\" cx=\"126.26526357275601\" cy=\"44.36201887139462\" r=\"4\"/><circle class=\"bean\" cx=\"132.3620188713946\" cy=\"57.73473642724399\" r=\"4\"/><circle class=\"bean\" cx=\"145.734736427244\" cy=\"51.63798112860538\" r=\"4\"/><circle class=\"bean\" cx=\"228.18989847761674\" cy=\"38.48975548435977\" r=\"4\"/><circle class=\"bean\" cx=\"214.48975548435976\" cy=\"43.81010152238328\" r=\"4\"/><circle class=\"bean\" cx=\"219.81010152238326\" cy=\"57.51024451564023\" r=\"4\"/><circle class=\"bean\" cx=\"233.51024451564024\" cy=\"52.18989847761672\" r=\"4\"/><circle class=\"bean\" cx=\"321.4250576189977\" cy=\"43.621839555409956\" r=\"4\"/><circle class=\"bean\" cx=\"307.62183955540996\" cy=\"38.57494238100227\" r=\"4\"/><circle class=\"bean\" cx=\"302.57494238100224\" cy=\"52.37816044459004\" r=\"4\"/><circle class=\"bean\" cx=\"316.37816044459004\" cy=\"57.42505761899773\" r=\"4\"/><circle class=\"bean\" cx=\"409.55572472891316\" cy=\"52.08511014603493\" r=\"4\"/><circle class=\"bean\" cx=\"404.08511014603494\" cy=\"38.44427527108684\" r=\"4\"/><circle class=\"bean\" cx=\"390.44427527108684\" cy=\"43.91488985396507\" r=\"4\"/><circle class=\"bean\" cx=\"395.91488985396506\" cy=\"57.55572472891316\" r=\"4\"/><circle class=\"bean\" cx=\"490.3950199254441\" cy=\"37.88743951529951\" r=\"4\"/><circle class=\"bean\" cx=\"477.8874395152995\" cy=\"45.604980074555904\" r=\"4\"/><circle class=\"bean\" cx=\"485.6049800745559\" cy=\"58.11256048470049\" r=\"4\"/><circle class=\"bean\" cx=\"498.1125604847005\" cy=\"50.395019925444096\" r=\"4\"/><circle class=\"bean\" cx=\"58.26852775265462\" cy=\"137.5991678438994\" r=\"4\"/><circle class=\"bean\" cx=\"49.5991678438994\" cy=\"125.73147224734538\" r=\"4\"/><circle class=\"bean\" cx=\"37.73147224734538\" cy=\"134.4008321561006\" r=\"4\"/><circle class=\"bean\" cx=\"46.4008321561006\" cy=\"146.26852775265462\" r=\"4\"/><circle class=\"bean\" cx=\"139.20772410691006\" cy=\"126.1151375298415\" r=\"4\"/><circle class=\"bean\" cx=\"126.1151375298415\" cy=\"132.79227589308994\" r=\"4\"/><circle class=\"bean\" cx=\"132.79227589308994\" cy=\"145.8848624701585\" r=\"4\"/><circle class=\"bean\" cx=\"145.8848624701585\" cy=\"139.20772410691006\" r=\"4\"/><circle class=\"bean\" cx=\"225.30287711095676\" cy=\"146.31031091838383\" r=\"4\"/><circle class=\"bean\" cx=\"234.31031091838383\" cy=\"134.69712288904324\" r=\"4\"/><circle class=\"bean\" cx=\"222.69712288904324\" cy=\"125.68968908161617\" r=\"4\"/><circle class=\"bean\" cx=\"213.68968908161617\" cy=\"137.30287711095676\" r=\"4\"/><circle class=\"bean\" cx=\"321.70356603204334\" cy=\"139.72032340822332\" r=\"4\"/><circle class=\"bean\" cx=\"315.7203234082233\" cy=\"126.29643396795665\" r=\"4\"/><circle class=\"bean\" cx=\"302.29643396795666\" cy=\"132.27967659177668\" r=\"4\"/><circle class=\"bean\" cx=\"308.2796765917767\" cy=\"145.70356603204337\" r=\"4\"/><circle class=\"bean\" cx=\"406.4761201720312\" cy=\"127.87227783955366\" r=\"4\"/><circle class=\"bean\" cx=\"391.87227783955365\" cy=\"129.52387982796878\" r=\"4\"/><circle class=\"bean\" cx=\"393.5238798279688\" cy=\"144.12772216044635\" r=\"4\"/><circle class=\"bean\" cx=\"408.12772216044635\" cy=\"142.47612017203122\" r=\"4\"/><circle class=\"bean\" cx=\"493.5437170621958\" cy=\"127.20982360050046\" r=\"4\"/><circle class=\"bean\" cx=\"479.20982360050044\" cy=\"130.45628293780416\" r=\"4\"/><circle class=\"bean\" cx=\"482.4562829378042\" cy=\"144.79017639949956\" r=\"4\"/><circle class=\"bean\" cx=\"496.79017639949956\" cy=\"141.54371706219584\" r=\"4\"/>\n",
       "    </svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = np.full((2, 6), 4)\n",
    "SVG(board_to_svg(board, True))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  A schematized view of the initial state of the board."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mancala\n",
    "-------\n",
    "\n",
    "The Mancala games are an ancient family of game that are played on many continents :cite:`deVoogt2008`, Awale being one of them.\n",
    "The word mancala comes from the Arabic word \"ŸÜŸÇŸÑÿ©\", transliterated as \"naqala\" and literally meaning \"to move\".\n",
    "\n",
    "Like Awale, Mancala games can consist of rows of pits, some of them having more than two rows (:numref:`see Fig. %s <bao>`) and sometimes extra pits with a special role. Mancala games can sometimes be played by more than two players.\n",
    " \n",
    ".. _bao:\n",
    "\n",
    ".. figure:: _static/bao.jpg\n",
    "\n",
    "  A wooden Bao game [#source_bao]_\n",
    "\n",
    "There are too many variants of the Mancala games to list them all here, but a\n",
    "few notable ones are Awale, Wari, Bao, Congkak and Kalah.\n",
    "\n",
    "Mancala games in general, while less known than Chess or Go, are quite popular and\n",
    "are played in tournaments around the world, both in offline and online competitions :cite:`owaresociety,fandom_tournaments`.\n",
    "\n",
    "\n",
    "\n",
    "In particular, Kalah is a commercial, modern variant of Mancala, introduced in the 1950s by William Julius Champion Jr., that is widespread in the United States. :cite:`irving2000solving`. This variant has been studied in Artifical Intelligence as early as 1964 by :cite:`russel1964`.\n",
    "Nowadays, Kalah is often used as an example game in computer-science courses.\n",
    "Other Mancala games have been studied in Computer Science and Artificial Intelligence :cite:`deVoogt2008`. Tournaments opposing computers on both sides have been organised multiple times, notably in the Computer Olympiad organized by the International Computer Games Association :cite:`icga_olympiad`.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _sec:rules:\n",
    "\n",
    "Rules of the game\n",
    "-----------------\n",
    "\n",
    "The basic rules of Awale are the same everywhere but there are some minor differences around the globe and in the literature.\n",
    "The rules presented here and implemented later in this thesis are inspired from :cite:`goot2001` and adapted by us.\n",
    "\n",
    "The goal for each player is to capture more seeds than his opponent. Because the\n",
    "game has 48 seeds, capturing 25 is enough for a player to win and ends the game.\n",
    "\n",
    "Each player plays alternatively, without the right to pass his turn. A\n",
    "player's turn consists in choosing one of his non-empty pits, picking all seeds\n",
    "contained in the pit and sowing them one by one in every consecutive pits on the right\n",
    "(rotating counter-clockwise). The player thus has at most 6 possible moves at\n",
    "each turn (one per non-empty pit owned by him).\n",
    "\n",
    "Usually, the player that starts the game is the oldest player. In this work, South will always play first.\n",
    "\n",
    "In this work, the pits of a player are numbered left to right from his point of view as shown in :numref:`Figure %s <fig:pit_numbering>`. :math:`1` being the leftmost pit of South, until :math:`6` at the far right. The same holds for North: :math:`1'` to :math:`6'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hc",
     "fig:pit_numbering"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"140\" width=\"397\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "  <style>\n",
       "    circle {\n",
       "      fill: none;\n",
       "      stroke: #000;\n",
       "      stroke-width: 2;\n",
       "    }\n",
       "    text {\n",
       "      font-size: 1.5em;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "  <circle cx=\"36.0\" cy=\"36.0\" r=\"30\"/><text x=\"30.0\" y=\"42.0\">6'</text><circle cx=\"102.0\" cy=\"36.0\" r=\"30\"/><text x=\"96.0\" y=\"42.0\">5'</text><circle cx=\"168.0\" cy=\"36.0\" r=\"30\"/><text x=\"162.0\" y=\"42.0\">4'</text><circle cx=\"234.0\" cy=\"36.0\" r=\"30\"/><text x=\"228.0\" y=\"42.0\">3'</text><circle cx=\"300.0\" cy=\"36.0\" r=\"30\"/><text x=\"294.0\" y=\"42.0\">2'</text><circle cx=\"366.0\" cy=\"36.0\" r=\"30\"/><text x=\"360.0\" y=\"42.0\">1'</text><circle cx=\"36.0\" cy=\"102.0\" r=\"30\"/><text x=\"30.0\" y=\"108.0\">1</text><circle cx=\"102.0\" cy=\"102.0\" r=\"30\"/><text x=\"96.0\" y=\"108.0\">2</text><circle cx=\"168.0\" cy=\"102.0\" r=\"30\"/><text x=\"162.0\" y=\"108.0\">3</text><circle cx=\"234.0\" cy=\"102.0\" r=\"30\"/><text x=\"228.0\" y=\"108.0\">4</text><circle cx=\"300.0\" cy=\"102.0\" r=\"30\"/><text x=\"294.0\" y=\"108.0\">5</text><circle cx=\"366.0\" cy=\"102.0\" r=\"30\"/><text x=\"360.0\" y=\"108.0\">6</text>\n",
       "  \n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pit_numbering"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Pit numbering convention: the pits of a player are numbered left to right from his point of view."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "As an example, in the initial state (:numref:`See Fig. %s <fig:initial_board>`), the first player to move is South (on the bottom) and he plays :math:`4` (highlighted in the figure in red), the board will then be in the  state shown in :numref:`Figure %s <fig:first_move>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hc",
     "fig:first_move"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"180\" width=\"535\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\"/><text x=\"82.0\" y=\"82.0\">4</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\"/><text x=\"170.0\" y=\"82.0\">4</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\"/><text x=\"258.0\" y=\"82.0\">4</text><circle cx=\"312.0\" cy=\"48.0\" r=\"40\"/><text x=\"346.0\" y=\"82.0\">4</text><circle cx=\"400.0\" cy=\"48.0\" r=\"40\"/><text x=\"434.0\" y=\"82.0\">5</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\"/><text x=\"522.0\" y=\"82.0\">5</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\"/><text x=\"82.0\" y=\"170.0\">4</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\"/><text x=\"170.0\" y=\"170.0\">4</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\"/><text x=\"258.0\" y=\"170.0\">4</text><circle class=\"highlight\" cx=\"312.0\" cy=\"136.0\" r=\"40\"/><text x=\"346.0\" y=\"170.0\">0</text><circle cx=\"400.0\" cy=\"136.0\" r=\"40\"/><text x=\"434.0\" y=\"170.0\">5</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\"/><text x=\"522.0\" y=\"170.0\">5</text>\n",
       "      <circle class=\"bean\" cx=\"54.894317132122836\" cy=\"55.77614244222144\" r=\"4\"/><circle class=\"bean\" cx=\"55.77614244222144\" cy=\"41.10568286787717\" r=\"4\"/><circle class=\"bean\" cx=\"41.10568286787717\" cy=\"40.22385755777856\" r=\"4\"/><circle class=\"bean\" cx=\"40.223857557778565\" cy=\"54.894317132122836\" r=\"4\"/><circle class=\"bean\" cx=\"145.03493399791688\" cy=\"53.13516968106078\" r=\"4\"/><circle class=\"bean\" cx=\"141.13516968106077\" cy=\"38.965066002083134\" r=\"4\"/><circle class=\"bean\" cx=\"126.96506600208313\" cy=\"42.86483031893922\" r=\"4\"/><circle class=\"bean\" cx=\"130.86483031893923\" cy=\"57.034933997916866\" r=\"4\"/><circle class=\"bean\" cx=\"230.02537764783264\" cy=\"56.46727962222808\" r=\"4\"/><circle class=\"bean\" cx=\"232.4672796222281\" cy=\"41.974622352167366\" r=\"4\"/><circle class=\"bean\" cx=\"217.97462235216736\" cy=\"39.53272037777192\" r=\"4\"/><circle class=\"bean\" cx=\"215.5327203777719\" cy=\"54.025377647832634\" r=\"4\"/><circle class=\"bean\" cx=\"314.0587010969521\" cy=\"37.8136488479236\" r=\"4\"/><circle class=\"bean\" cx=\"301.8136488479236\" cy=\"45.94129890304789\" r=\"4\"/><circle class=\"bean\" cx=\"309.9412989030479\" cy=\"58.1863511520764\" r=\"4\"/><circle class=\"bean\" cx=\"322.1863511520764\" cy=\"50.05870109695211\" r=\"4\"/><circle class=\"bean\" cx=\"407.3525907205025\" cy=\"38.51636094651531\" r=\"4\"/><circle class=\"bean\" cx=\"393.252598765311\" cy=\"38.076665047570074\" r=\"4\"/><circle class=\"bean\" cx=\"388.47728598072666\" cy=\"51.35068077113317\" r=\"4\"/><circle class=\"bean\" cx=\"399.6259723281332\" cy=\"59.99416955444094\" r=\"4\"/><circle class=\"bean\" cx=\"411.29155220532664\" cy=\"52.06212368034051\" r=\"4\"/><circle class=\"bean\" cx=\"499.17588781541406\" cy=\"43.6296989191499\" r=\"4\"/><circle class=\"bean\" cx=\"487.2971359410766\" cy=\"36.02060176324897\" r=\"4\"/><circle class=\"bean\" cx=\"476.38971830670056\" cy=\"44.96662580576741\" r=\"4\"/><circle class=\"bean\" cx=\"481.52731535350364\" cy=\"58.104669884118465\" r=\"4\"/><circle class=\"bean\" cx=\"495.6099425833051\" cy=\"57.278403627715264\" r=\"4\"/><circle class=\"bean\" cx=\"52.78390752753907\" cy=\"145.22573730213227\" r=\"4\"/><circle class=\"bean\" cx=\"57.22573730213228\" cy=\"131.21609247246093\" r=\"4\"/><circle class=\"bean\" cx=\"43.21609247246093\" cy=\"126.77426269786773\" r=\"4\"/><circle class=\"bean\" cx=\"38.77426269786772\" cy=\"140.78390752753907\" r=\"4\"/><circle class=\"bean\" cx=\"137.38494721626037\" cy=\"125.70039218182689\" r=\"4\"/><circle class=\"bean\" cx=\"125.70039218182689\" cy=\"134.61505278373963\" r=\"4\"/><circle class=\"bean\" cx=\"134.61505278373963\" cy=\"146.29960781817311\" r=\"4\"/><circle class=\"bean\" cx=\"146.29960781817311\" cy=\"137.38494721626037\" r=\"4\"/><circle class=\"bean\" cx=\"227.39968941065777\" cy=\"145.82049448404007\" r=\"4\"/><circle class=\"bean\" cx=\"233.82049448404007\" cy=\"132.60031058934223\" r=\"4\"/><circle class=\"bean\" cx=\"220.60031058934223\" cy=\"126.17950551595993\" r=\"4\"/><circle class=\"bean\" cx=\"214.17950551595993\" cy=\"139.39968941065777\" r=\"4\"/><circle class=\"bean\" cx=\"409.775817263645\" cy=\"129.040589333297\" r=\"4\"/><circle class=\"bean\" cx=\"396.4021008042284\" cy=\"124.55206912245421\" r=\"4\"/><circle class=\"bean\" cx=\"388.0005587452722\" cy=\"135.88420028352033\" r=\"4\"/><circle class=\"bean\" cx=\"396.18183665434213\" cy=\"147.37636271687373\" r=\"4\"/><circle class=\"bean\" cx=\"409.6396865325122\" cy=\"143.14677854385474\" r=\"4\"/><circle class=\"bean\" cx=\"499.99920094057774\" cy=\"135.861519721123\" r=\"4\"/><circle class=\"bean\" cx=\"491.57625443795405\" cy=\"124.5452889955698\" r=\"4\"/><circle class=\"bean\" cx=\"478.21104585449547\" cy=\"129.0590795468317\" r=\"4\"/><circle class=\"bean\" cx=\"478.37383918580997\" cy=\"143.16498625116287\" r=\"4\"/><circle class=\"bean\" cx=\"491.8396595811627\" cy=\"147.36912548531262\" r=\"4\"/>\n",
       "    </svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = np.array([[4, 4, 4, 4, 5, 5], [4, 4, 4, 0, 5, 5],])\n",
    "SVG(board_to_svg(board, True, highlight=[(1, 3)]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  The board after the forst move, where South played pit 4."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When the last sowed seed is placed in a pit owned by the opponent and, after sowing,\n",
    "the pit contains two or three seeds, the content of the pit is captured by\n",
    "the player and removed from the game. If the pit preceding the captured pit also\n",
    "contains two or three seeds, it is also captured. The capture continues until a\n",
    "pit without two or three seeds is encountered. When the capture is ended the\n",
    "next player's turn starts.\n",
    "\n",
    "Otherwise, when the last sowed seed is placed in a pit that, after sowing, contains one seed, more\n",
    "than 3 seeds or in the current player's own pits, the turn of the player is ended without\n",
    "any capture.\n",
    "For example, if South plays :math:`4` in the configuration shown in :numref:`Figure %s <fig:pre_capture>`, he will\n",
    "be able to capture the seeds in pits 2' and 3' (highlighted in red in :numref:`Figure %s <fig:post_capture>`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hc",
     "fig:pre_capture"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"180\" width=\"535\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\"/><text x=\"82.0\" y=\"82.0\">4</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\"/><text x=\"170.0\" y=\"82.0\">6</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\"/><text x=\"258.0\" y=\"82.0\">4</text><circle cx=\"312.0\" cy=\"48.0\" r=\"40\"/><text x=\"346.0\" y=\"82.0\">1</text><circle cx=\"400.0\" cy=\"48.0\" r=\"40\"/><text x=\"434.0\" y=\"82.0\">2</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\"/><text x=\"522.0\" y=\"82.0\">3</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\"/><text x=\"82.0\" y=\"170.0\">3</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\"/><text x=\"170.0\" y=\"170.0\">3</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\"/><text x=\"258.0\" y=\"170.0\">3</text><circle class=\"highlight\" cx=\"312.0\" cy=\"136.0\" r=\"40\"/><text x=\"346.0\" y=\"170.0\">5</text><circle cx=\"400.0\" cy=\"136.0\" r=\"40\"/><text x=\"434.0\" y=\"170.0\">2</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\"/><text x=\"522.0\" y=\"170.0\">2</text>\n",
       "      <circle class=\"bean\" cx=\"55.659407736154726\" cy=\"40.97622087965936\" r=\"4\"/><circle class=\"bean\" cx=\"40.97622087965936\" cy=\"40.340592263845274\" r=\"4\"/><circle class=\"bean\" cx=\"40.34059226384527\" cy=\"55.023779120340635\" r=\"4\"/><circle class=\"bean\" cx=\"55.023779120340635\" cy=\"55.65940773615473\" r=\"4\"/><circle class=\"bean\" cx=\"147.2624569550367\" cy=\"40.70911093652182\" r=\"4\"/><circle class=\"bean\" cx=\"135.3171333323721\" cy=\"34.6009816361704\" r=\"4\"/><circle class=\"bean\" cx=\"124.05467637733543\" cy=\"41.89187069964858\" r=\"4\"/><circle class=\"bean\" cx=\"124.7375430449633\" cy=\"55.29088906347818\" r=\"4\"/><circle class=\"bean\" cx=\"136.68286666762788\" cy=\"61.3990183638296\" r=\"4\"/><circle class=\"bean\" cx=\"147.94532362266457\" cy=\"54.108129300351415\" r=\"4\"/><circle class=\"bean\" cx=\"233.05377757367182\" cy=\"53.1018733467695\" r=\"4\"/><circle class=\"bean\" cx=\"229.1018733467695\" cy=\"38.94622242632817\" r=\"4\"/><circle class=\"bean\" cx=\"214.94622242632818\" cy=\"42.89812665323049\" r=\"4\"/><circle class=\"bean\" cx=\"218.8981266532305\" cy=\"57.05377757367183\" r=\"4\"/><circle class=\"bean\" cx=\"312.0\" cy=\"48.0\" r=\"4\"/><circle class=\"bean\" cx=\"405.95267252042265\" cy=\"48.752123570037014\" r=\"4\"/><circle class=\"bean\" cx=\"394.04732747957735\" cy=\"47.247876429962986\" r=\"4\"/><circle class=\"bean\" cx=\"496.4845479783523\" cy=\"48.11155986302353\" r=\"4\"/><circle class=\"bean\" cx=\"483.85433968624494\" cy=\"40.596385979607234\" r=\"4\"/><circle class=\"bean\" cx=\"483.6611123354028\" cy=\"55.29205415736923\" r=\"4\"/><circle class=\"bean\" cx=\"55.16802513910278\" cy=\"140.54086066789\" r=\"4\"/><circle class=\"bean\" cx=\"48.34848812388694\" cy=\"127.5218778006265\" r=\"4\"/><circle class=\"bean\" cx=\"40.48348673701028\" cy=\"139.93726153148347\" r=\"4\"/><circle class=\"bean\" cx=\"140.4123226055643\" cy=\"143.24785549141444\" r=\"4\"/><circle class=\"bean\" cx=\"140.0706656757413\" cy=\"128.55488878818176\" r=\"4\"/><circle class=\"bean\" cx=\"127.5170117186944\" cy=\"136.1972557204038\" r=\"4\"/><circle class=\"bean\" cx=\"232.04058473131187\" cy=\"133.28909661208766\" r=\"4\"/><circle class=\"bean\" cx=\"217.6319964332067\" cy=\"130.3921010553588\" r=\"4\"/><circle class=\"bean\" cx=\"222.32741883548144\" cy=\"144.3188023325535\" r=\"4\"/><circle class=\"bean\" cx=\"318.9593379446192\" cy=\"145.7758690341362\" r=\"4\"/><circle class=\"bean\" cx=\"323.44795764184903\" cy=\"132.40218596500168\" r=\"4\"/><circle class=\"bean\" cx=\"312.1158889798126\" cy=\"124.00055960703342\" r=\"4\"/><circle class=\"bean\" cx=\"300.6236656865967\" cy=\"132.18175202616658\" r=\"4\"/><circle class=\"bean\" cx=\"304.8531497471225\" cy=\"145.6396333676621\" r=\"4\"/><circle class=\"bean\" cx=\"400.92577723463984\" cy=\"141.9281478146064\" r=\"4\"/><circle class=\"bean\" cx=\"399.07422276536016\" cy=\"130.0718521853936\" r=\"4\"/><circle class=\"bean\" cx=\"490.30280110326663\" cy=\"130.4595029935218\" r=\"4\"/><circle class=\"bean\" cx=\"485.69719889673337\" cy=\"141.5404970064782\" r=\"4\"/>\n",
       "    </svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = np.array([[4, 6, 4, 1, 2, 3], [3, 3, 3, 5, 2, 2],])\n",
    "SVG(board_to_svg(board, True, highlight=[(1, 3)]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  An example of a board configuration where South is to play pit 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": [
     "hc",
     "fig:post_capture"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"180\" width=\"535\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\"/><text x=\"82.0\" y=\"82.0\">4</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\"/><text x=\"170.0\" y=\"82.0\">6</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\"/><text x=\"258.0\" y=\"82.0\">4</text><circle class=\"highlight\" cx=\"312.0\" cy=\"48.0\" r=\"40\"/><text x=\"346.0\" y=\"82.0\">2</text><circle class=\"highlight\" cx=\"400.0\" cy=\"48.0\" r=\"40\"/><text x=\"434.0\" y=\"82.0\">3</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\"/><text x=\"522.0\" y=\"82.0\">4</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\"/><text x=\"82.0\" y=\"170.0\">3</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\"/><text x=\"170.0\" y=\"170.0\">3</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\"/><text x=\"258.0\" y=\"170.0\">3</text><circle cx=\"312.0\" cy=\"136.0\" r=\"40\"/><text x=\"346.0\" y=\"170.0\">0</text><circle cx=\"400.0\" cy=\"136.0\" r=\"40\"/><text x=\"434.0\" y=\"170.0\">3</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\"/><text x=\"522.0\" y=\"170.0\">3</text>\n",
       "      <circle class=\"bean\" cx=\"57.136120612231\" cy=\"52.95290825260956\" r=\"4\"/><circle class=\"bean\" cx=\"52.95290825260956\" cy=\"38.863879387769\" r=\"4\"/><circle class=\"bean\" cx=\"38.863879387769\" cy=\"43.04709174739043\" r=\"4\"/><circle class=\"bean\" cx=\"43.04709174739043\" cy=\"57.136120612231\" r=\"4\"/><circle class=\"bean\" cx=\"140.28725264680455\" cy=\"60.71296443566439\" r=\"4\"/><circle class=\"bean\" cx=\"149.15337648209572\" cy=\"50.64361251325739\" r=\"4\"/><circle class=\"bean\" cx=\"144.86612383529118\" cy=\"37.930648077593005\" r=\"4\"/><circle class=\"bean\" cx=\"131.71274735319545\" cy=\"35.28703556433561\" r=\"4\"/><circle class=\"bean\" cx=\"122.84662351790428\" cy=\"45.356387486742605\" r=\"4\"/><circle class=\"bean\" cx=\"127.13387616470881\" cy=\"58.069351922406995\" r=\"4\"/><circle class=\"bean\" cx=\"234.37683282507018\" cy=\"47.433130949384314\" r=\"4\"/><circle class=\"bean\" cx=\"223.43313094938432\" cy=\"37.62316717492982\" r=\"4\"/><circle class=\"bean\" cx=\"213.62316717492982\" cy=\"48.566869050615686\" r=\"4\"/><circle class=\"bean\" cx=\"224.56686905061568\" cy=\"58.37683282507018\" r=\"4\"/><circle class=\"bean\" cx=\"314.117663647503\" cy=\"53.61386682029814\" r=\"4\"/><circle class=\"bean\" cx=\"309.882336352497\" cy=\"42.38613317970186\" r=\"4\"/><circle class=\"bean\" cx=\"401.3013480386834\" cy=\"39.61510326347337\" r=\"4\"/><circle class=\"bean\" cx=\"392.087792398717\" cy=\"51.06544790759845\" r=\"4\"/><circle class=\"bean\" cx=\"406.6108595625996\" cy=\"53.31944882892818\" r=\"4\"/><circle class=\"bean\" cx=\"495.77112790309\" cy=\"54.89996892122102\" r=\"4\"/><circle class=\"bean\" cx=\"494.899968921221\" cy=\"40.228872096909996\" r=\"4\"/><circle class=\"bean\" cx=\"480.22887209691\" cy=\"41.10003107877898\" r=\"4\"/><circle class=\"bean\" cx=\"481.100031078779\" cy=\"55.771127903090004\" r=\"4\"/><circle class=\"bean\" cx=\"50.36413062516946\" cy=\"144.1492874772667\" r=\"4\"/><circle class=\"bean\" cx=\"53.87542466547063\" cy=\"129.87795908210512\" r=\"4\"/><circle class=\"bean\" cx=\"39.76044470935991\" cy=\"133.9727534406282\" r=\"4\"/><circle class=\"bean\" cx=\"144.36482296949876\" cy=\"137.4246882778159\" r=\"4\"/><circle class=\"bean\" cx=\"133.0514047563131\" cy=\"128.04350667134653\" r=\"4\"/><circle class=\"bean\" cx=\"130.58377227418814\" cy=\"142.53180505083753\" r=\"4\"/><circle class=\"bean\" cx=\"225.4174740457521\" cy=\"127.63395151044298\" r=\"4\"/><circle class=\"bean\" cx=\"216.04605245587516\" cy=\"138.95545571195208\" r=\"4\"/><circle class=\"bean\" cx=\"230.53647349837274\" cy=\"141.41059277760493\" r=\"4\"/><circle class=\"bean\" cx=\"406.71400122572834\" cy=\"130.81134048708932\" r=\"4\"/><circle class=\"bean\" cx=\"392.1494884373674\" cy=\"132.7798341339347\" r=\"4\"/><circle class=\"bean\" cx=\"401.1365103369043\" cy=\"144.40882537897593\" r=\"4\"/><circle class=\"bean\" cx=\"496.4137992443526\" cy=\"134.90091753005913\" r=\"4\"/><circle class=\"bean\" cx=\"482.84126703800075\" cy=\"129.26297734701876\" r=\"4\"/><circle class=\"bean\" cx=\"484.74493371764663\" cy=\"143.8361051229221\" r=\"4\"/>\n",
       "    </svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = np.array([[4, 6, 4, 2, 3, 4], [3, 3, 3, 0, 3, 3],])\n",
    "SVG(board_to_svg(board, True, highlight=[(0, 3), (0, 4)]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  The resulting board after South played 4 in :numref:`Fig %s <fig:pre_capture>`. Pits 2' and 3' will be captured."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If the pit chosen by the player contains more than 12 seeds, the sowing makes\n",
    "more than a full revolution of the board and the starting hole is skipped during the second\n",
    "and subsequent passes.\n",
    "\n",
    "If the current player's opponent has no seed left in his half board, the\n",
    "current player has to play a move that gives him seeds if such a move exists.\n",
    "This rule is called the \"feed your opponent\".\n",
    "In :numref:`Figure %s <fig:feed>`, South has to play pit 5 because playing pit 1 would leave the opponent without any move to play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hc",
     "fig:feed"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"180\" width=\"535\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\"/><text x=\"82.0\" y=\"82.0\">0</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\"/><text x=\"170.0\" y=\"82.0\">0</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\"/><text x=\"258.0\" y=\"82.0\">0</text><circle cx=\"312.0\" cy=\"48.0\" r=\"40\"/><text x=\"346.0\" y=\"82.0\">0</text><circle cx=\"400.0\" cy=\"48.0\" r=\"40\"/><text x=\"434.0\" y=\"82.0\">0</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\"/><text x=\"522.0\" y=\"82.0\">0</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\"/><text x=\"82.0\" y=\"170.0\">2</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\"/><text x=\"170.0\" y=\"170.0\">0</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\"/><text x=\"258.0\" y=\"170.0\">0</text><circle cx=\"312.0\" cy=\"136.0\" r=\"40\"/><text x=\"346.0\" y=\"170.0\">0</text><circle class=\"highlight\" cx=\"400.0\" cy=\"136.0\" r=\"40\"/><text x=\"434.0\" y=\"170.0\">3</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\"/><text x=\"522.0\" y=\"170.0\">0</text>\n",
       "      <circle class=\"bean\" cx=\"51.498823299699865\" cy=\"140.87424204543407\" r=\"4\"/><circle class=\"bean\" cx=\"44.50117670030014\" cy=\"131.12575795456593\" r=\"4\"/><circle class=\"bean\" cx=\"404.04328642987696\" cy=\"143.4600157403301\" r=\"4\"/><circle class=\"bean\" cx=\"404.43891992881913\" cy=\"128.7684033667846\" r=\"4\"/><circle class=\"bean\" cx=\"391.51779364130385\" cy=\"135.77158089288528\" r=\"4\"/>\n",
       "    </svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = np.array([[0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 3, 0],])\n",
    "SVG(board_to_svg(board, True, highlight=[(1, 4)]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  South is forced to play pit 5 because playing pit 1 would leave North without any seed to play."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When a player has captured more than 25 seeds the game ends and he wins. If both\n",
    "players have captured 24 seeds, the game ends by a draw. If the current player's\n",
    "pits are all empty, the game ends and the player with the most captures wins.\n",
    "\n",
    "The last way to stop the game is when a position is encountered twice in the\n",
    "same game (there is a cycle): the game ends and the player with most captures\n",
    "wins."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Implementation of the rules\n",
    "---------------------------\n",
    "\n",
    ".. todo:: Insert here some text explaining that we are showing inline code as this document is in fact a big jupyter notebook that is executed.\n",
    "\n",
    "In this subsection, we define in multiple steps a Python :code:`Game()` class holding the state of the game and its rules. We will then successively inherit from it to add the rules and some convenience methods.\n",
    "\n",
    "We set the following encoding conventions:\n",
    " - :code:`0` is South, :code:`1` is North,\n",
    " - player's actions are numbered from :code:`0` to :code:`5`, :code:`0` being the leftmost pit in front of him, :code:`5` being the rightmost.\n",
    "\n",
    "First, we define a dataclass with the minimal attributes needed to store a state of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "ha"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from typing import List, Dict, Set, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Game:\n",
    "    # a 2x6 matrix containing the number of seeds in each pits\n",
    "    pits: np.array = field(default_factory=lambda: np.ones(6 * 2, dtype=int) * 4)\n",
    "    # 0 for South and 1 for North\n",
    "    current_player: int = 0\n",
    "    # the number of seeds captured by each player\n",
    "    captures: np.array = field(default_factory=lambda: np.zeros(2, dtype=int))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Next, we add some convenient methods that will be useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Game(Game):\n",
    "    ...\n",
    "\n",
    "    @property\n",
    "    def view_from_current_player(self) -> List[int]:\n",
    "        \"\"\"Returns the board as seen by a player\"\"\"\n",
    "        if self.current_player == 0:\n",
    "            return self.pits\n",
    "        else:\n",
    "            return np.roll(self.pits, 6)\n",
    "\n",
    "    @property\n",
    "    def current_player_pits(self) -> List[int]:\n",
    "        \"\"\"Returns a 6-vector containing the pits owned by the current player\"\"\"\n",
    "        if self.current_player == 0:\n",
    "            return self.pits[:6]\n",
    "        else:\n",
    "            return self.pits[6:]\n",
    "\n",
    "    @property\n",
    "    def current_opponent(self) -> int:\n",
    "        return (self.current_player + 1) % 2\n",
    "\n",
    "    @property\n",
    "    def adverse_pits_idx(self) -> List[int]:\n",
    "        \"\"\"Returns the indices in the `self.pits` array owned by the opposing player\"\"\"\n",
    "        if self.current_player == 1:\n",
    "            return list(range(6))\n",
    "        else:\n",
    "            return list(range(6, 6 * 2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Now that the base is set, we start implementing the rules,\n",
    "some of them being deliberately excluded from this implementation:\n",
    "\n",
    "-  Loops in the game state are not checked (this considerably speeds up the computations and we did not encounter a loop in our preliminary work);\n",
    "-  The \"feed your opponent\" rule is removed; This makes the\n",
    "   rules simpler and we expect it does not tremendously change the complexity of the game.\n",
    "\n",
    ".. todo We did later encounter loops after running way more simulations. But this only happened yet using basic algorithms (greedy vs greedy for example). For now, we simulate 500 turns, if we hit this threshold, we declare a tie. This should be detailed in the experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Game(Game):\n",
    "    ...\n",
    "\n",
    "    @property\n",
    "    def legal_actions(self) -> List[int]:\n",
    "        \"\"\"Returns a list of indices for each legal action for the current player\"\"\"\n",
    "        our_pits = self.current_player_pits\n",
    "        # Return every pit of the player that contains some seeds\n",
    "        return [x for x in range(6) if our_pits[x] != 0]\n",
    "\n",
    "    @property\n",
    "    def game_finished(self) -> bool:\n",
    "        # Does the current player has an available move ?\n",
    "        no_moves_left = np.sum(self.current_player_pits) == 0\n",
    "\n",
    "        # Has one player captured more than half the total seeds ?\n",
    "        HALF_SEEDS = 24  # (there are 2*6*4=48 seeds in total)\n",
    "        enough_captures = self.captures[0] > HALF_SEEDS or self.captures[1] > HALF_SEEDS\n",
    "\n",
    "        # Is it a draw ? Does both player have 24 seeds ?\n",
    "        draw = self.captures[0] == HALF_SEEDS and self.captures[1] == HALF_SEEDS\n",
    "\n",
    "        # If one of the above three are True, the game is finished\n",
    "        return no_moves_left or enough_captures or draw\n",
    "\n",
    "    @property\n",
    "    def winner(self) -> Optional[int]:\n",
    "        \"\"\"Returns the winner of the game or None if the game is not finished or in a draw\"\"\"\n",
    "        if not self.game_finished:\n",
    "            return None\n",
    "        # The game is finished but both player have the same amount of seeds: it's a draw\n",
    "        elif self.captures[0] == self.captures[1]:\n",
    "            return None\n",
    "        # Else, there is a winner: the player with the most seeds\n",
    "        else:\n",
    "            return 0 if self.captures[0] > self.captures[1] else 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "We can now define the :code:`Game.step(i)` method that is called for every step of the game.\n",
    "It takes a single parameter, :code:`i`, and plays the i-th pit in the current sate.\n",
    "This method returns the new state, the amount of seeds captured and a boolean informing whether the game is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Game(Game):\n",
    "    ...\n",
    "\n",
    "    def step(self, action: int) -> Tuple[Game, int, bool]:\n",
    "        \"\"\"Plays the action given as parameter and returns:\n",
    "            - a the new state as a new Game object,\n",
    "            - the amount of captured stones in the transition\n",
    "            - a bool indicating if the new state is the end of the game\n",
    "        \"\"\"\n",
    "        assert 0 <= action < 6, \"Illegal action\"\n",
    "\n",
    "        # Translate the action index to a pit index\n",
    "        target_pit = action if self.current_player == 0 else action - 6\n",
    "\n",
    "        seeds = self.pits[target_pit]\n",
    "        assert seeds != 0, \"Illegal action: pit % is empty\" % target_pit\n",
    "\n",
    "        # Copy the attributes of `Game` so that the original\n",
    "        # stays immutable\n",
    "        pits = np.copy(self.pits)\n",
    "        captures = np.copy(self.captures)\n",
    "\n",
    "        # Empty the pit targeted by the player\n",
    "        pits[target_pit] = 0\n",
    "\n",
    "        # Fill the next pits while there are still seeds\n",
    "        pit_to_sow = target_pit\n",
    "        while seeds > 0:\n",
    "            pit_to_sow = (pit_to_sow + 1) % (6 * 2)\n",
    "            # Do not fill the target pit ever\n",
    "            if pit_to_sow != target_pit:\n",
    "                pits[pit_to_sow] += 1\n",
    "                seeds -= 1\n",
    "\n",
    "        # Count the captures of the play\n",
    "        round_captures = 0\n",
    "\n",
    "        # If the last seed was in a adverse pit we can try to collect seeds\n",
    "        if pit_to_sow in self.adverse_pits_idx:\n",
    "            # If the pit contains 2 or 3 seeds, we capture them\n",
    "            while pits[pit_to_sow] in (2, 3):\n",
    "                captures[self.current_player] += pits[pit_to_sow]\n",
    "                round_captures += pits[pit_to_sow]\n",
    "                pits[pit_to_sow] = 0\n",
    "\n",
    "                # Select backwards the next pit to check\n",
    "                pit_to_sow = (pit_to_sow - 1) % 12\n",
    "\n",
    "        # Change the current player\n",
    "        current_player = (self.current_player + 1) % 2\n",
    "\n",
    "        # Create the new `Game` instance\n",
    "        new_game = type(self)(pits, current_player, captures)\n",
    "\n",
    "        return new_game, round_captures, new_game.game_finished"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "As the game rules are now implemented, we can add some methods to display the current state of the board to the user, either in textual mode or as an SVG file that can be displayed inline in this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(Game):\n",
    "    ...\n",
    "\n",
    "    def show_state(self):\n",
    "        \"\"\"Print a textual representation of the game to the standard output\"\"\"\n",
    "        if self.game_finished:\n",
    "            print(\"Game finished\")\n",
    "        print(\n",
    "            \"Current player: {} - Score: {}/{}\\n{}\".format(\n",
    "                self.current_player,\n",
    "                self.captures[self.current_player],\n",
    "                self.captures[(self.current_player + 1) % 2],\n",
    "                \"-\" * 6 * 3,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        pits = []\n",
    "        for seeds in self.view_from_current_player:\n",
    "            pits.append(\"{:3}\".format(seeds))\n",
    "\n",
    "        print(\"\".join(reversed(pits[6:])))\n",
    "        print(\"\".join(pits[:6]))\n",
    "\n",
    "    def _repr_svg_(self):\n",
    "        \"\"\"Return a SVG file representing the current state to be displayed in a notebook\"\"\"\n",
    "        board = np.array([list(reversed(self.pits[6:])), self.pits[:6]])\n",
    "        return board_to_svg(board, True) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To show a minimal example of the implementation, we can now play a move and have its results displayed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "\n",
       "    <svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"535\" height=\"180\">\n",
       "      <style>\n",
       "        circle {\n",
       "          fill: none;\n",
       "          stroke: #000;\n",
       "          stroke-width: 2;\n",
       "        }\n",
       "        .bean {\n",
       "          fill: #000\n",
       "        }\n",
       "        .highlight {\n",
       "          stroke: red;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <circle cx=\"48.0\" cy=\"48.0\" r=\"40\" /><text x=\"82.0\" y=\"82.0\" >4</text><circle cx=\"136.0\" cy=\"48.0\" r=\"40\" /><text x=\"170.0\" y=\"82.0\" >4</text><circle cx=\"224.0\" cy=\"48.0\" r=\"40\" /><text x=\"258.0\" y=\"82.0\" >4</text><circle cx=\"312.0\" cy=\"48.0\" r=\"40\" /><text x=\"346.0\" y=\"82.0\" >5</text><circle cx=\"400.0\" cy=\"48.0\" r=\"40\" /><text x=\"434.0\" y=\"82.0\" >5</text><circle cx=\"488.0\" cy=\"48.0\" r=\"40\" /><text x=\"522.0\" y=\"82.0\" >5</text><circle cx=\"48.0\" cy=\"136.0\" r=\"40\" /><text x=\"82.0\" y=\"170.0\" >4</text><circle cx=\"136.0\" cy=\"136.0\" r=\"40\" /><text x=\"170.0\" y=\"170.0\" >4</text><circle cx=\"224.0\" cy=\"136.0\" r=\"40\" /><text x=\"258.0\" y=\"170.0\" >4</text><circle cx=\"312.0\" cy=\"136.0\" r=\"40\" /><text x=\"346.0\" y=\"170.0\" >4</text><circle cx=\"400.0\" cy=\"136.0\" r=\"40\" /><text x=\"434.0\" y=\"170.0\" >0</text><circle cx=\"488.0\" cy=\"136.0\" r=\"40\" /><text x=\"522.0\" y=\"170.0\" >5</text>\n",
       "      <circle cx=\"53.14269192301019\" cy=\"57.030654449429775\" r=\"4\" class=\"bean\"/><circle cx=\"57.030654449429775\" cy=\"42.85730807698981\" r=\"4\" class=\"bean\"/><circle cx=\"42.85730807698981\" cy=\"38.969345550570225\" r=\"4\" class=\"bean\"/><circle cx=\"38.969345550570225\" cy=\"53.14269192301019\" r=\"4\" class=\"bean\"/><circle cx=\"145.52722316328118\" cy=\"43.84885331540325\" r=\"4\" class=\"bean\"/><circle cx=\"131.84885331540326\" cy=\"38.47277683671882\" r=\"4\" class=\"bean\"/><circle cx=\"126.47277683671882\" cy=\"52.15114668459675\" r=\"4\" class=\"bean\"/><circle cx=\"140.15114668459674\" cy=\"57.52722316328118\" r=\"4\" class=\"bean\"/><circle cx=\"231.46489670164064\" cy=\"55.23016716499935\" r=\"4\" class=\"bean\"/><circle cx=\"231.23016716499936\" cy=\"40.53510329835936\" r=\"4\" class=\"bean\"/><circle cx=\"216.53510329835936\" cy=\"40.76983283500065\" r=\"4\" class=\"bean\"/><circle cx=\"216.76983283500064\" cy=\"55.46489670164064\" r=\"4\" class=\"bean\"/><circle cx=\"321.1926224734114\" cy=\"55.71334506302759\" r=\"4\" class=\"bean\"/><circle cx=\"322.17650365178264\" cy=\"41.64085120277446\" r=\"4\" class=\"bean\"/><circle cx=\"309.0968026700277\" cy=\"36.35648484076901\" r=\"4\" class=\"bean\"/><circle cx=\"300.0292217222466\" cy=\"47.16306068029614\" r=\"4\" class=\"bean\"/><circle cx=\"307.5048494825317\" cy=\"59.126258213132786\" r=\"4\" class=\"bean\"/><circle cx=\"410.8851968061277\" cy=\"42.94901093924486\" r=\"4\" class=\"bean\"/><circle cx=\"398.5599347402426\" cy=\"36.0867211882018\" r=\"4\" class=\"bean\"/><circle cx=\"388.22479391732435\" cy=\"45.68817783760989\" r=\"4\" class=\"bean\"/><circle cx=\"394.1625876761293\" cy=\"58.48449413949584\" r=\"4\" class=\"bean\"/><circle cx=\"408.16748686017604\" cy=\"56.791595895447614\" r=\"4\" class=\"bean\"/><circle cx=\"493.3441515260365\" cy=\"58.74430288416897\" r=\"4\" class=\"bean\"/><circle cx=\"499.8698729130978\" cy=\"46.23758205101426\" r=\"4\" class=\"bean\"/><circle cx=\"489.99183337639965\" cy=\"36.166462920974965\" r=\"4\" class=\"bean\"/><circle cx=\"477.36114781344367\" cy=\"42.44888982701612\" r=\"4\" class=\"bean\"/><circle cx=\"479.4329943710224\" cy=\"56.40276231682569\" r=\"4\" class=\"bean\"/><circle cx=\"49.13310129772461\" cy=\"146.33034759575372\" r=\"4\" class=\"bean\"/><circle cx=\"58.33034759575373\" cy=\"134.8668987022754\" r=\"4\" class=\"bean\"/><circle cx=\"46.86689870227539\" cy=\"125.66965240424628\" r=\"4\" class=\"bean\"/><circle cx=\"37.66965240424627\" cy=\"137.1331012977246\" r=\"4\" class=\"bean\"/><circle cx=\"144.85767624973218\" cy=\"130.56478413906765\" r=\"4\" class=\"bean\"/><circle cx=\"130.56478413906765\" cy=\"127.14232375026782\" r=\"4\" class=\"bean\"/><circle cx=\"127.14232375026783\" cy=\"141.43521586093235\" r=\"4\" class=\"bean\"/><circle cx=\"141.43521586093235\" cy=\"144.85767624973218\" r=\"4\" class=\"bean\"/><circle cx=\"234.00422439968887\" cy=\"138.81344880185688\" r=\"4\" class=\"bean\"/><circle cx=\"226.8134488018569\" cy=\"125.99577560031113\" r=\"4\" class=\"bean\"/><circle cx=\"213.99577560031113\" cy=\"133.1865511981431\" r=\"4\" class=\"bean\"/><circle cx=\"221.1865511981431\" cy=\"146.00422439968887\" r=\"4\" class=\"bean\"/><circle cx=\"314.2385986734839\" cy=\"146.14833365528924\" r=\"4\" class=\"bean\"/><circle cx=\"322.1483336552892\" cy=\"133.7614013265161\" r=\"4\" class=\"bean\"/><circle cx=\"309.7614013265161\" cy=\"125.85166634471076\" r=\"4\" class=\"bean\"/><circle cx=\"301.8516663447108\" cy=\"138.2385986734839\" r=\"4\" class=\"bean\"/><circle cx=\"493.67243561655437\" cy=\"146.5746618941716\" r=\"4\" class=\"bean\"/><circle cx=\"499.809980107083\" cy=\"133.87294337867945\" r=\"4\" class=\"bean\"/><circle cx=\"489.626533496083\" cy=\"124.11074481785676\" r=\"4\" class=\"bean\"/><circle cx=\"477.1952728773365\" cy=\"130.77909281783522\" r=\"4\" class=\"bean\"/><circle cx=\"479.69577790294306\" cy=\"144.66255709145696\" r=\"4\" class=\"bean\"/>\n",
       "    </svg>\n",
       "    "
      ],
      "text/plain": [
       "Game(pits=array([4, 4, 4, 4, 0, 5, 5, 5, 5, 4, 4, 4]), current_player=1, captures=array([0, 0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Game()  # Create a new game\n",
    "g, captures, done = g.step(4)  # play the 5th pit (our implementation starts at 0)\n",
    "g  # Display the resulting board inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=====================\n",
    "Awale and Game Theory\n",
    "=====================\n",
    "\n",
    ".. warning::\n",
    "  Previouosly, this section contained text about perfect information games, strongly solved games, then represented perfect information games as finite state machines and trees. After reading more litterature, i decided to remove an rewrite it.\n",
    "  I plan to rewrite it with the following: Set the basics of Game Theory and the concept of a \"solution\" to a game, talk about the minimax, define perfect information/combinatorial games then their tree representation.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tree representation\n",
    "~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "A combinatorial game like Awale can be represented as a tree in a straightforward way where every node is a state of the game.\n",
    "The root of the tree represents the initial state.\n",
    "If in a state :math:`s` the current player plays action :math:`i` resulting in state :math:`s'` then :math:`s'` will be the i-th child of the node representing :math:`s`.\n",
    "\n",
    "This results in the following properties:\n",
    "    - As the current player at the root node is South and that players alternate after each turn,\n",
    "      the tree contains alternating layers of current players:\n",
    "      the current player for nodes with an even depth is South and for odd depths is North;\n",
    "    - The leaf nodes of the tree correspond to final states;\n",
    "    - The path from the root to a leaf thus represents an instance of a full game.\n",
    "\n",
    ".. todo:: Insert a figure of an tree here\n",
    "\n",
    "\n",
    "We can now define the branching factor: the maximum number of children of a node in the game.\n",
    "In Awale the player can choose to sow his seeds from one of his non-empty pits.\n",
    "As the player has 6 pits, the branching factor is 6.\n",
    "\n",
    "We now implement this tree representation in Python by inheriting from :code:`Game()` class previously defined so that a state can hold references to its parent and children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Optional, List\n",
    "from weakref import ref, ReferenceType\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TreeGame(Game):\n",
    "    # Hold an optional reference to the parent state\n",
    "    parent: Optional[ReferenceType[Game]] = None\n",
    "    # Hold a list of 6 optional references to the children\n",
    "    children: List[Optional[Game]] = field(default_factory=lambda: [None] * 6)\n",
    "    depth: int = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Next, we overload the ``Game.step(i)`` method so that we do not compute twice state if it was already in the tree. If a new node was generated, we keep a reference to the parent when we create a new child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeGame(TreeGame):\n",
    "    ...\n",
    "\n",
    "    def step(self, action):\n",
    "        # If we already did compute the children node, just return it\n",
    "        if self.children[action] is not None:\n",
    "            new_game = self.children[action]\n",
    "            captures = (\n",
    "                new_game.captures[self.current_player]\n",
    "                - self.captures[self.current_player]\n",
    "            )\n",
    "            return new_game, captures, new_game.game_finished\n",
    "        # If not, call the original `step()` method and keep references in both directions\n",
    "        else:\n",
    "            new_game, captures, finished = super().step(action)\n",
    "            new_game.parent = ref(self)\n",
    "            new_game.depth = self.depth + 1\n",
    "            self.children[action] = new_game\n",
    "            return new_game, captures, finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class TreeGame(TreeGame):\n",
    "    ...\n",
    "\n",
    "    @property\n",
    "    def successors(self):\n",
    "        children = [x for x in self.children if x is not None]\n",
    "        successors = children + list(itertools.chain(*[x.successors for x in children]))\n",
    "        return successors\n",
    "\n",
    "    @property\n",
    "    def unvisited_actions(self):\n",
    "        return [i for i, x in enumerate(self.children) if x is None]\n",
    "\n",
    "    @property\n",
    "    def legal_unvisited_actions(self):\n",
    "        return list(set(self.unvisited_actions).intersection(set(self.legal_actions)))\n",
    "\n",
    "    @property\n",
    "    def expanded_children(self):\n",
    "        return [x for x in self.children if x is not None]\n",
    "\n",
    "    @property\n",
    "    def is_fully_expanded(self):\n",
    "        legal_actions = set(self.legal_actions)\n",
    "        unvisited_actions = set(self.unvisited_actions)\n",
    "        return len(legal_actions.intersection(unvisited_actions)) == 0\n",
    "\n",
    "    @property\n",
    "    def is_leaf_game(self):\n",
    "        return self.children == [None] * 6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "================================================\n",
    "Artificial Intelligence approaches to play Awale\n",
    "================================================\n",
    "\n",
    "Many algorithms have been proposed and studied to play sequential perfect information games.\n",
    "A few examples detailed here are retrograde analysis, Minimax, :math:`\\alpha-\\beta` pruning,\n",
    "Monte Carlo tree search (MCTS) and the new approach from Deepmind: Alpha Zero :cite:`AlphaGoZero`.\n",
    "\n",
    "We will quickly present those and then focus on MCTS and its variants as they are computationally feasible and do not require expert knowledge about the given game to make reasonable decisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First we implement a player class. A player keeps track of the game state internaly.\n",
    "At each turn of the game, a player is called with the method `play()` to get the action played by the opponent\n",
    "(and thus update it's internal state) and then chooses an action with `get_action()`,\n",
    "updates once more it's internal state and then outputs it's action for the other player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def play(self, their_action):\n",
    "        # If we are the first player, there is no previous action\n",
    "        if their_action != -1:\n",
    "            # Play the opponent's move\n",
    "            self.root, _, _ = self.root.step(their_action)\n",
    "        else:\n",
    "            assert self.player_id == 0, \"Only the first player can have their_action=-1\"\n",
    "        \n",
    "        action = self.get_action()\n",
    "        self.root, _, _ = self.root.step(action)\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Alpha-Beta pruning Minimax\n",
    "--------------------------\n",
    "\n",
    ".. todo:: Describe the algorithm and implement an agent for Awale\n",
    "\n",
    "\n",
    "\n",
    "Retrograde analysis\n",
    "-------------------\n",
    "\n",
    "\n",
    "For both divergent and convergent games search algorithms can prove the game result for positions near\n",
    "the end of a game. However, for divergent games the number of endgame\n",
    "positions is so big that enumerating all of them is computationally impossible (except for trivial\n",
    "games like Tic-Tac-Toe). However, for convergent games, the number of positions\n",
    "near the end of the game is small. Usually small enough to traverse them all, and collect\n",
    "their game values in a database, a so called endgame database.\n",
    "\n",
    "Retrograde Analysis computes endgame databases by going backward from values of final\n",
    "positions towards the initial position :cite:`goot2001`.\n",
    "First, Retrograde Analysis identifies all final positions in which the game value is known.\n",
    "By making reverse moves from these final positions the game value of some non-final positions can be deduced. And by making reverse moves from these newly proven non-final positions, the game value of other non-final positions can be deduced. This can continue either by running of available memory or by having enumerated all the legal positions in the game.\n",
    "\n",
    "Str√∂hlein is the first researcher who came up with the idea to create endgame databases and applied his idea to chess :cite:`endgame1970`.\n",
    "The first endgame database for Awale has been created by :cite:`allis1995` and was followed by many others, while the quest was ended by :cite:`romein2003solving` publishing a database for all legal positions.\n",
    "\n",
    "\n",
    "The above-mentioned results for Kalah and Awale both use an almost brute-force\n",
    "method to solve the game and use a database of all possible states. The database\n",
    "used by :cite:`romein2003solving` has 204 billion entries and weighs 178GiB.\n",
    "Such a huge database is of course not practical and  we thus think  there is still room for\n",
    "improvement if we can create an agent with a policy that does not need a\n",
    "exhaustive database, even if the agent is not capable of a perfect play.\n",
    "\n",
    "\n",
    "Monte Carlo Tree Search\n",
    "-----------------------\n",
    "\n",
    ".. todo:: This section and the next should be more detailed\n",
    "\n",
    "In this subsection, we define Markov Decision Processes (MDP) and model Awale with this framework. We then describe and detail Monte Carlo Tree Search, a policy-optimization algorithm for finite-horizon, finite-size MDPs.\n",
    "\n",
    "\n",
    "As Awale can be represented as an MDP, we could be tempted to use the usual framework of Q-Learning [Cite XXX] to find the best policy to maximise our reward. But since the state space is huge, this is computationally difficult or even impossible in memory and time constrained cases.\n",
    "To overcome this computational problem, the MCTS method constructs only a part of game the tree by sampling and tries to estimate the chance of winning based on this information.\n",
    "\n",
    "Algorithm\n",
    "~~~~~~~~\n",
    "\n",
    ".. figure:: _static/mcts-algorithm.png\n",
    "\n",
    "   The 4 steps of MCTS :cite:`chaslot2008monte`\n",
    "\n",
    "\n",
    "The (partial) tree is constructed as follows:\n",
    "\n",
    "* Selection: starting at the root node, recursively choose a child until\n",
    "  a leaf :math:`L` is reached\n",
    "* Expansion: if :math:`L` is not a terminal node\\footnote{As the tree is\n",
    "  not complete, a leaf could be a node that is missing its children, not\n",
    "  necessarily a terminal state}, create a child :math:`C`\n",
    "* Simulation: run a playout from :math:`C` until a terminal node :math:`T` is\n",
    "  reached (play a full game)\n",
    "* Back-propagation: update the counters described below of each ancestor\n",
    "  of :math:`T`.\n",
    "\n",
    "\n",
    "Each node holds 3 counters : (:math:`W_S`), the number of simulations using this node ended that\n",
    "with a win for South;  and North (:math:`W_N`). From this\n",
    "counters, a probability of North winning conditional on a given action can be computed\n",
    "immediately: :math:`\\frac{W_N}{N}`.\n",
    "\n",
    "This sampling can be ran as many times as allowed (most of the\n",
    "time, the agent is time constrained). One can also stop the sampling earlier if\n",
    "\n",
    "each time refining the probability of\n",
    "winning when choosing a child of the root node. When we are done sampling, the\n",
    "agent chooses the child with the highest probability of winning and plays the\n",
    "corresponding action in the game.\n",
    "\n",
    "the total number of times a node has been played during a\n",
    "sampling iteration (:math:`N`)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Implementation\n",
    "~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TreeStatsGame(TreeGame):\n",
    "    wins: np.array = field(default_factory=lambda: np.zeros(2, dtype=int))\n",
    "    n_playouts: int = 0\n",
    "\n",
    "    def update_stats(self, winner):\n",
    "        if winner in [0, 1]:\n",
    "            self.wins[winner] += 1\n",
    "        self.n_playouts += 1\n",
    "        if self.parent and self.parent():\n",
    "            self.parent().update_stats(winner)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The MCTS first chooses a node to expand with the `tree_policy()` when the node is found, it is expanded with the `default_policy()`. When reaching a terminal node, the counters are updated. This is repeated `BUDGET` times and then the final action is chosen as the action that has the highest amount of wins.\n",
    "\n",
    "Both policies in this implementation are random walks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSPlayer(Player):\n",
    "    def __init__(self, player_id, budget: Union[int, timedelta]):\n",
    "        self.root = TreeStatsGame()\n",
    "        self.player_id = player_id\n",
    "        self.budget = budget\n",
    "\n",
    "    def tree_policy(self, node):\n",
    "        while not node.is_leaf_game:\n",
    "            if node.is_fully_expanded:\n",
    "                node = random.choice(node.expanded_children)\n",
    "            else:\n",
    "                action = random.choice(node.legal_unvisited_actions)\n",
    "                node, _, _ = node.step(action)\n",
    "        return node\n",
    "    \n",
    "    def explore_tree(self):\n",
    "        # Choose a starting node\n",
    "        node = self.tree_policy(self.root)\n",
    "\n",
    "        # Run a simulation on that node\n",
    "        finished = node.game_finished\n",
    "        while not finished:\n",
    "            action = self.default_policy(node)\n",
    "            node, _, finished = node.step(action)\n",
    "\n",
    "        # Backtrack stats\n",
    "        node.update_stats(node.winner)\n",
    "    \n",
    "    def default_policy(self, node):\n",
    "        # Random walk\n",
    "        return random.choice(node.legal_actions)\n",
    "    \n",
    "    def action_score(self, x):\n",
    "        node = self.root.children[x]\n",
    "        if node is None:\n",
    "            return -random.random()\n",
    "\n",
    "        assert self.root.current_player == self.player_id\n",
    "        assert node.current_player != self.player_id\n",
    "\n",
    "        return node.wins[self.player_id]\n",
    "        \n",
    "    \n",
    "    def get_action(self):\n",
    "        if isinstance(self.budget, int):\n",
    "            for _ in range(self.budget):\n",
    "                self.explore_tree()\n",
    "        elif isinstance(self.budget, timedelta):\n",
    "            start = datetime.now()\n",
    "            end = start + self.budget\n",
    "            while datetime.now() < end:\n",
    "                self.explore_tree()\n",
    "        else:\n",
    "            raise TypeError(\"budget should be Union[int, timedelta], not %s\" % type(budget))\n",
    "        \n",
    "        possible_actions = self.root.legal_actions\n",
    "        return max(possible_actions, key=self.action_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Naive agents\n",
    "------------\n",
    "\n",
    "To be able to benchmark our agents, we also implement two naive agents.\n",
    "The first is a random player thatchooses an action at random between all the legal actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer(Player):\n",
    "    def __init__(self, player_id):\n",
    "        self.root = Game()\n",
    "        self.player_id = player_id\n",
    "    \n",
    "    def get_action(self):\n",
    "        return random.choice(self.root.legal_actions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The second is :math:`\\varepsilon`-Greedy: an agent that tries to maximise an immediate reward at each turn: the number of seeds captured during that turn. The :math:`\\varepsilon` parameter introduces randomness: at each turn, the agent draws an number between 0 and 1, if it is geater than :math:`\\varepsilon`, the agent plays at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyPlayer(Player):\n",
    "    def __init__(self, player_id, eps=0):\n",
    "        self.root = Game()\n",
    "        self.player_id = player_id\n",
    "        self.eps = eps\n",
    "    \n",
    "    def get_action(self):\n",
    "        # Choose a move\n",
    "        children = []\n",
    "        \n",
    "        for legal_action in self.root.legal_actions:\n",
    "            new_state, captures, finished = self.root.step(legal_action)\n",
    "            if new_state.winner is None:\n",
    "                win = 0\n",
    "            elif new_state.winner == self.player_id:\n",
    "                win = 1\n",
    "            else:\n",
    "                win = -1\n",
    "            children.append((legal_action, captures, win))\n",
    "        \n",
    "        # order wins first, then by captures, then random\n",
    "        sorted_children = sorted(children, key=lambda a_c_w: (-a_c_w[2], -a_c_w[1], random.random()))\n",
    "        if random.random() < self.eps:\n",
    "            action = random.choice(self.root.legal_actions)\n",
    "        else:\n",
    "            action = sorted_children[0][0]\n",
    "            \n",
    "        return action"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "================================\n",
    "Monte Carlo tree search variants\n",
    "================================\n",
    "\n",
    "Node Selection\n",
    "--------------\n",
    "\n",
    "In step 1 and 3 of the algorithm, we have to choose nodes.\n",
    "There are multiples ways to choose those.\n",
    "\n",
    "In the original MCTS we take a child at random each time.\n",
    "This is easy to implement but it is not effective since it explores every part of the tree even if a part has no chance of leading to a win for the player."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Upper Confidence Bounds for Trees\n",
    "---------------------------------\n",
    "\n",
    "A better method would be asymmetric and explore more often the interesting parts of the\n",
    "tree. Kocsis and Szepervari :cite:`kocsis2006bandit` defined Upper Confidence\n",
    "Bounds for Trees (UCT), a method mixing vanilla MCTS and Upper Confidence Bounds\n",
    "(UCB).\n",
    "\n",
    "Indeed, in step 1, selecting the node during the tree descent that maximizes the\n",
    "probability of winning is analogous to the multi-armed bandit problem in which a\n",
    "player has to choose the slot machine that maximizes the estimated reward.\n",
    "\n",
    "The UCB is\n",
    "\n",
    ".. math::\n",
    "\n",
    "    \\frac{W_1}{N} + c \\times \\sqrt{\\frac{ln N'}{N}},\n",
    "\n",
    "where :math:`N'` is the number of times the\n",
    "parent node has been visited and :math:`c` is a parameter that can be tuned to balance exploitation of known wins and exploration of\n",
    "less visited nodes. Kocsis et al. has shown that :math:`\\frac{\\sqrt{2}}{2}`\n",
    ":cite:`kocsis2006bandit` is a good value when rewards are in :math:`[0, 1]`.\n",
    "\n",
    "In step 3, the playouts are played by choosing an action from an uniform distribution since it is the first time these nodes\n",
    "are seen and we do not have a generic evaluation function do direct the playout\n",
    "towards 'better' states."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "`UCTPlayer` reuses the MCTS agent but subclasses the `tree_policy` and uses UCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCTPlayer(MCTSPlayer):\n",
    "    def __init__(self, player_id, budget: Union[int, timedelta], c: float):\n",
    "        super().__init__(player_id, budget)\n",
    "        self.c = c\n",
    "        \n",
    "    def node_score(self, node):\n",
    "        exporation = node.wins[node.current_opponent] / (node.n_playouts + 1)\n",
    "        exploitation = math.sqrt(math.log(node.parent().n_playouts) / (node.n_playouts + 1))\n",
    "        return exporation + self.c * exploitation\n",
    "\n",
    "    def tree_policy(self, node):\n",
    "        while not node.is_leaf_game:\n",
    "            if node.is_fully_expanded:\n",
    "                node = max_rand(node.expanded_children, key=self.node_score)\n",
    "            else:\n",
    "                action = random.choice(node.legal_unvisited_actions)\n",
    "                node, _, _ = node.step(action)\n",
    "        return node"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Informed UCT\n",
    "------------\n",
    "\n",
    " `GreedyUCTPlayer` subclasses `UCTPlayer` and changes the `default_policy` to weigh more the actions that will give more immediate rewards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyUCTPlayer(UCTPlayer):    \n",
    "    def default_policy(self, node):\n",
    "        # Greedy walk\n",
    "        assert len(node.legal_actions) != 0\n",
    "        captures = [node.step(action)[1] + 1 for action in node.legal_actions]\n",
    "        return random.choices(node.legal_actions, weights=captures)[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Alpha Zero\n",
    "----------\n",
    "\n",
    "To replace the random play in step 3, D. Silver et al. propose\n",
    ":cite:`AlphaGoZero` to use a neural network to estimate the value of a\n",
    "game state without having to play it. This can greatly enhances the performance\n",
    "of the algorithm as much less playouts are required."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=================\n",
    "Empirical results\n",
    "=================\n",
    "\n",
    "\n",
    "This section first describes the experimental setup in wich the games between agents are played as well as the method used to run the experiments in a massively parallel setup to be able to record enough game to have statistically strong results. Next, we individually tune variables of the different agents to create a champion agent for each algorithm. Those champions are then opposed against each other in a final round of matches used to rank them.\n",
    "\n",
    "Experimental setup\n",
    "------------------\n",
    "\n",
    "A match between two agents is played with the following code, where the variables `player` and `opponent` contain an instance of an agent (a class derived from `Player`).\n",
    "Because most games finish in less than 200 moves, we limit games to 500 moves to avoid agents playing infinite games. A game that goes over the threshold of 500 moves is considered a draw, regardles of the score of both players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "ha"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "player = RandomPlayer(0)\n",
    "opponent = RandomPlayer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game()\n",
    "opponent_action = -1\n",
    "depth = 0\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "while not game.game_finished and depth < 500:\n",
    "    player_action = player.play(opponent_action)\n",
    "    game, captures, finished = game.step(player_action)\n",
    "\n",
    "    player, opponent = opponent, player\n",
    "    opponent_action = player_action\n",
    "    depth += 1\n",
    "\n",
    "duration = round(time.perf_counter() - start, 4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Relevant data from the match can then be recorded in a dictionary like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration': 0.0265, 'depth': 81, 'score': [30, 14], 'winner': 0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"duration\": duration,\n",
    "    \"depth\": depth,\n",
    "    \"score\": game.captures.tolist(),\n",
    "    \"winner\": game.winner,\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Because the number of matches we expect to play is quite high and a match between two agents might take a few minutes, we have to be able to run matches in a massively parralel setup.\n",
    "\n",
    "To this effect, we placed the code to run a match in a standalone Python script that accepts the match parameters via environment variables and packaged it in a Docker container. The dictionary showed above is then outputed to the standard output.\n",
    "\n",
    "This Docker container is then used to launch hundreds of AWS Batch tasks in parallel, their standard output being sent to AWS Cloudwatch to be analyzed later.\n",
    "Each AWS Batch tasks are allowed 1 vCPU each with 500MB of RAM and are running on C5 compute optimized EC2 instances [#aws_c5]_. \n",
    "\n",
    "AWS Batch tasks can be launched with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('batch')\n",
    "\n",
    "def submit_match(a, b, pool, side, timeout=600):\n",
    "    return client.submit_job(\n",
    "        jobDefinition='run-match',\n",
    "        jobName=pool,\n",
    "        jobQueue='match-queue',\n",
    "        containerOverrides={\n",
    "            'command': [\"python\", \"simulate.py\"],\n",
    "            'environment': [\n",
    "                {'name': 'PLAYER_A', 'value': a % 0},\n",
    "                {'name': 'PLAYER_B', 'value': b % 1},\n",
    "                {'name': 'POOL','value': pool},\n",
    "                {'name': 'SIDE', 'value': str(side)},\n",
    "            ]\n",
    "        },\n",
    "        timeout={'attemptDurationSeconds': timeout},\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Because we can not be sure an agent has the same strength if it is allowed to be the first player as if it is the second to play, each time we play a match between two agents (A and B), we play the match A vs B and B vs A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumbit_symmetric_match(a, b, pool, timeout=600):\n",
    "    submit_job(a, b, pool, side=0, timeout=timeout)\n",
    "    submit_job(b, a, pool, side=1, timeout=timeout)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Algorithm tuning\n",
    "----------------\n",
    "\n",
    "Now that we have a way to run a match between two agents of our choice and record the result, we can start tuning each algorithm individually to create be best agent possible for a given algorithm.\n",
    "\n",
    ".. todo:: Insert here a paragraph about the (non-)transitivity of the relation \"A wins against B\". The best way to avoid this problem would be to play a full tournament for each possible value of a variable. But this is not feasible. However, we think that the relation is fairly transitive inside a single algorithm family. This enables us to play a much smaller amount of matches.\n",
    "\n",
    "\n",
    "\n",
    ":math:`\\varepsilon`-Greedy\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "The first agent we have to tune is :math:`\\varepsilon`-Greedy and it has one parameter, :math:`\\varepsilon` that can very in the interval :math:`[0, 1]`. As running a match between two :math:`\\varepsilon`-Greedy agents takes less than 100ms, playing thousands of matches is computaionaly feasible.\n",
    "\n",
    "We thus pick evenly spaced values of :math:`\\varepsilon` in the interval :math:`[0, 1]` and play 50 matches for each pair of values of :math:`\\varepsilon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = np.linspace(0, 1, 21)\n",
    "\n",
    "for i in range(25):\n",
    "    for eps1 in search_space:\n",
    "        for eps2 in search_space:\n",
    "            player = f\"GreedyPlayer(%s, {eps1})\"\n",
    "            opponent = f\"GreedyPlayer(%s, {eps2})\"\n",
    "            sumbit_symmetric_match(player, opponent, \"epsilon-greedy-tuning\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The results of these matches is shown in :numref:`Figure %s <eps-matrix>` below in wich we can see despite the noise that a higher value of :math:`\\varepsilon` (meaning the agent choses most often the greedy approach) is stronger than a lower value. Due to the noise in the data despite the high number of games played it is hard to know for sure if :math:`\\varepsilon = 1` is the optimium or if it is a bit lower. We will keep a value of :math:`\\varepsilon = 0.95` for the rest of this work.\n",
    "\n",
    ".. _eps-matrix:\n",
    "\n",
    ".. figure:: /notebooks/plot-eps.png\n",
    "\n",
    "  Heatmap of the win ratio of the row player against the column player.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MCTS\n",
    "~~~~\n",
    "\n",
    "The MCTS agent has a parameter :math:`t` that states how much time the agent may spend on simulation during its turn.\n",
    "As :cite:`kocsis2006bandit` have shown that given enough time MCTS converges to the minimax tree and thus is optimal, we know that the higher is :math:`t`, the better the agent will be. However, since we are constrained by the capacity of our computation resources, we have to choose a reasonable value of :math:`t`.\n",
    "\n",
    "Given our objective of producing an agent capable of playing against a human, choosing a value of :math:`t` higher than 1 minute is unrealistic as the human will not want to wait more than that at each turn of the game. While 1 minute is an upper bound, having a much smaller waiting time at each turn would be valuable. We think that  :math:`t = 5s` is a reasonable value.\n",
    "\n",
    "As stated earlier, we know that the strength of the agent is an increasing function of :math:`t`. However, we don't know the shape of this function. We compare the strength of MCTS(t=5) against a range of values of :math:`t' \\in \\{0.5, 1, 1.5, 2, 3, 5, 7, 10, 15, 20, 30, 40\\}` by playing 10 matches for each value of :math:`t'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [0.5, 1, 1.5, 2, 3, 5, 7, 10, 15, 20, 30, 40]\n",
    "\n",
    "for i in range(5):\n",
    "    for time in search_space:\n",
    "            player = \"MCTSPlayer(%s, td(seconds=5))\"\n",
    "            opponent = f\"MCTSPlayer(%s, td(seconds={time}))\"\n",
    "\n",
    "            sumbit_symmetric_match(player, opponent, \"mcts-5s-time-compare\", timeout=60*100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "While the results showin in :numref:`Figure %s <mcts-time_5s>` are also noisy, we indeed see that the strength of MCTS increases with :math:`t` but the slope of the curve is not very important after :math:`t=5s` so we decide that :math:`t=5s` is a good compromise between strength and waiting time.\n",
    "\n",
    "\n",
    ".. _mcts-time_5s:\n",
    "\n",
    "..  figure:: notebooks/mcts-time.png\n",
    "\n",
    "  Strength of MCTS related to the allowed simulation time budget"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "UCT\n",
    "~~~\n",
    "\n",
    "The UCT agent has 2 variables that we can tune, :math:`t` as in MCTS and :math:`c` the balance between exploration and exploitation. We will fix :math:`t=5s` so that we can fairly compare MCTS and UTC later.\n",
    ":cite:`kocsis2006bandit` has shown that :math:`c=\\frac{\\sqrt{2}}{2}` is a good starting value. We thus play matches of UCT(:math:`c=\\frac{\\sqrt{2}}{2}`) against a range of 11 values equaly spaced between 0.2 and 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = np.linspace(0, 2, 11) + 0.2\n",
    "\n",
    "for i in range(25):\n",
    "    for c in search_space:\n",
    "            player = \"UCTPlayer(%s, td(seconds=5), c=math.sqrt(2)/2)\"\n",
    "            opponent = f\"UCTPlayer(%s, td(seconds=5), c={c:.2f})\"\n",
    "\n",
    "            sumbit_symmetric_match(player, opponent, \"uct-tuning-c\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What we see in :numref:`Figure %s <utc-tuning-c>` is a bell curve with some noise and a plateau around :math:`c = \\sqrt(2) / 2`. The noise is louder on the right than on on the left of its maximum. An explanation for this could be that on the left, as :math:`c` is lower, there is not much exploration so the algorithm is more deterministic while it's the opposite on the right and each simulation could be either really good or really bad depending on luck.\n",
    "\n",
    "As the maximum of the bell curve is around :math:`c = \\sqrt(2) / 2` it seems to confirm that it is the optimum value for UCT.\n",
    "\n",
    ".. _utc-tuning-c:\n",
    "\n",
    ".. figure:: notebooks/uct-value.png\n",
    "\n",
    "  Strength of UCT(:math:`c=\\frac{\\sqrt{2}}{2}`) against other values of :math:`c`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Under the assumption that the curve is smooth, we know that :math:`c = \\sqrt(2) / 2` is will win against any value of :math:`c \\in [0.2, 2.2]`. While this result might be convenient, we don't know if the relation of one agent winning against another is transitive, so while :math:`c = \\sqrt(2) / 2` beats every value, we might have another value of :math:`c = \\sqrt(2) / 2` that beats every :math:`c \\neq \\sqrt(2) / 2` by a bigger margin. To have a better intuition it is the case or not, we can also run the same experiment as above but with :math:`c = 1.5` to see if we were not lucky by using :math:`c = \\sqrt(2) / 2` the first time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = np.linspace(0, 2, 11) + 0.2\n",
    "\n",
    "for i in range(25):\n",
    "    for c in space:\n",
    "            player = \"UCTPlayer(%s, td(seconds=5), c=1.5)\"\n",
    "            opponent = f\"UCTPlayer(%s, td(seconds=5), c={c:.2f})\"\n",
    "\n",
    "            sumbit_double(player, opponent, \"uct-tuning-c-15\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "While the curve in :numref:`Figure %s <uct-tuning-c-15>` is not as smooth as in the first experiment, the result of the matches against :math:`c = 1.5` seem to show the same curve with a maximum at :math:`c = \\sqrt(2) / 2`.\n",
    "\n",
    ".. _uct-tuning-c-15:\n",
    "\n",
    ".. figure:: notebooks/uct-c-15.png\n",
    "\n",
    "  Strength of UCT(:math:`c=1.5`) against other values of :math:`c`.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comparing algorithms\n",
    "--------------------\n",
    "\n",
    "Now that we have found the best values of each variable for each algorithm, we have a small (:math:`N = 5`) set of agents to compare to each other. As the assumptions of smoothness and transitivity we placed in the previous section might not hold when comparing agents using different algorithms, we need to define a stronger framework to find the best agent.\n",
    "\n",
    "\n",
    "How to compare A and B\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "The first step is to define a way to compare agent A and B. The probability that A wins is denoted by :math:`p` and is unknown (the probability that B wins is :math:`1-p`).\n",
    "Our null hypothesis is that both agents are equaly strong (:math:`p=0.50`) and the alternative hypothesis is that they are of different strength (:math:`p \\neq 0.50`).\n",
    "To compare agents A and B, we run :math:`N` matches and A wins :math:`n` times (thus B wins :math:`N-n` times).\n",
    "\n",
    "Using the SciPy function `scipy.stats.binom_test`, we then compute the p-value.\n",
    "If it is lower than :math:`5\\%`, we traditionally reject the null hypothesis.\n",
    "This guarantees that, conditional on H0 being true, the probability of making an incorrect decision is :math:`5\\%`.\n",
    "But if H1 is true, the probability of an incorrect decision is not necessarily :math:`5\\%`: it depends on the number :math:`N` of matches and on the true value of :math:`p`.\n",
    "To ensure that the probability of an incorrect decision, conditional on H1, be acceptable, we resort to the concept of statistical power.\n",
    "\n",
    "Suppose the true probability :math:`p` is :math:`0.75`. This is very far from the null hypothesis. In that case, we want the probability of choosing H1 (not making an incorrect decision) to be high (for instance :math:`95\\%`). This probability is the power and can be computed by means of the R function powerBinom implemented in the R package exactci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "#powerBinom(power = 0.95, p0 = 0.5, p1 = 0.75, sig.level = 0.05, alternative = \"two.sided\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The output of this command is the number :math:`N` of matches needed to achieve the desired power and it is 49. As we always play a even number of matches between two agents (A vs. B and B vs. A), we decide that we need :math:`N=50` matches.\n",
    "\n",
    "Now that we know the amount of matches we need to play to be able to assertain that H1 is probable enough, we still need to know how many matches of the 50 an agent needs to win so we may declare H1 true. This can be done with the `scipy.stats.binom_test` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If a agent wins 32 matches, we can reject H0 with a p-value of 0.0325\n"
     ]
    }
   ],
   "source": [
    "for wins in range(50):\n",
    "    pvalue = scipy.stats.binom_test(wins, 50, p=0.5, alternative=\"greater\")\n",
    "    if pvalue < 0.05:\n",
    "        print(\"If a agent wins\", wins, \"matches, we can reject H0 with a p-value of\", round(pvalue, 4))\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "How to compare more than 2\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "We now have a way to determine if an agent is stronger than another but we don't have a way to order all our agents regarding to their strength. In the following, we prove that a total order between all agents does not exist by showing that the relation between two agents is not transitive.\n",
    "\n",
    "Lets define 3 theoretical algorithms: each of them play the first move at random and the next moves of the match depending on the first move in three different ways: always playing the best move (noted :math:`+`), never playing the best move (noted :math:`-`) or playing at random (noted :math:`r`).\n",
    "\n",
    ".. table:: Moves of the theoretical algorithms depending on the first move of the game.\n",
    "\n",
    "    +------------+-----------+-----------+-----------+\n",
    "    | First move | A         | B         | C         |\n",
    "    +------------+-----------+-----------+-----------+\n",
    "    | 1, 2       | :math:`+` | :math:`r` | :math:`-` |\n",
    "    +------------+-----------+-----------+-----------+\n",
    "    | 3, 4       | :math:`r` | :math:`-` | :math:`+` |\n",
    "    +------------+-----------+-----------+-----------+\n",
    "    | 5, 6       | :math:`-` | :math:`+` | :math:`r` |\n",
    "    +------------+-----------+-----------+-----------+\n",
    "\n",
    "\n",
    "If A and B are playing matches, if the match starts with move:\n",
    " - 1 or 2: A wins all the time,\n",
    " - 3 or 4: A wins more than half the matches,\n",
    " - 5 or 6: B wins all the matches.\n",
    "So A wins more matches than B and we can say :math:`A > B`. By doing the same with B vs. C and C vs. A we have :math:`B > C` and :math:`C > A`. Thus the relation between these 3 theoretical algorithms is not transitive.\n",
    "\n",
    "\n",
    "As proved above, transitivity can not be assumed in all cases so if we want to compare different algorithms, we do have to use a full tournament.\n",
    "\n",
    ".. todo:: We transform the valued tournament in a binary tournament. The check if the tournament a complete pre-order.\n",
    "\n",
    "\n",
    "Run + result\n",
    "------------\n",
    "\n",
    ".. todo:: Here we run the big tournament with all the algorithms against the others\n",
    "\n",
    "\n",
    ".. figure:: notebooks/matrix.png\n",
    "\n",
    "We see that UCT and GreedyUCT beat every other agent. There is no clear winner between those 2 champions though.\n",
    "\n",
    "Limitations\n",
    "-----------\n",
    "\n",
    ".. todo:: As we only compare the champions of each algorithm, we might have a non-champion that would still won against another algo. Then we would not have a complete pre-order. We can not do this due to compute limitation.\n",
    "\n",
    "\n",
    "Ranking\n",
    "--------\n",
    "\n",
    ".. todo:: We might still want to rank our algorithms on a scale with total ordering. There are a lot of algorithms to do this (Elo ranking and others). Research is still developing on this subject and there is no consensus on the right method to use. This is beyond the topic, i won't go further.\n",
    "https://www.researchgate.net/publication/287630111_A_Comparison_between_Different_Chess_Rating_Systems_for_Ranking_Evolutionary_Algorithms\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "==========\n",
    "Conclusion\n",
    "=========="
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "========\n",
    "Appendix\n",
    "========\n",
    "\n",
    "Bibliography\n",
    "------------\n",
    "\n",
    ".. warning::\n",
    "   Some papers are currently wrongly cited. \n",
    "\n",
    ".. bibliography:: refs.bib\n",
    "   :style: custom"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Footnotes\n",
    "---------\n",
    "\n",
    ".. [#source_bao] Picture by Yintan under Creative Commons SA license https://commons.wikimedia.org/wiki/File:Bao_europe.jpg\n",
    "\n",
    ".. [#Fly08] Jennifer Flynn. Independent study quarterly reports.\n",
    " http://users.soe.ucsc.edu/~charlie/projects/SlugGo/, 2008\n",
    "\n",
    ".. [#GS07] Sylvain Gelly and David Silver. Combining online and offline\n",
    " knowledge in uct. In ICML ‚Äô07: Proceedings of the 24th\n",
    " Internatinoal Conference on Machine Learning, pages 273‚Äì280.\n",
    " ACM, 2007. \n",
    " \n",
    " .. [#aws_c5] C5 instances contain a 2nd generation Intel Xeon Scalable Processor (Cascade Lake) with a sustained all core Turbo frequency of 3.6GHz.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
